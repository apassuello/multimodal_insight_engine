# Mermaid Diagrams - Complete Reference

**Purpose**: Exportable, styled versions of all architecture diagrams
**Format**: Ready for copying, rendering, and presentations
**Last Updated**: 2025-11-07

---

## Diagram 1: Repository Structure (Copy-Paste Ready)

### Usage
- Copy the code block below
- Paste into any Mermaid viewer (mermaid.live, GitHub, etc.)
- Export as PNG/SVG for presentations

### Styled Version
```mermaid
%%{init: {'theme': 'default', 'themeVariables': { 'primaryColor': '#e1f5ff', 'fontSize': '12px'}}}%%
graph TD
    ROOT["ğŸ—ï¸ MultiModal Insight Engine<br/>Root Directory<br/>(18 directories, 120+ files)"]

    ROOT -->|Core Code| SRC["ğŸ“ src/<br/>Core Application Code<br/>8 major modules"]
    ROOT -->|Testing| TESTS["ğŸ“ tests/<br/>Test Suite<br/>35+ test files"]
    ROOT -->|Documentation| DOCS["ğŸ“ docs/<br/>Documentation<br/>20+ guides"]
    ROOT -->|Prototypes| DEMOS["ğŸ“ demos/<br/>Example Scripts<br/>24 demos"]

    SRC -->|Config| CONFIGS["âš™ï¸ configs/<br/>Training configs<br/>4 files"]
    SRC -->|Data| DATA["ğŸ“Š data/<br/>Datasets & Preprocessing<br/>27 modules"]
    SRC -->|Models| MODELS["ğŸ§  models/<br/>Neural Architectures<br/>14 files"]
    SRC -->|Training| TRAINING["ğŸ‹ï¸ training/<br/>Training Logic<br/>20+ files, 21 losses"]
    SRC -->|Safety| SAFETY["ğŸ›¡ï¸ safety/<br/>Constitutional AI<br/>5 modules"]
    SRC -->|Evaluation| EVALUATION["ğŸ“ˆ evaluation/<br/>Metrics & Evaluation<br/>3 files"]
    SRC -->|Optimization| OPTIMIZATION["âš¡ optimization/<br/>Pruning, Quantization<br/>4 files"]
    SRC -->|Utilities| UTILS["ğŸ”§ utils/<br/>Helpers & Logging<br/>11 files"]

    DATA -->|Loaders| "WMT Dataset"
    DATA -->|Loaders| "Flickr30K Dataset"
    DATA -->|Loaders| "OpenSubtitles"
    DATA -->|Processing| "Tokenization (BPE)"
    DATA -->|Processing| "Augmentation Pipeline"

    MODELS -->|Components| "Attention Mechanisms"
    MODELS -->|Components| "Feed Forward Layers"
    MODELS -->|Components| "Transformer Stack"
    MODELS -->|Components| "Embeddings"

    TRAINING -->|Losses| "Contrastive Losses"
    TRAINING -->|Losses| "InfoNCE"
    TRAINING -->|Losses| "VICReg"
    TRAINING -->|Losses| "BarlowTwins"
    TRAINING -->|Trainers| "Multimodal Trainer"
    TRAINING -->|Trainers| "Vision Trainer"

    TESTS -->|Coverage| "Model Tests: 70%"
    TESTS -->|Coverage| "Data Tests: 65%"
    TESTS -->|Coverage| "Loss Tests: 55%"
    TESTS -->|Coverage| "Training Tests: 45%"

    style ROOT fill:#263238,color:#fff
    style SRC fill:#e1f5ff
    style TESTS fill:#f3e5f5
    style DOCS fill:#e8f5e9
    style DEMOS fill:#fff3e0
    style DATA fill:#fce4ec
    style MODELS fill:#f1f8e9
    style TRAINING fill:#ffe0b2
    style SAFETY fill:#c8e6c9
```

---

## Diagram 2: Current Architecture (Copy-Paste Ready)

```mermaid
%%{init: {'theme': 'default'}}%%
graph LR
    INPUT["ğŸ“¥ Input Data<br/>Text | Images | Sequences<br/>Raw, unprocessed"]

    INPUT --> LOADER["ğŸ”„ DataLoader<br/>Dataset Classes<br/>WMT | Flickr30K<br/>OpenSubtitles | IWSLT"]

    LOADER --> PREPROCESS["ğŸ“ Preprocessing<br/>Tokenization | Normalization<br/>Augmentation | Padding"]

    PREPROCESS --> FEATURES["âš™ï¸ Feature Engineering<br/>Embeddings | Position IDs<br/>Segment IDs | Attention Masks"]

    FEATURES --> MODEL["ğŸ§  Model Architecture<br/>Multi-Stage Transformer"]

    MODEL --> TEXT_ENC["ğŸ“– Text Encoder<br/>Self-Attention Layers<br/>Token â†’ Embeddings"]

    MODEL --> IMG_ENC["ğŸ–¼ï¸ Image Encoder<br/>Patch Embeddings<br/>Spatial Features"]

    MODEL --> FUSION["ğŸ”— Fusion Module<br/>Cross-Modal Attention<br/>Projection"]

    TEXT_ENC --> LOSS["ğŸ’£ Loss Computation<br/>21 Different Classes<br/>35% Code Duplication"]
    IMG_ENC --> LOSS
    FUSION --> LOSS

    LOSS --> OPTIM["âš™ï¸ Optimization<br/>Mixed Precision | Gradient Clip<br/>LR Scheduler | Weight Decay"]

    OPTIM --> BACKWARD["ğŸ”™ Backward Pass<br/>Gradient Computation<br/>Parameter Updates"]

    BACKWARD --> EVAL["ğŸ“Š Evaluation<br/>Training Metrics<br/>Validation Loss<br/>Checkpointing"]

    EVAL --> OUTPUT["ğŸ“¤ Output<br/>Trained Model<br/>Checkpoints"]

    EVAL --> SAFETY["ğŸ›¡ï¸ Safety Integration<br/>Constitutional AI<br/>Principles Check"]

    SAFETY --> FILTER["ğŸš« Safety Filter<br/>Output Validation<br/>Alignment Check"]

    FILTER --> OUTPUT

    style INPUT fill:#e3f2fd,stroke:#01579b
    style OUTPUT fill:#e3f2fd,stroke:#01579b
    style MODEL fill:#c8e6c9,stroke:#1b5e20
    style LOSS fill:#ffccbc,stroke:#bf360c
    style OPTIM fill:#d1c4e9,stroke:#512da8
    style SAFETY fill:#f8bbd0,stroke:#880e4f
    style LOADER fill:#fff9c4,stroke:#f57f17
    style PREPROCESS fill:#fff9c4,stroke:#f57f17
    style FEATURES fill:#fce4ec,stroke:#c2185b
```

---

## Diagram 3: Problem Areas Heat Map (Copy-Paste Ready)

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#ffebee', 'primaryBorderColor': '#c62828'}}}%%
graph TD
    SCORE["âš ï¸ Architecture Quality Score: 5.5/10<br/>FUNCTIONAL BUT NEEDS REFACTORING"]

    SCORE --> LOSS_ISSUE["ğŸ”´ CRITICAL: Loss Functions<br/>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<br/>â€¢ 21 classes in 20 files<br/>â€¢ 35% code duplication<br/>â€¢ Duplicated DecoupledContrastiveLoss<br/>â€¢ SimpleContrastiveLoss in factory<br/>â€¢ No inheritance hierarchy<br/>â€¢ 240KB of code<br/><br/>IMPACT: 4-hour cost per new loss"]

    SCORE --> TRAINER_ISSUE["ğŸ”´ CRITICAL: Trainer God Object<br/>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<br/>â€¢ multimodal_trainer.py: 2,927 lines<br/>â€¢ 8 trainers with 60% duplication<br/>â€¢ No base trainer class<br/>â€¢ Mixed responsibilities<br/>â€¢ Violates SRP<br/><br/>IMPACT: Difficult to understand, maintain"]

    SCORE --> CONFIG_ISSUE["ğŸŸ  HIGH: Configuration Chaos<br/>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<br/>â€¢ 4 different approaches<br/>â€¢ Dataclasses + argparse + dicts<br/>â€¢ No single source of truth<br/>â€¢ Config mutations throughout<br/>â€¢ Inconsistent naming<br/><br/>IMPACT: Configuration bugs, parameter mismatches"]

    SCORE --> DUP_ISSUE["ğŸŸ  HIGH: Code Duplication<br/>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<br/>â€¢ 35-60% duplication<br/>â€¢ Copy-paste implementations<br/>â€¢ Weak base classes<br/>â€¢ Similar patterns everywhere<br/>â€¢ Hard to maintain consistency<br/><br/>IMPACT: Changes propagate slowly"]

    LOSS_ISSUE --> FIX1["âœ… Fix Available<br/>Time: 3-4 days<br/>Effort: Moderate<br/>Impact: 67% reduction<br/>Priority: CRITICAL"]

    TRAINER_ISSUE --> FIX2["âœ… Fix Available<br/>Time: 4-5 days<br/>Effort: High<br/>Impact: 60% reduction<br/>Priority: CRITICAL"]

    CONFIG_ISSUE --> FIX3["âœ… Fix Available<br/>Time: 2-3 days<br/>Effort: Moderate<br/>Impact: Consistency<br/>Priority: HIGH"]

    DUP_ISSUE --> FIX4["âœ… Fix Available<br/>Time: 5-7 days<br/>Effort: High<br/>Impact: Maintainability<br/>Priority: HIGH"]

    FIX1 --> ROADMAP["ğŸ“Š 8-WEEK REFACTORING ROADMAP<br/>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<br/>Phase 1 (Week 1): Foundation (40h)<br/>Phase 2 (Weeks 2-3): Consolidation (120h)<br/>Phase 3 (Weeks 4-5): Enhancement (80h)<br/>Phase 4 (Weeks 6-8): Stabilization (40h)<br/><br/>TOTAL: 260 hours | ROI: 270% Year 1"]

    FIX2 --> ROADMAP
    FIX3 --> ROADMAP
    FIX4 --> ROADMAP

    ROADMAP --> METRICS["ğŸ“ˆ PROJECTED IMPROVEMENTS<br/>â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”<br/>Largest file: 2,927 â†’ <800 lines<br/>Duplication: 35% â†’ <10%<br/>Test coverage: 60% â†’ 85%<br/>Complexity: >50 â†’ <15<br/>Add feature: 4h â†’ 30min<br/>Code review: 2h â†’ 20min<br/>Onboarding: 2-3w â†’ 3-5d"]

    style SCORE fill:#ffebee
    style LOSS_ISSUE fill:#c62828,color:#fff
    style TRAINER_ISSUE fill:#c62828,color:#fff
    style CONFIG_ISSUE fill:#f57c00,color:#fff
    style DUP_ISSUE fill:#f57c00,color:#fff
    style FIX1 fill:#4caf50,color:#fff
    style FIX2 fill:#4caf50,color:#fff
    style FIX3 fill:#4caf50,color:#fff
    style FIX4 fill:#4caf50,color:#fff
    style ROADMAP fill:#2196f3,color:#fff
    style METRICS fill:#a5d6a7
```

---

## Diagram 4: Timeline Gantt (Copy-Paste Ready)

```mermaid
gantt
    title 8-Week Refactoring Roadmap - Implementation Timeline
    dateFormat YYYY-MM-DD

    section Critical Foundation
    Week 1 - Remove Duplication :crit, fund1, 2025-11-07, 2d
    Week 1 - Extract SimpleContrastiveLoss :crit, fund2, after fund1, 1d
    Week 1 - Create BaseTrainer :crit, fund3, after fund2, 3d
    Foundation Testing :fund4, after fund3, 1d

    section Consolidation Phase
    Design Loss Hierarchy :cons1, 2025-11-17, 2d
    Refactor Loss Functions :crit, cons2, after cons1, 5d
    Decompose Trainers :crit, cons3, after cons2, 3d
    Unify Configuration :cons4, after cons3, 3d
    Consolidation Testing :cons5, after cons4, 2d

    section Enhancement Phase
    Template Method Pattern :enh1, 2025-12-01, 5d
    Repository Pattern :enh2, after enh1, 5d
    Callback System :enh3, after enh2, 3d
    Architecture Documentation :enh4, after enh3, 2d
    Enhancement Testing :enh5, after enh4, 2d

    section Stabilization
    Performance Benchmarks :stab1, 2025-12-15, 3d
    Documentation Updates :stab2, after stab1, 3d
    Team Training :stab3, after stab2, 2d
    Production Readiness :stab4, after stab3, 2d

    section Milestones
    Foundation Complete :milestone, m1, after fund4, 0d
    50% Code Reduction Achieved :milestone, m2, after cons5, 0d
    Modern Architecture Ready :milestone, m3, after enh5, 0d
    Production Ready :milestone, m4, after stab4, 0d
```

---

## Diagram 5: Proposed Architecture (Copy-Paste Ready)

```mermaid
%%{init: {'theme': 'default'}}%%
graph LR
    INPUT["ğŸ“¥ Input Data<br/>Text | Images | Sequences"]

    INPUT --> PIPE["ğŸ”„ Pipeline<br/>Orchestrator<br/>Coordinates stages"]

    PIPE --> DATA_REPO["ğŸ’¾ Data Repository<br/>Abstraction Layer"]

    DATA_REPO --> LOADER["ğŸ“‚ Loader Strategy<br/>load_wmt()<br/>load_flickr30k()<br/>load_opensubtitles()"]

    DATA_REPO --> PREPROC["ğŸ”§ Preprocessing<br/>Chain Pattern<br/>Composable steps"]

    LOADER --> FEAT["âš™ï¸ Features<br/>Repository<br/>Embeddings, IDs"]

    PREPROC --> FEAT

    FEAT --> MODEL["ğŸ§  Model Layer<br/>Unified Interface"]

    MODEL --> BASEMODEL["ğŸ“‹ BaseModel<br/>Template Methods<br/>Shared Logic<br/>~200 lines"]

    BASEMODEL --> ENC["ğŸ”€ Encoder<br/>Text + Image<br/>Attention Stack"]

    BASEMODEL --> FUSION["ğŸ”— Fusion<br/>Cross-Modal<br/>Projection"]

    BASEMODEL --> DEC["ğŸ“¤ Decoder<br/>Output Head<br/>Generation"]

    ENC --> TRAIN["ğŸ‹ï¸ Training Layer<br/>Unified Interface"]

    FUSION --> TRAIN

    DEC --> TRAIN

    TRAIN --> BASETRAINER["ğŸ“‹ BaseTrainer<br/>Template Method<br/>Shared Training<br/>~300 lines"]

    BASETRAINER --> SPECIFIC["ğŸ¯ Specific Trainers<br/>MultimodalTrainer<br/>LanguageTrainer<br/>VisionTrainer<br/><500 lines each"]

    ENC --> LOSS["ğŸ’£ Loss Layer<br/>Inheritance Tree"]

    FUSION --> LOSS

    LOSS --> BASELOSS["ğŸ“‹ BaseLoss<br/>Abstract Base<br/>Shared Interface"]

    BASELOSS --> CONTLOSS["ğŸ”— ContrastiveLossBase<br/>Shared Logic<br/>~100 lines"]

    CONTLOSS --> SPECLOSS["ğŸ¯ Specialized Losses<br/>InfoNCE<br/>VICReg<br/>BarlowTwins<br/>Decoupled<br/>~50 lines each"]

    SPECIFIC --> LOSS

    LOSS --> OPTIM["âš™ï¸ Optimization<br/>Strategy Pattern"]

    OPTIM --> OPT["ğŸ¯ Optimizer<br/>Strategies<br/>AdamW | SGD<br/>RAdam | Others"]

    OPT --> BACKWARD["ğŸ”™ Backward<br/>Gradient<br/>Management"]

    BACKWARD --> EVAL["ğŸ“Š Evaluation<br/>Repository"]

    EVAL --> METRICS["ğŸ“ˆ Metrics<br/>Repository<br/>Tracking"]

    METRICS --> CONFIG["âš™ï¸ Configuration<br/>Pydantic Models<br/>Single Source<br/>Type-Safe"]

    CONFIG --> SAFETY["ğŸ›¡ï¸ Safety<br/>Callback Pattern<br/>Hooks"]

    SAFETY --> CHECKS["ğŸ” Safety Checks<br/>Evaluator<br/>Filter<br/>Harness"]

    CHECKS --> OUTPUT["ğŸ“¤ Output<br/>Trained Model<br/>Artifacts"]

    style INPUT fill:#e3f2fd
    style OUTPUT fill:#e3f2fd
    style BASEMODEL fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
    style BASETRAINER fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    style BASELOSS fill:#ffccbc,stroke:#bf360c,stroke-width:2px
    style CONTLOSS fill:#ffccbc,stroke:#bf360c,stroke-width:2px
    style SPECLOSS fill:#ffccbc,stroke:#bf360c
    style SPECIFIC fill:#fff9c4
    style DATA_REPO fill:#f3e5f5
    style CONFIG fill:#b3e5fc
    style SAFETY fill:#f8bbd0
```

---

## Diagram 6: Data Flow (Copy-Paste Ready)

```mermaid
%%{init: {'theme': 'default'}}%%
graph TD
    START["ğŸŸ¢ START<br/>Raw Dataset<br/>Files | Streams | APIs"]

    START --> SELECT["ğŸ” Select Source<br/>WMT | Flickr30K<br/>OpenSubtitles | Wikipedia<br/>Custom Dataset"]

    SELECT --> LOAD["ğŸ“‚ Load Data<br/>DataLoader Class<br/>Read files<br/>Batch preparation"]

    LOAD --> CACHE["ğŸ’¾ Cache Check<br/>Avoid reprocessing<br/>Speed up iteration"]

    CACHE --> TOKENIZE["ğŸ”¤ Tokenization<br/>BPE Tokenizer<br/>Text â†’ Token IDs<br/>Vocabulary build"]

    TOKENIZE --> CHECKLEN{"Token Count<br/>Valid?"}

    CHECKLEN -->|Too Long| TRUNC["âœ‚ï¸ Truncate<br/>Max sequence<br/>length"]

    CHECKLEN -->|Too Short| PAD["â• Pad<br/>Add pad tokens<br/>Attention masks"]

    CHECKLEN -->|OK| DONE1["âœ… Tokens"]

    TRUNC --> DONE1
    PAD --> DONE1

    DONE1 --> ENCODE["ğŸ”— Encoding<br/>Create embeddings<br/>Position IDs<br/>Segment IDs"]

    ENCODE --> AUGMENT["ğŸ¨ Augmentation<br/>Random crops<br/>Color jitter<br/>Text perturbation<br/>Mixup"]

    AUGMENT --> CURRK["ğŸ“š Curriculum<br/>Easy â†’ Hard<br/>Progressive difficulty<br/>Sample reweighting"]

    CURRK --> BATCH["ğŸ“¦ Batching<br/>Group samples<br/>Tensor prep<br/>GPU transfer"]

    BATCH --> FWD["â¬œ Forward Pass<br/>Text Encoder<br/>+ Image Encoder<br/>+ Fusion Module<br/>+ Projection"]

    FWD --> LOSS_CALC["ğŸ’£ Loss Compute<br/>Select loss:<br/>InfoNCE | VICReg<br/>Contrastive | etc<br/>Calculate scalar loss"]

    LOSS_CALC --> CHECKVAL{"Loss<br/>Valid?"}

    CHECKVAL -->|NaN/Inf| DBG["ğŸ› Debug<br/>Check gradients<br/>Log stats<br/>Diagnose issue"]

    DBG --> CHECKVAL

    CHECKVAL -->|OK| BWD["â¬…ï¸ Backward<br/>Compute gradients<br/>Gradient clip<br/>Accumulation"]

    BWD --> OPT["ğŸ”§ Optimizer Step<br/>Update params<br/>LR schedule<br/>Weight decay"]

    OPT --> METRIK["ğŸ“Š Update Metrics<br/>Track loss<br/>Accuracy<br/>Custom metrics"]

    METRIK --> EPCHECK{"Epoch<br/>Complete?"}

    EPCHECK -->|No| BATCH
    EPCHECK -->|Yes| VAL["âœ… Validation<br/>Disable grad<br/>Full val set<br/>Compute metrics"]

    VAL --> VAL_MET["ğŸ“ˆ Val Metrics<br/>Val loss<br/>Val accuracy<br/>Compare baseline"]

    VAL_MET --> CKPT_CHK{"New Best<br/>Checkpoint?"}

    CKPT_CHK -->|Yes| SAVE["ğŸ’¾ Save<br/>Model weights<br/>Optimizer state<br/>Metrics"]

    CKPT_CHK -->|No| SAFE_CHK

    SAVE --> SAFE_CHK["ğŸ›¡ï¸ Safety Check<br/>Constitutional AI<br/>Run evaluator<br/>Check principles<br/>Filter output"]

    SAFE_CHK --> STOP_CHK{"Early Stop<br/>Triggered?"}

    STOP_CHK -->|Yes| TRAIN_END

    STOP_CHK -->|No| FINAL_CHK{"All Epochs<br/>Complete?"}

    FINAL_CHK -->|No| BATCH
    FINAL_CHK -->|Yes| TRAIN_END["ğŸŸ¢ END<br/>Model Ready<br/>Checkpoints Saved<br/>Metrics Logged"]

    style START fill:#c8e6c9
    style TRAIN_END fill:#c8e6c9
    style FWD fill:#c8e6c9
    style LOSS_CALC fill:#ffccbc
    style BWD fill:#ffccbc
    style OPT fill:#d1c4e9
    style VAL fill:#fff9c4
    style SAFE_CHK fill:#f8bbd0
    style BATCH fill:#fce4ec
    style TOKENIZE fill:#f3e5f5
```

---

## Diagram 7: Testing Coverage Map (Copy-Paste Ready)

```mermaid
%%{init: {'theme': 'default'}}%%
graph TD
    OVERVIEW["ğŸ§ª Testing Coverage Analysis<br/>Current: 60% | Target: 85% | Effort: 60h"]

    OVERVIEW --> DATA["ğŸ“Š Data Layer<br/>Coverage: 65%<br/>âœ… Loaders tested<br/>âœ… Preprocessing tested<br/>âŒ Augmentation gaps<br/>âŒ Edge cases<br/>ğŸ¯ Target: 85%"]

    OVERVIEW --> MODELS["ğŸ§  Models<br/>Coverage: 70%<br/>âœ… Attention: 90%<br/>âœ… Feed Forward: 85%<br/>âœ… Transformer: 80%<br/>âŒ Fusion gaps<br/>âŒ Integration gaps<br/>ğŸ¯ Target: 90%"]

    OVERVIEW --> LOSSES["ğŸ’£ Losses<br/>Coverage: 55% âš ï¸<br/>âœ… Basic tests exist<br/>âŒ All 21 losses not tested<br/>âŒ Edge cases<br/>âŒ Gradient checks<br/>âŒ Numerical stability<br/>ğŸ¯ Target: 90%"]

    OVERVIEW --> TRAINERS["ğŸ‹ï¸ Trainers<br/>Coverage: 45% âš ï¸<br/>âŒ Integration gaps<br/>âŒ Multi-stage untested<br/>âŒ Checkpoint tests<br/>âŒ Error recovery<br/>ğŸ¯ Target: 85%"]

    OVERVIEW --> SAFETY["ğŸ›¡ï¸ Safety<br/>Coverage: 80%<br/>âœ… Evaluator: 85%<br/>âœ… Filter: 80%<br/>âœ… Principles: 90%<br/>âŒ Integration gaps<br/>ğŸ¯ Target: 90%"]

    OVERVIEW --> OPTIM["âš¡ Optimization<br/>Coverage: 60%<br/>âœ… Optimizers: 70%<br/>âŒ Mixed precision<br/>âŒ Quantization<br/>âŒ Pruning<br/>ğŸ¯ Target: 80%"]

    OVERVIEW --> UTILS["ğŸ”§ Utils<br/>Coverage: 75%<br/>âœ… Config: 80%<br/>âœ… Logging: 75%<br/>âŒ Profiling<br/>âŒ Visualization<br/>ğŸ¯ Target: 85%"]

    DATA --> DATA_PLAN["ğŸ“‹ Action Plan<br/>1. Augmentation edge cases (4h)<br/>2. Tokenizer stress tests (3h)<br/>3. Combined datasets (3h)<br/>4. Curriculum learning (4h)<br/>ğŸ“ˆ Gain: +20%"]

    MODELS --> MODEL_PLAN["ğŸ“‹ Action Plan<br/>1. Fusion module (5h)<br/>2. Cross-modal attention (3h)<br/>3. Multi-stage integration (4h)<br/>4. Gradient validation (3h)<br/>ğŸ“ˆ Gain: +20%"]

    LOSSES --> LOSS_PLAN["ğŸ“‹ Action Plan<br/>1. All 21 loss tests (10h)<br/>2. Gradient checks (5h)<br/>3. Stability tests (4h)<br/>4. Batch size tests (3h)<br/>ğŸ“ˆ Gain: +35% â­"]

    TRAINERS --> TRAIN_PLAN["ğŸ“‹ Action Plan<br/>1. Full integration (8h)<br/>2. Checkpoint tests (4h)<br/>3. Multi-stage pipeline (6h)<br/>4. Error recovery (3h)<br/>ğŸ“ˆ Gain: +40% â­"]

    SAFETY --> SAFE_PLAN["ğŸ“‹ Action Plan<br/>1. Integration tests (4h)<br/>2. End-to-end tests (3h)<br/>3. Edge case principles (3h)<br/>ğŸ“ˆ Gain: +10%"]

    OPTIM --> OPT_PLAN["ğŸ“‹ Action Plan<br/>1. Mixed precision (5h)<br/>2. Quantization (4h)<br/>3. Pruning verification (3h)<br/>ğŸ“ˆ Gain: +20%"]

    UTILS --> UTIL_PLAN["ğŸ“‹ Action Plan<br/>1. Profiling suite (3h)<br/>2. Visualization tests (2h)<br/>3. Error handling (2h)<br/>ğŸ“ˆ Gain: +10%"]

    DATA_PLAN --> TIMELINE["â±ï¸ Implementation<br/>Week 1-2: Data + Models (20h)<br/>Week 3-4: Losses + Trainers (30h)<br/>Week 5: Safety + Utils (10h)<br/>Total: 4-5 weeks<br/>2-3 hours/day"]

    MODEL_PLAN --> TIMELINE
    LOSS_PLAN --> TIMELINE
    TRAIN_PLAN --> TIMELINE
    SAFE_PLAN --> TIMELINE
    OPT_PLAN --> TIMELINE
    UTIL_PLAN --> TIMELINE

    TIMELINE --> RESULT["âœ… Result<br/>Coverage: 60% â†’ 85%<br/>+25% improvement<br/>60 hours effort<br/>ROI: Faster development"]

    style OVERVIEW fill:#f3e5f5
    style DATA fill:#fff9c4
    style MODELS fill:#c8e6c9
    style LOSSES fill:#ffccbc
    style TRAINERS fill:#ffe0b2
    style SAFETY fill:#f8bbd0
    style OPTIM fill:#d1c4e9
    style UTILS fill:#b3e5fc
    style LOSS_PLAN fill:#ffccbc,stroke:#bf360c,stroke-width:2px
    style TRAIN_PLAN fill:#ffe0b2,stroke:#e65100,stroke-width:2px
    style RESULT fill:#a5d6a7
```

---

## Quick Reference: Rendering & Exporting

### Render Online
1. Visit: [Mermaid Live Editor](https://mermaid.live)
2. Copy any diagram from above
3. Paste into editor
4. Export as PNG/SVG

### GitHub Integration
These diagrams render automatically in GitHub markdown files.

### PowerPoint/Presentations
1. Render in Mermaid Live Editor
2. Right-click â†’ Save as image
3. Insert into PowerPoint
4. Recommended: Use SVG format for best quality

### Documentation
Copy entire markdown blocks into:
- Confluence
- Notion
- GitHub Wiki
- Any Mermaid-compatible platform

### Custom Styling
Edit the `%%{init: {...}}%%` block at the start of any diagram:

```mermaid
%%{init: {
  'theme': 'default',           // Options: default, dark, forest, neutral
  'themeVariables': {
    'primaryColor': '#e1f5ff',
    'fontSize': '12px',
    'fontFamily': 'arial'
  }
}}}%%
```

---

## Theme Options

### Default Theme
```
'theme': 'default'
primaryColor: '#e1f5ff'
```

### Dark Theme
```
'theme': 'dark'
primaryColor: '#1a1a1a'
```

### Forest Theme
```
'theme': 'forest'
primaryColor: '#2b6b2d'
```

### Neutral Theme
```
'theme': 'neutral'
primaryColor: '#f0f0f0'
```

---

## Size & Resolution Tips

### For Screen Display
- Use theme: 'default'
- Font size: 12-14px
- Optimal width: 1200px

### For Printing
- Use theme: 'neutral'
- Font size: 11px
- Render at 300 DPI

### For Presentations
- Use theme: 'dark'
- Font size: 14-16px
- Consider contrast with slide background

---

## Integration Examples

### In Markdown Files
```markdown
## Architecture Overview

```mermaid
[Copy diagram code here]
```

### In GitHub Issues
```
[Paste diagram markdown directly into comment]
```

### In Confluence
1. Use Mermaid for Confluence plugin
2. Paste diagram code into plugin
3. Plugin renders automatically

---

## Diagram Summary Table

| # | Name | Type | Complexity | Best For |
|---|------|------|-----------|----------|
| 1 | Repository Structure | Graph | Low | Understanding codebase layout |
| 2 | Current Architecture | Flow | Medium | Component relationships |
| 3 | Problem Areas | Heat Map | Medium | Identifying issues |
| 4 | Gantt Timeline | Gantt | High | Project planning |
| 5 | Proposed Architecture | Flow | High | Future state design |
| 6 | Data Flow | Flow | Very High | Pipeline understanding |
| 7 | Testing Coverage | Graph | Medium | Testing strategy |

---

## Maintenance Notes

**Last Generated**: 2025-11-07
**Based on**: ARCHITECTURE_SUMMARY.md, ARCHITECTURE_QUICK_FIXES.md
**Next Update**: After refactoring Phase 1 completion

To update diagrams:
1. Edit the `.md` files with new data
2. Regenerate diagrams
3. Update this reference document
4. Commit all changes

---

## Support & Questions

For questions about:
- **Rendering**: See "Quick Reference" section
- **Customization**: See "Theme Options" section
- **Integration**: See "Integration Examples" section
- **Architecture**: See VISUAL_ARCHITECTURE_DIAGRAMS.md

All diagrams are maintained in:
- `/docs/VISUAL_ARCHITECTURE_DIAGRAMS.md` (full versions)
- `/docs/MERMAID_DIAGRAMS_REFERENCE.md` (this file, styled versions)

---

**Document Purpose**: Provide copy-paste ready, styled Mermaid diagrams for easy rendering and presentation
**Format**: Markdown with embedded Mermaid code blocks
**Audience**: Technical team, project managers, stakeholders
