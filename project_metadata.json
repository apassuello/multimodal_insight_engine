{
  "project_name": "MultiModal Insight Engine",
  "directory_structure": {
    "name": "src",
    "type": "directory",
    "children": [
      {
        "name": "optimization",
        "type": "directory",
        "children": [
          {
            "name": "mixed_precision.py",
            "type": "file",
            "path": "src/optimization/mixed_precision.py"
          },
          {
            "name": "quantization.py",
            "type": "file",
            "path": "src/optimization/quantization.py"
          },
          {
            "name": "pruning.py",
            "type": "file",
            "path": "src/optimization/pruning.py"
          },
          {
            "name": "benchmarking.py",
            "type": "file",
            "path": "src/optimization/benchmarking.py"
          }
        ]
      },
      {
        "name": "training",
        "type": "directory",
        "children": [
          {
            "name": "losses",
            "type": "directory",
            "children": [
              {
                "name": "multimodal_mixed_contrastive_loss.py",
                "type": "file",
                "path": "src/training/losses/multimodal_mixed_contrastive_loss.py"
              },
              {
                "name": "loss_factory.py",
                "type": "file",
                "path": "src/training/losses/loss_factory.py"
              },
              {
                "name": "vicreg_loss.py",
                "type": "file",
                "path": "src/training/losses/vicreg_loss.py"
              },
              {
                "name": "multitask_loss.py",
                "type": "file",
                "path": "src/training/losses/multitask_loss.py"
              },
              {
                "name": "contrastive_learning.py",
                "type": "file",
                "path": "src/training/losses/contrastive_learning.py"
              },
              {
                "name": "memory_queue_contrastive_loss.py",
                "type": "file",
                "path": "src/training/losses/memory_queue_contrastive_loss.py"
              },
              {
                "name": "supervised_contrastive_loss.py",
                "type": "file",
                "path": "src/training/losses/supervised_contrastive_loss.py"
              },
              {
                "name": "decoupled_contrastive_loss.py",
                "type": "file",
                "path": "src/training/losses/decoupled_contrastive_loss.py"
              },
              {
                "name": "barlow_twins_loss.py",
                "type": "file",
                "path": "src/training/losses/barlow_twins_loss.py"
              },
              {
                "name": "combined_loss.py",
                "type": "file",
                "path": "src/training/losses/combined_loss.py"
              },
              {
                "name": "hard_negative_mining_contrastive_loss.py",
                "type": "file",
                "path": "src/training/losses/hard_negative_mining_contrastive_loss.py"
              },
              {
                "name": "ema_moco_loss.py",
                "type": "file",
                "path": "src/training/losses/ema_moco_loss.py"
              },
              {
                "name": "contrastive_loss.py",
                "type": "file",
                "path": "src/training/losses/contrastive_loss.py"
              },
              {
                "name": "hybrid_pretrain_vicreg_loss.py",
                "type": "file",
                "path": "src/training/losses/hybrid_pretrain_vicreg_loss.py"
              },
              {
                "name": "clip_style_loss.py",
                "type": "file",
                "path": "src/training/losses/clip_style_loss.py"
              },
              {
                "name": "feature_consistency_loss.py",
                "type": "file",
                "path": "src/training/losses/feature_consistency_loss.py"
              },
              {
                "name": "losses.py",
                "type": "file",
                "path": "src/training/losses/losses.py"
              },
              {
                "name": "decorrelation_loss.py",
                "type": "file",
                "path": "src/training/losses/decorrelation_loss.py"
              },
              {
                "name": "dynamic_temperature_contrastive_loss.py",
                "type": "file",
                "path": "src/training/losses/dynamic_temperature_contrastive_loss.py"
              }
            ]
          },
          {
            "name": "metrics.py",
            "type": "file",
            "path": "src/training/metrics.py"
          },
          {
            "name": "flickr_multistage_training.py",
            "type": "file",
            "path": "src/training/flickr_multistage_training.py"
          },
          {
            "name": "strategies",
            "type": "directory",
            "children": [
              {
                "name": "single_modality_strategy.py",
                "type": "file",
                "path": "src/training/strategies/single_modality_strategy.py"
              },
              {
                "name": "training_strategy.py",
                "type": "file",
                "path": "src/training/strategies/training_strategy.py"
              },
              {
                "name": "end_to_end_strategy.py",
                "type": "file",
                "path": "src/training/strategies/end_to_end_strategy.py"
              },
              {
                "name": "cross_modal_strategy.py",
                "type": "file",
                "path": "src/training/strategies/cross_modal_strategy.py"
              }
            ]
          },
          {
            "name": "transformer_utils.py",
            "type": "file",
            "path": "src/training/transformer_utils.py"
          },
          {
            "name": "trainers",
            "type": "directory",
            "children": [
              {
                "name": "multistage_trainer.py",
                "type": "file",
                "path": "src/training/trainers/multistage_trainer.py"
              },
              {
                "name": "vision_transformer_trainer.py",
                "type": "file",
                "path": "src/training/trainers/vision_transformer_trainer.py"
              },
              {
                "name": "language_model_trainer.py",
                "type": "file",
                "path": "src/training/trainers/language_model_trainer.py"
              },
              {
                "name": "trainer_factory.py",
                "type": "file",
                "path": "src/training/trainers/trainer_factory.py"
              },
              {
                "name": "transformer_trainer.py",
                "type": "file",
                "path": "src/training/trainers/transformer_trainer.py"
              },
              {
                "name": "trainer.py",
                "type": "file",
                "path": "src/training/trainers/trainer.py"
              },
              {
                "name": "multimodal_trainer.py",
                "type": "file",
                "path": "src/training/trainers/multimodal_trainer.py"
              }
            ]
          },
          {
            "name": "optimizers.py",
            "type": "file",
            "path": "src/training/optimizers.py"
          },
          {
            "name": "joint_bpe_training.py",
            "type": "file",
            "path": "src/training/joint_bpe_training.py"
          }
        ]
      },
      {
        "name": "utils",
        "type": "directory",
        "children": [
          {
            "name": "model_utils.py",
            "type": "file",
            "path": "src/utils/model_utils.py"
          },
          {
            "name": "logging.py",
            "type": "file",
            "path": "src/utils/logging.py"
          },
          {
            "name": "argument_configs.py",
            "type": "file",
            "path": "src/utils/argument_configs.py"
          },
          {
            "name": "learningrate_scheduler.py",
            "type": "file",
            "path": "src/utils/learningrate_scheduler.py"
          },
          {
            "name": "config.py",
            "type": "file",
            "path": "src/utils/config.py"
          },
          {
            "name": "feature_attribution.py",
            "type": "file",
            "path": "src/utils/feature_attribution.py"
          },
          {
            "name": "metrics_tracker.py",
            "type": "file",
            "path": "src/utils/metrics_tracker.py"
          },
          {
            "name": "gradient_manager.py",
            "type": "file",
            "path": "src/utils/gradient_manager.py"
          },
          {
            "name": "visualization.py",
            "type": "file",
            "path": "src/utils/visualization.py"
          },
          {
            "name": "list_models.py",
            "type": "file",
            "path": "src/utils/list_models.py"
          },
          {
            "name": "gradient_handler.py",
            "type": "file",
            "path": "src/utils/gradient_handler.py"
          },
          {
            "name": "profiling.py",
            "type": "file",
            "path": "src/utils/profiling.py"
          }
        ]
      },
      {
        "name": "models",
        "type": "directory",
        "children": [
          {
            "name": "attention.py",
            "type": "file",
            "path": "src/models/attention.py"
          },
          {
            "name": "activations.py",
            "type": "file",
            "path": "src/models/activations.py"
          },
          {
            "name": "feed_forward.py",
            "type": "file",
            "path": "src/models/feed_forward.py"
          },
          {
            "name": "vision",
            "type": "directory",
            "children": [
              {
                "name": "image_preprocessing.py",
                "type": "file",
                "path": "src/models/vision/image_preprocessing.py"
              },
              {
                "name": "vision_transformer.py",
                "type": "file",
                "path": "src/models/vision/vision_transformer.py"
              },
              {
                "name": "patch_embedding.py",
                "type": "file",
                "path": "src/models/vision/patch_embedding.py"
              }
            ]
          },
          {
            "name": "base_model.py",
            "type": "file",
            "path": "src/models/base_model.py"
          },
          {
            "name": "multimodal",
            "type": "directory",
            "children": [
              {
                "name": "multimodal_decoder_generation.py",
                "type": "file",
                "path": "src/models/multimodal/multimodal_decoder_generation.py"
              },
              {
                "name": "multimodal_integration.py",
                "type": "file",
                "path": "src/models/multimodal/multimodal_integration.py"
              },
              {
                "name": "vicreg_multimodal_model.py",
                "type": "file",
                "path": "src/models/multimodal/vicreg_multimodal_model.py"
              },
              {
                "name": "bidirectional_cross_attention.py",
                "type": "file",
                "path": "src/models/multimodal/bidirectional_cross_attention.py"
              },
              {
                "name": "co_attention_fusion.py",
                "type": "file",
                "path": "src/models/multimodal/co_attention_fusion.py"
              },
              {
                "name": "gated_cross_modal_attention.py",
                "type": "file",
                "path": "src/models/multimodal/gated_cross_modal_attention.py"
              },
              {
                "name": "clip_style_direct_projection.py",
                "type": "file",
                "path": "src/models/multimodal/clip_style_direct_projection.py"
              },
              {
                "name": "dual_encoder.py",
                "type": "file",
                "path": "src/models/multimodal/dual_encoder.py"
              },
              {
                "name": "cross_modal_attention_base.py",
                "type": "file",
                "path": "src/models/multimodal/cross_modal_attention_base.py"
              }
            ]
          },
          {
            "name": "embeddings.py",
            "type": "file",
            "path": "src/models/embeddings.py"
          },
          {
            "name": "transformer.py",
            "type": "file",
            "path": "src/models/transformer.py"
          },
          {
            "name": "text_generation.py",
            "type": "file",
            "path": "src/models/text_generation.py"
          },
          {
            "name": "layers.py",
            "type": "file",
            "path": "src/models/layers.py"
          },
          {
            "name": "model_factory.py",
            "type": "file",
            "path": "src/models/model_factory.py"
          },
          {
            "name": "pretrained",
            "type": "directory",
            "children": [
              {
                "name": "vision_transformer.py",
                "type": "file",
                "path": "src/models/pretrained/vision_transformer.py"
              },
              {
                "name": "huggingface_wrapper.py",
                "type": "file",
                "path": "src/models/pretrained/huggingface_wrapper.py"
              },
              {
                "name": "clip_model.py",
                "type": "file",
                "path": "src/models/pretrained/clip_model.py"
              },
              {
                "name": "base_wrapper.py",
                "type": "file",
                "path": "src/models/pretrained/base_wrapper.py"
              },
              {
                "name": "model_registry.py",
                "type": "file",
                "path": "src/models/pretrained/model_registry.py"
              },
              {
                "name": "adapters.py",
                "type": "file",
                "path": "src/models/pretrained/adapters.py"
              }
            ]
          },
          {
            "name": "positional.py",
            "type": "file",
            "path": "src/models/positional.py"
          }
        ]
      },
      {
        "name": "safety",
        "type": "directory",
        "children": [
          {
            "name": "harness.py",
            "type": "file",
            "path": "src/safety/harness.py"
          },
          {
            "name": "integration.py",
            "type": "file",
            "path": "src/safety/integration.py"
          },
          {
            "name": "utils.py",
            "type": "file",
            "path": "src/safety/utils.py"
          },
          {
            "name": "filter.py",
            "type": "file",
            "path": "src/safety/filter.py"
          },
          {
            "name": "evaluator.py",
            "type": "file",
            "path": "src/safety/evaluator.py"
          },
          {
            "name": "red_teaming",
            "type": "directory",
            "children": [
              {
                "name": "framework.py",
                "type": "file",
                "path": "src/safety/red_teaming/framework.py"
              },
              {
                "name": "generators.py",
                "type": "file",
                "path": "src/safety/red_teaming/generators.py"
              },
              {
                "name": "model_loader.py",
                "type": "file",
                "path": "src/safety/red_teaming/model_loader.py"
              },
              {
                "name": "prompt_injection.py",
                "type": "file",
                "path": "src/safety/red_teaming/prompt_injection.py"
              },
              {
                "name": "evaluator.py",
                "type": "file",
                "path": "src/safety/red_teaming/evaluator.py"
              }
            ]
          }
        ]
      },
      {
        "name": "configs",
        "type": "directory",
        "children": [
          {
            "name": "flickr30k_multistage_config.py",
            "type": "file",
            "path": "src/configs/flickr30k_multistage_config.py"
          },
          {
            "name": "training_config.py",
            "type": "file",
            "path": "src/configs/training_config.py"
          },
          {
            "name": "stage_config.py",
            "type": "file",
            "path": "src/configs/stage_config.py"
          }
        ]
      },
      {
        "name": "evaluation",
        "type": "directory",
        "children": [
          {
            "name": "translation_metrics.py",
            "type": "file",
            "path": "src/evaluation/translation_metrics.py"
          },
          {
            "name": "language_model_evaluation.py",
            "type": "file",
            "path": "src/evaluation/language_model_evaluation.py"
          },
          {
            "name": "inference_demo.py",
            "type": "file",
            "path": "src/evaluation/inference_demo.py"
          }
        ]
      },
      {
        "name": "data",
        "type": "directory",
        "children": [
          {
            "name": "wmt_dataset.py",
            "type": "file",
            "path": "src/data/wmt_dataset.py"
          },
          {
            "name": "curriculum_dataset.py",
            "type": "file",
            "path": "src/data/curriculum_dataset.py"
          },
          {
            "name": "image_dataset.py",
            "type": "file",
            "path": "src/data/image_dataset.py"
          },
          {
            "name": "augmentation_pipeline.py",
            "type": "file",
            "path": "src/data/augmentation_pipeline.py"
          },
          {
            "name": "wmt_dataloader.py",
            "type": "file",
            "path": "src/data/wmt_dataloader.py"
          },
          {
            "name": "combined_dataset.py",
            "type": "file",
            "path": "src/data/combined_dataset.py"
          },
          {
            "name": "augmentation.py",
            "type": "file",
            "path": "src/data/augmentation.py"
          },
          {
            "name": "iwslt_dataset.py",
            "type": "file",
            "path": "src/data/iwslt_dataset.py"
          },
          {
            "name": "language_modeling.py",
            "type": "file",
            "path": "src/data/language_modeling.py"
          },
          {
            "name": "europarl_dataset.py",
            "type": "file",
            "path": "src/data/europarl_dataset.py"
          },
          {
            "name": "combined_wmt_translation_dataset.py",
            "type": "file",
            "path": "src/data/combined_wmt_translation_dataset.py"
          },
          {
            "name": "combined_translation_dataset.py",
            "type": "file",
            "path": "src/data/combined_translation_dataset.py"
          },
          {
            "name": "multimodal_data_utils.py",
            "type": "file",
            "path": "src/data/multimodal_data_utils.py"
          },
          {
            "name": "tokenization",
            "type": "directory",
            "children": [
              {
                "name": "optimized_bpe_tokenizer.py",
                "type": "file",
                "path": "src/data/tokenization/optimized_bpe_tokenizer.py"
              },
              {
                "name": "base_tokenizer.py",
                "type": "file",
                "path": "src/data/tokenization/base_tokenizer.py"
              },
              {
                "name": "utils.py",
                "type": "file",
                "path": "src/data/tokenization/utils.py"
              },
              {
                "name": "preprocessing.py",
                "type": "file",
                "path": "src/data/tokenization/preprocessing.py"
              },
              {
                "name": "bert_tokenizer_adapter.py",
                "type": "file",
                "path": "src/data/tokenization/bert_tokenizer_adapter.py"
              },
              {
                "name": "bpe_tokenizer.py",
                "type": "file",
                "path": "src/data/tokenization/bpe_tokenizer.py"
              },
              {
                "name": "tokenizer_metrics.py",
                "type": "file",
                "path": "src/data/tokenization/tokenizer_metrics.py"
              },
              {
                "name": "vocabulary.py",
                "type": "file",
                "path": "src/data/tokenization/vocabulary.py"
              },
              {
                "name": "turbo_bpe_preprocessor.py",
                "type": "file",
                "path": "src/data/tokenization/turbo_bpe_preprocessor.py"
              },
              {
                "name": "simple_tokenizer.py",
                "type": "file",
                "path": "src/data/tokenization/simple_tokenizer.py"
              }
            ]
          },
          {
            "name": "fixed_semantic_sampler.py",
            "type": "file",
            "path": "src/data/fixed_semantic_sampler.py"
          },
          {
            "name": "multimodal_dataset.py",
            "type": "file",
            "path": "src/data/multimodal_dataset.py"
          },
          {
            "name": "preprocessing.py",
            "type": "file",
            "path": "src/data/preprocessing.py"
          },
          {
            "name": "sequence_data.py",
            "type": "file",
            "path": "src/data/sequence_data.py"
          },
          {
            "name": "opensubtitles_dataset.py",
            "type": "file",
            "path": "src/data/opensubtitles_dataset.py"
          },
          {
            "name": "dataloader.py",
            "type": "file",
            "path": "src/data/dataloader.py"
          },
          {
            "name": "dataset_wrapper.py",
            "type": "file",
            "path": "src/data/dataset_wrapper.py"
          },
          {
            "name": "wikipedia_dataset.py",
            "type": "file",
            "path": "src/data/wikipedia_dataset.py"
          }
        ]
      }
    ]
  },
  "modules": [
    {
      "filename": "mixed_precision.py",
      "module_purpose": "Converts models to use mixed precision formats for training and inference.",
      "key_classes": [
        {
          "name": "MixedPrecisionConverter",
          "purpose": "Converts models to use mixed precision formats.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, model: nn.Module, dtype: torch.dtype = torch.float16, use_auto_cast: bool = True)",
              "brief_description": "Initialize the mixed precision converter."
            },
            {
              "name": "convert_to_mixed_precision",
              "signature": "(self) -> nn.Module",
              "brief_description": "Convert the model to use mixed precision."
            },
            {
              "name": "restore_original_precision",
              "signature": "(self)",
              "brief_description": "Restore the model to its original precision."
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "typing",
            "logging"
          ]
        },
        {
          "name": "MixedPrecisionWrapper",
          "purpose": "Wrapper for mixed precision inference with autocast.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, model: nn.Module, dtype: torch.dtype = torch.float16)",
              "brief_description": "Initialize the mixed precision wrapper."
            },
            {
              "name": "forward",
              "signature": "(self, *args, **kwargs)",
              "brief_description": "Forward pass with automatic mixed precision."
            },
            {
              "name": "__getattr__",
              "signature": "(self, name)",
              "brief_description": "Delegate attribute access to the wrapped model."
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "typing",
            "logging"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing",
        "logging"
      ],
      "complexity_score": 5,
      "module_path": "src/optimization/mixed_precision.py"
    },
    {
      "filename": "quantization.py",
      "module_purpose": "Implements various quantization techniques for neural networks.",
      "key_classes": [
        {
          "name": "QuantizationConfig",
          "purpose": "Configuration class for model quantization settings.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, quantization_type: str = 'dynamic', dtype: Optional[torch.dtype] = None, quantize_weights: bool = True, quantize_activations: bool = True, bits: int = 8, symmetric: bool = False, per_channel: bool = False)",
              "brief_description": "Initialize quantization configuration."
            },
            {
              "name": "__str__",
              "signature": "(self) -> str",
              "brief_description": "String representation of the configuration."
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "typing"
          ]
        },
        {
          "name": "ModelOptimizer",
          "purpose": "Base class for model optimization techniques.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, model: nn.Module)",
              "brief_description": "Initialize the model optimizer."
            },
            {
              "name": "optimize",
              "signature": "(self) -> nn.Module",
              "brief_description": "Apply optimization to the model."
            },
            {
              "name": "restore_original",
              "signature": "(self)",
              "brief_description": "Restore the model to its original state."
            },
            {
              "name": "get_size_info",
              "signature": "(self) -> Dict[str, Any]",
              "brief_description": "Get information about model size before and after optimization."
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "typing",
            "logging"
          ]
        },
        {
          "name": "DynamicQuantizer",
          "purpose": "Implements dynamic quantization for PyTorch models.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, model: nn.Module, config: Optional[QuantizationConfig] = None, dtype: torch.dtype = torch.qint8, qconfig_spec: Optional[Dict[Type[nn.Module], Any]] = None)",
              "brief_description": "Initialize the dynamic quantizer."
            },
            {
              "name": "optimize",
              "signature": "(self) -> nn.Module",
              "brief_description": "Apply dynamic quantization to the model."
            },
            {
              "name": "_fuse_modules",
              "signature": "(self, model: nn.Module) -> nn.Module",
              "brief_description": "Fuse modules for improved quantization where applicable."
            }
          ],
          "inheritance": "ModelOptimizer",
          "dependencies": [
            "torch",
            "typing",
            "logging"
          ]
        },
        {
          "name": "StaticQuantizer",
          "purpose": "Implements static quantization for PyTorch models.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, model: nn.Module, config: Optional[QuantizationConfig] = None, calibration_loader: Optional[torch.utils.data.DataLoader] = None)",
              "brief_description": "Initialize the static quantizer."
            },
            {
              "name": "optimize",
              "signature": "(self) -> nn.Module",
              "brief_description": "Apply static quantization to the model."
            },
            {
              "name": "_calibrate_model",
              "signature": "(self, model: nn.Module)",
              "brief_description": "Calibrate the model for static quantization."
            },
            {
              "name": "_fuse_modules",
              "signature": "(self, model: nn.Module, fusion_patterns: Optional[List[Tuple[Type[nn.Module], ...]]] = None) -> nn.Module",
              "brief_description": "Fuse modules for improved quantization where applicable."
            }
          ],
          "inheritance": "ModelOptimizer",
          "dependencies": [
            "torch",
            "typing",
            "logging"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing",
        "logging"
      ],
      "complexity_score": 8,
      "module_path": "src/optimization/quantization.py"
    },
    {
      "filename": "pruning.py",
      "module_purpose": "Implements various pruning techniques for neural networks.",
      "key_classes": [
        {
          "name": "PruningConfig",
          "purpose": "Configuration class for model pruning settings.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, method: str = 'magnitude', amount: Union[float, int] = 0.2, dim: Optional[int] = None, n_iterations: int = 1, pruning_dims: Optional[List[str]] = None, sparsity_distribution: str = 'uniform', reinitialize: bool = False)",
              "brief_description": "Initialize pruning configuration."
            },
            {
              "name": "__str__",
              "signature": "(self) -> str",
              "brief_description": "String representation of the configuration."
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "typing"
          ]
        },
        {
          "name": "ModelPruner",
          "purpose": "Implements various pruning techniques for neural networks.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, model: nn.Module, config: Optional[PruningConfig] = None)",
              "brief_description": "Initialize the model pruner."
            },
            {
              "name": "prune_model",
              "signature": "(self) -> nn.Module",
              "brief_description": "Apply pruning to the model."
            },
            {
              "name": "restore_model",
              "signature": "(self)",
              "brief_description": "Restore the model to its original unpruned state."
            },
            {
              "name": "get_pruning_info",
              "signature": "(self) -> Dict[str, Any]",
              "brief_description": "Get information about pruning results."
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "typing",
            "logging"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing",
        "logging"
      ],
      "complexity_score": 7,
      "module_path": "src/optimization/pruning.py"
    },
    {
      "filename": "benchmarking.py",
      "module_purpose": "Provides a framework for measuring and comparing model optimization techniques.",
      "key_classes": [
        {
          "name": "OptimizationBenchmark",
          "purpose": "Framework for measuring and comparing model optimization techniques.",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "(self, model: nn.Module, input_generator: Callable[[int], Union[torch.Tensor, Dict[str, torch.Tensor]]], batch_sizes: List[int] = [1, 4, 16, 32], precision: float = 0.001, save_dir: str = 'benchmark_results')",
              "brief_description": "Initialize the optimization benchmark."
            },
            {
              "name": "benchmark_original_model",
              "signature": "(self) -> Dict[str, Any]",
              "brief_description": "Benchmark the original unoptimized model."
            },
            {
              "name": "benchmark_optimized_model",
              "signature": "(self, model: nn.Module, name: str) -> Dict[str, Any]",
              "brief_description": "Benchmark an optimized model."
            },
            {
              "name": "compare_optimizations",
              "signature": "(self, save_plot: bool = True) -> Dict[str, Any]",
              "brief_description": "Compare all benchmarked optimizations."
            },
            {
              "name": "save_results",
              "signature": "(self, filename: str = 'optimization_benchmark.json')",
              "brief_description": "Save benchmark results to a file."
            },
            {
              "name": "generate_report",
              "signature": "(self) -> str",
              "brief_description": "Generate a report of the benchmark results."
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "typing",
            "json",
            "os",
            "numpy",
            "matplotlib"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing",
        "json",
        "os",
        "numpy",
        "matplotlib"
      ],
      "complexity_score": 6,
      "module_path": "src/optimization/benchmarking.py"
    },
    {
      "filename": "metrics.py",
      "module_purpose": "Implements common training metrics for model evaluation with support for various tasks",
      "key_classes": [
        {
          "name": "Accuracy",
          "purpose": "Computes classification accuracy with support for top-k accuracy",
          "key_methods": [
            {
              "name": "update",
              "signature": "update(self, pred: torch.Tensor, target: torch.Tensor)",
              "brief_description": "Updates the accuracy metric with new predictions and targets"
            },
            {
              "name": "compute",
              "signature": "compute(self) -> float",
              "brief_description": "Computes the current accuracy value"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch"
          ]
        },
        {
          "name": "Perplexity",
          "purpose": "Computes perplexity for language models",
          "key_methods": [
            {
              "name": "update",
              "signature": "update(self, loss: torch.Tensor, num_tokens: int)",
              "brief_description": "Updates the perplexity metric with new loss values"
            },
            {
              "name": "compute",
              "signature": "compute(self) -> float",
              "brief_description": "Computes the current perplexity value"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "numpy"
          ]
        },
        {
          "name": "F1Score",
          "purpose": "Computes F1 score for classification tasks",
          "key_methods": [
            {
              "name": "update",
              "signature": "update(self, pred: torch.Tensor, target: torch.Tensor)",
              "brief_description": "Updates the F1 score metric with new predictions"
            },
            {
              "name": "compute",
              "signature": "compute(self) -> float",
              "brief_description": "Computes the current F1 score"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch"
          ]
        },
        {
          "name": "BLEUScore",
          "purpose": "Computes BLEU score for machine translation",
          "key_methods": [
            {
              "name": "update",
              "signature": "update(self, hypothesis: str, reference: str)",
              "brief_description": "Updates the BLEU score metric with new translations"
            },
            {
              "name": "compute",
              "signature": "compute(self) -> float",
              "brief_description": "Computes the current BLEU score"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "nltk"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "nltk"
      ],
      "complexity_score": 7,
      "module_path": "src/training/metrics.py"
    },
    {
      "filename": "flickr_multistage_training.py",
      "module_purpose": "Implements a three-stage training pipeline for multimodal vision-language models using the Flickr30k dataset",
      "key_classes": [
        {
          "name": "FlickrMultistageTrainer",
          "purpose": "Manages the three-stage training process with different optimization strategies for each stage",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model: nn.Module, data_root: str, output_dir: str = 'flickr30k', device: Optional[torch.device] = None, batch_size: int = 64, num_workers: int = 4, stage1_epochs: int = 30, stage2_epochs: int = 15, stage3_epochs: int = 15, image_size: int = 224, use_metadata: bool = True)",
              "brief_description": "Initialize the multistage trainer with model, data paths, and training configuration"
            },
            {
              "name": "train_stage1",
              "signature": "train_stage1(self)",
              "brief_description": "Run Stage 1: Modality-Specific Learning with focus on individual encoders"
            },
            {
              "name": "train_stage2",
              "signature": "train_stage2(self)",
              "brief_description": "Run Stage 2: Cross-Modal Fusion to align vision and text feature spaces"
            },
            {
              "name": "train_stage3",
              "signature": "train_stage3(self)",
              "brief_description": "Run Stage 3: End-to-End Fine-tuning of all components together"
            },
            {
              "name": "train_all_stages",
              "signature": "train_all_stages(self)",
              "brief_description": "Run all three training stages in sequence"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.optim",
            "EnhancedMultimodalDataset",
            "SemanticGroupBatchSampler"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "create_flickr30k_multistage_model",
          "signature": "create_flickr30k_multistage_model(vision_model: VisionTransformerWrapper, text_model: HuggingFaceTextModelWrapper, projection_dim: int = 512) -> VICRegMultimodalModel",
          "brief_description": "Create a multimodal model instance configured for Flickr30k multistage training"
        },
        {
          "name": "train_flickr30k_multistage",
          "signature": "train_flickr30k_multistage(data_root: str, output_dir: str = 'flickr30k', batch_size: int = 64, stage1_epochs: int = 30, stage2_epochs: int = 15, stage3_epochs: int = 15, vision_model: str = 'ViT-B/16', text_model: str = 'bert-base-uncased', embedding_dim: int = 512, use_metadata: bool = True)",
          "brief_description": "Top-level function to set up and run the complete multistage training pipeline"
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "matplotlib",
        "tqdm"
      ],
      "complexity_score": 9,
      "module_path": "src/training/flickr_multistage_training.py"
    },
    {
      "filename": "transformer_utils.py",
      "module_purpose": "Provides utility functions and classes for transformer model training, including attention masking and label smoothing",
      "key_classes": [
        {
          "name": "LabelSmoothing",
          "purpose": "Implements label smoothing loss for improved model generalization",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor",
              "brief_description": "Computes smoothed loss with proper handling of padding tokens"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "create_padding_mask",
          "signature": "create_padding_mask(seq: torch.Tensor, pad_idx: int) -> torch.Tensor",
          "brief_description": "Creates attention masks for padding tokens"
        },
        {
          "name": "create_causal_mask",
          "signature": "create_causal_mask(seq_len: int, device: torch.device) -> torch.Tensor",
          "brief_description": "Creates causal masks to prevent attending to future tokens"
        },
        {
          "name": "create_combined_mask",
          "signature": "create_combined_mask(seq: torch.Tensor, pad_idx: int) -> torch.Tensor",
          "brief_description": "Combines padding and causal masks for transformer attention"
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy"
      ],
      "complexity_score": 6,
      "module_path": "src/training/transformer_utils.py"
    },
    {
      "filename": "optimizers.py",
      "module_purpose": "Implements custom optimizers and learning rate schedulers for model training",
      "key_classes": [
        {
          "name": "AdamW",
          "purpose": "AdamW optimizer with improved weight decay handling and gradient clipping",
          "key_methods": [
            {
              "name": "step",
              "signature": "step(self, closure=None)",
              "brief_description": "Performs a single optimization step with optional gradient clipping"
            }
          ],
          "inheritance": "optim.AdamW",
          "dependencies": [
            "torch",
            "torch.optim"
          ]
        },
        {
          "name": "OneCycleLR",
          "purpose": "One-cycle learning rate scheduler for fast training",
          "key_methods": [
            {
              "name": "get_lr",
              "signature": "get_lr(self) -> List[float]",
              "brief_description": "Computes learning rates based on the one-cycle policy"
            },
            {
              "name": "step",
              "signature": "step(self, closure=None)",
              "brief_description": "Performs a scheduler step and updates learning rates"
            }
          ],
          "inheritance": "_LRScheduler",
          "dependencies": [
            "torch",
            "torch.optim.lr_scheduler"
          ]
        },
        {
          "name": "CosineAnnealingLR",
          "purpose": "Cosine annealing learning rate scheduler with warm restarts",
          "key_methods": [
            {
              "name": "get_lr",
              "signature": "get_lr(self) -> List[float]",
              "brief_description": "Computes learning rates based on cosine annealing"
            }
          ],
          "inheritance": "_LRScheduler",
          "dependencies": [
            "torch",
            "torch.optim.lr_scheduler"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 8,
      "module_path": "src/training/optimizers.py"
    },
    {
      "filename": "joint_bpe_training.py",
      "module_purpose": "Implements joint BPE tokenizer training for multilingual text processing in machine translation tasks",
      "key_classes": [],
      "key_functions": [
        {
          "name": "train_joint_bpe_tokenizer",
          "signature": "train_joint_bpe_tokenizer(src_texts: List[str], tgt_texts: List[str], vocab_size: int = 8000, min_frequency: int = 2, save_dir: str = 'models/tokenizers') -> BPETokenizer",
          "brief_description": "Trains a shared BPE tokenizer on combined source and target language texts"
        },
        {
          "name": "main",
          "signature": "main()",
          "brief_description": "Demonstrates the usage of joint BPE tokenizer training with example texts"
        }
      ],
      "external_dependencies": [
        "src.data.tokenization"
      ],
      "complexity_score": 3,
      "module_path": "src/training/joint_bpe_training.py"
    },
    {
      "filename": "multimodal_mixed_contrastive_loss.py",
      "module_purpose": "Implements a mixed contrastive loss combining multiple contrastive learning objectives for multimodal data",
      "key_classes": [
        {
          "name": "MultiModalMixedContrastiveLoss",
          "purpose": "Combines multiple contrastive learning objectives with configurable weights",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, temperature: float = 0.07, loss_weights: Optional[Dict[str, float]] = None)",
              "brief_description": "Initialize mixed contrastive loss with temperature and weights"
            },
            {
              "name": "forward",
              "signature": "forward(self, vision_features: torch.Tensor, text_features: torch.Tensor, match_ids: Optional[List[str]] = None) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute mixed contrastive loss components"
            },
            {
              "name": "_nt_xent_loss",
              "signature": "_nt_xent_loss(self, vision_features: torch.Tensor, text_features: torch.Tensor) -> torch.Tensor",
              "brief_description": "Compute NT-Xent contrastive loss"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 8,
      "module_path": "src/training/losses/multimodal_mixed_contrastive_loss.py"
    },
    {
      "filename": "loss_factory.py",
      "module_purpose": "Factory functions for creating and configuring loss functions",
      "key_functions": [
        {
          "name": "create_loss_function",
          "signature": "create_loss_function(args: Any, dataset_size: Optional[int] = None, train_loader: Optional[Any] = None) -> nn.Module",
          "brief_description": "Create the appropriate loss function based on arguments"
        }
      ],
      "external_dependencies": [
        "torch",
        "logging"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/loss_factory.py"
    },
    {
      "filename": "vicreg_loss.py",
      "module_purpose": "Implements VICReg (Variance-Invariance-Covariance Regularization) loss for representation learning",
      "key_classes": [
        {
          "name": "VICRegLoss",
          "purpose": "Implements VICReg loss with variance, invariance, and covariance terms",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, sim_weight: float = 25.0, var_weight: float = 25.0, cov_weight: float = 1.0)",
              "brief_description": "Initialize VICReg loss with component weights"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor, y: torch.Tensor) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute VICReg loss components"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/vicreg_loss.py"
    },
    {
      "filename": "multitask_loss.py",
      "module_purpose": "Implements a flexible multitask loss function that combines multiple task-specific losses with configurable weights",
      "key_classes": [
        {
          "name": "MultitaskLoss",
          "purpose": "Combines multiple loss functions with configurable or dynamic weighting for multitask learning",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, loss_functions: Dict[str, nn.Module], loss_weights: Optional[Dict[str, float]] = None, dynamic_weighting: bool = False, reduction: str = 'mean')",
              "brief_description": "Initialize with task-specific loss functions and optional weighting configuration"
            },
            {
              "name": "forward",
              "signature": "forward(self, inputs: Dict[str, Any], targets: Dict[str, Any]) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute weighted combination of task-specific losses"
            },
            {
              "name": "_update_dynamic_weights",
              "signature": "_update_dynamic_weights(self, individual_losses: Dict[str, torch.Tensor]) -> None",
              "brief_description": "Update task weights dynamically based on current loss values"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "logging"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/multitask_loss.py"
    },
    {
      "filename": "contrastive_learning.py",
      "module_purpose": "Implements contrastive learning losses and utilities for self-supervised and supervised learning",
      "key_classes": [
        {
          "name": "ContrastiveLearning",
          "purpose": "Base class for implementing various contrastive learning objectives",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, temperature: float = 0.07, normalize: bool = True)",
              "brief_description": "Initialize contrastive learning with temperature scaling"
            },
            {
              "name": "forward",
              "signature": "forward(self, features: torch.Tensor, labels: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute contrastive loss with optional supervision"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/contrastive_learning.py"
    },
    {
      "filename": "memory_queue_contrastive_loss.py",
      "module_purpose": "Implements contrastive loss with memory queue for maintaining large sets of negative examples",
      "key_classes": [
        {
          "name": "MemoryQueueContrastiveLoss",
          "purpose": "Contrastive loss with memory queue for enhanced negative sampling",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, dim: int, K: int = 65536, m: float = 0.999, T: float = 0.07)",
              "brief_description": "Initialize loss with queue parameters"
            },
            {
              "name": "forward",
              "signature": "forward(self, q: torch.Tensor, k: torch.Tensor) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute loss using memory queue"
            },
            {
              "name": "_dequeue_and_enqueue",
              "signature": "_dequeue_and_enqueue(self, keys: torch.Tensor) -> None",
              "brief_description": "Update memory queue with new keys"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/memory_queue_contrastive_loss.py"
    },
    {
      "filename": "supervised_contrastive_loss.py",
      "module_purpose": "Implements supervised contrastive learning for multimodal models using explicit labels",
      "key_classes": [
        {
          "name": "SupervisedContrastiveLoss",
          "purpose": "Improves contrastive learning by leveraging class labels to identify semantically related samples",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, vision_features: torch.Tensor, text_features: torch.Tensor, labels: Optional[torch.Tensor] = None, similarity_scores: Optional[torch.Tensor] = None, class_weights: Optional[torch.Tensor] = None, **kwargs) -> Dict[str, Any]",
              "brief_description": "Computes supervised contrastive loss with support for class labels or similarity scores"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "logging"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "logging"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/supervised_contrastive_loss.py"
    },
    {
      "filename": "decoupled_contrastive_loss.py",
      "module_purpose": "Implements decoupled contrastive learning for multimodal models by separating vision-to-text and text-to-vision learning objectives",
      "key_classes": [
        {
          "name": "DecoupledContrastiveLoss",
          "purpose": "Implements a decoupled approach to contrastive learning with separated vision-to-text and text-to-vision objectives",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, temperature: float = 0.07, lambda_v: float = 0.5, lambda_t: float = 0.5, reduction: str = 'mean')",
              "brief_description": "Initialize with temperature scaling and loss component weights"
            },
            {
              "name": "forward",
              "signature": "forward(self, vision_features: torch.Tensor, text_features: torch.Tensor, match_ids: List[str]) -> Dict[str, Any]",
              "brief_description": "Compute decoupled contrastive loss with separated vision-to-text and text-to-vision components"
            },
            {
              "name": "train",
              "signature": "train(self, mode: bool = True)",
              "brief_description": "Set the module to training mode"
            },
            {
              "name": "eval",
              "signature": "eval(self)",
              "brief_description": "Set the module to evaluation mode"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "logging"
      ],
      "complexity_score": 8,
      "module_path": "src/training/losses/decoupled_contrastive_loss.py"
    },
    {
      "filename": "barlow_twins_loss.py",
      "module_purpose": "Implements Barlow Twins loss for multimodal learning through redundancy reduction",
      "key_classes": [
        {
          "name": "BarlowTwinsLoss",
          "purpose": "Loss function that creates embeddings with minimal redundancy between their components",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, lambda_coeff: float = 0.005, batch_norm_last_layer: bool = True, correlation_mode: str = 'cross_modal', add_projection: bool = False, projection_dim: int = 8192, input_dim: Optional[int] = None, normalize_embeddings: bool = True)",
              "brief_description": "Initialize the Barlow Twins loss module with configurable parameters"
            },
            {
              "name": "project",
              "signature": "project(self, vision_features: torch.Tensor, text_features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Apply projection heads to features if enabled"
            },
            {
              "name": "forward",
              "signature": "forward(self, vision_features: torch.Tensor, text_features: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, float]]",
              "brief_description": "Compute Barlow Twins loss between vision and text features"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "typing"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 6,
      "module_path": "src/training/losses/barlow_twins_loss.py"
    },
    {
      "filename": "combined_loss.py",
      "module_purpose": "Implements a flexible combined loss function that can aggregate multiple loss components with weights",
      "key_classes": [
        {
          "name": "CombinedLoss",
          "purpose": "Combines multiple loss functions with configurable weights",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, loss_functions: Dict[str, Callable], loss_weights: Optional[Dict[str, float]] = None)",
              "brief_description": "Initialize combined loss with component functions and weights"
            },
            {
              "name": "forward",
              "signature": "forward(self, **kwargs) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute weighted combination of loss components"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 5,
      "module_path": "src/training/losses/combined_loss.py"
    },
    {
      "filename": "hard_negative_mining_contrastive_loss.py",
      "module_purpose": "Implements contrastive loss with hard negative mining for more effective training",
      "key_classes": [
        {
          "name": "HardNegativeMiningContrastiveLoss",
          "purpose": "Contrastive loss that mines hard negatives during training",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, temperature: float = 0.07, mining_ratio: float = 0.5)",
              "brief_description": "Initialize loss with temperature and mining parameters"
            },
            {
              "name": "forward",
              "signature": "forward(self, features: torch.Tensor, labels: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute loss with mined hard negatives"
            },
            {
              "name": "mine_hard_negatives",
              "signature": "mine_hard_negatives(self, features: torch.Tensor, labels: torch.Tensor) -> torch.Tensor",
              "brief_description": "Find hard negative examples in batch"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 8,
      "module_path": "src/training/losses/hard_negative_mining_contrastive_loss.py"
    },
    {
      "filename": "ema_moco_loss.py",
      "module_purpose": "Implements MoCo (Momentum Contrast) with EMA updates for large-batch contrastive learning",
      "key_classes": [
        {
          "name": "EMAMoCoLoss",
          "purpose": "Enables efficient contrastive learning with memory queue and momentum-updated encoders",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, vision_queries: torch.Tensor, text_queries: torch.Tensor, vision_features: Optional[torch.Tensor] = None, text_features: Optional[torch.Tensor] = None, **kwargs) -> Dict[str, Any]",
              "brief_description": "Computes MoCo loss with EMA-updated encoders and memory queue"
            },
            {
              "name": "_momentum_update_key_encoder",
              "signature": "_momentum_update_key_encoder(self, q_encoder: nn.Module, k_encoder: nn.Module)",
              "brief_description": "Updates key encoder using momentum for stable feature space"
            },
            {
              "name": "_dequeue_and_enqueue",
              "signature": "_dequeue_and_enqueue(self, keys: torch.Tensor, queue: torch.Tensor, queue_ptr: torch.Tensor)",
              "brief_description": "Updates queue by dequeuing old keys and enqueuing new ones"
            },
            {
              "name": "_copy_and_detach",
              "signature": "_copy_and_detach(self, model: nn.Module) -> nn.Module",
              "brief_description": "Creates a deep copy of a model detached from computation graph"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "logging",
            "math",
            "copy"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "logging",
        "math",
        "copy"
      ],
      "complexity_score": 8,
      "module_path": "src/training/losses/ema_moco_loss.py"
    },
    {
      "filename": "contrastive_loss.py",
      "module_purpose": "Implements core contrastive loss functions for self-supervised learning with InfoNCE and variants",
      "key_classes": [
        {
          "name": "ContrastiveLoss",
          "purpose": "Implements InfoNCE contrastive loss with various configurations and memory bank support",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, temperature: float = 0.07, loss_type: str = 'infonce', reduction: str = 'mean', add_projection: bool = True, projection_dim: int = 256, input_dim: Optional[int] = None, sampling_strategy: str = 'auto', memory_bank_size: int = 4096, dataset_size: Optional[int] = None)",
              "brief_description": "Initialize contrastive loss with temperature, loss type, and memory options"
            },
            {
              "name": "project",
              "signature": "project(self, vision_features: torch.Tensor, text_features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Apply projection heads to features and normalize them"
            },
            {
              "name": "forward",
              "signature": "forward(self, vision_features: torch.Tensor, text_features: torch.Tensor, match_ids: Optional[List[str]] = None, indices: Optional[torch.Tensor] = None, labels: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute contrastive loss between vision and text features with various configurations"
            },
            {
              "name": "update_memory_bank",
              "signature": "update_memory_bank(self, vision_features: torch.Tensor, text_features: torch.Tensor)",
              "brief_description": "Update memory bank with new vision and text features for additional negatives"
            },
            {
              "name": "update_global_embeddings",
              "signature": "update_global_embeddings(self, vision_features: torch.Tensor, text_features: torch.Tensor, indices: torch.Tensor)",
              "brief_description": "Update global embedding store for improved contrastive learning with more negatives"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "nt_xent_loss",
          "signature": "nt_xent_loss(vision_features: torch.Tensor, text_features: torch.Tensor, temperature: float = 0.07, reduction: str = 'mean') -> torch.Tensor",
          "brief_description": "Compute NT-Xent (Normalized Temperature-scaled Cross Entropy) contrastive loss"
        },
        {
          "name": "supervised_contrastive_loss",
          "signature": "supervised_contrastive_loss(vision_features: torch.Tensor, text_features: torch.Tensor, labels: torch.Tensor, temperature: float = 0.07, reduction: str = 'mean') -> torch.Tensor",
          "brief_description": "Compute supervised contrastive loss using class labels to form positive pairs"
        },
        {
          "name": "compute_recall_at_k",
          "signature": "compute_recall_at_k(similarity: torch.Tensor, K: List[int] = [1, 5, 10], v2t_targets: Optional[torch.Tensor] = None, t2i_targets: Optional[torch.Tensor] = None) -> Dict[str, float]",
          "brief_description": "Compute recall@K metrics for image-text retrieval evaluation"
        }
      ],
      "external_dependencies": [
        "torch",
        "typing",
        "numpy",
        "logging"
      ],
      "complexity_score": 8,
      "module_path": "src/training/losses/contrastive_loss.py"
    },
    {
      "filename": "hybrid_pretrain_vicreg_loss.py",
      "module_purpose": "Implements a hybrid pretraining loss that combines VICReg with contrastive learning for improved representation learning",
      "key_classes": [
        {
          "name": "HybridPretrainVICRegLoss",
          "purpose": "Combines VICReg and contrastive losses with adaptive transition",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, sim_coeff: float = 5.0, var_coeff: float = 5.0, cov_coeff: float = 1.0, warmup_epochs: int = 5)",
              "brief_description": "Initialize hybrid loss with coefficients and warmup"
            },
            {
              "name": "forward",
              "signature": "forward(self, z_a: torch.Tensor, z_b: torch.Tensor) -> Dict[str, Union[torch.Tensor, float, Literal['contrastive_pretrain']]]",
              "brief_description": "Compute hybrid loss with current transition state"
            },
            {
              "name": "update_step",
              "signature": "update_step(self, step: int, total_steps: int) -> None",
              "brief_description": "Update training progress for adaptive transition"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 9,
      "module_path": "src/training/losses/hybrid_pretrain_vicreg_loss.py"
    },
    {
      "filename": "clip_style_loss.py",
      "module_purpose": "Implements a CLIP-style contrastive loss for multimodal learning with bidirectional alignment",
      "key_classes": [
        {
          "name": "CLIPStyleLoss",
          "purpose": "Aligns visual and textual representations in a shared embedding space using bidirectional contrastive learning",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, vision_features: torch.Tensor, text_features: torch.Tensor, match_ids: Optional[List[str]] = None, similarity_matrix: Optional[torch.Tensor] = None, **kwargs) -> Dict[str, Any]",
              "brief_description": "Computes bidirectional contrastive loss with comprehensive metrics"
            },
            {
              "name": "_create_smooth_labels",
              "signature": "_create_smooth_labels(self, batch_size: int, targets: torch.Tensor, label_smoothing: float) -> torch.Tensor",
              "brief_description": "Creates smoothed label distributions for more stable training"
            },
            {
              "name": "_compute_recall_at_k",
              "signature": "_compute_recall_at_k(self, similarity: torch.Tensor, K: List[int] = [1, 5, 10], v2t_targets: Optional[torch.Tensor] = None, t2v_targets: Optional[torch.Tensor] = None) -> Dict[str, float]",
              "brief_description": "Calculates recall@K metrics for retrieval evaluation"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "logging"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "logging"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/clip_style_loss.py"
    },
    {
      "filename": "feature_consistency_loss.py",
      "module_purpose": "Implements feature consistency loss to prevent catastrophic forgetting during fine-tuning",
      "key_classes": [
        {
          "name": "FeatureConsistencyLoss",
          "purpose": "Maintains consistency between current and reference model features to prevent forgetting",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, vision_features: Optional[torch.Tensor] = None, text_features: Optional[torch.Tensor] = None, vision_inputs: Optional[torch.Tensor] = None, text_inputs: Optional[torch.Tensor] = None, **kwargs) -> Dict[str, Any]",
              "brief_description": "Computes consistency loss between current and reference features"
            },
            {
              "name": "_compute_distance",
              "signature": "_compute_distance(self, current_features: torch.Tensor, reference_features: torch.Tensor) -> torch.Tensor",
              "brief_description": "Calculates distance between feature representations using selected metric"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "logging"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "logging"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/feature_consistency_loss.py"
    },
    {
      "filename": "losses.py",
      "module_purpose": "Implements custom loss functions for model training with support for label smoothing and weighted samples",
      "key_classes": [
        {
          "name": "CrossEntropyLoss",
          "purpose": "Cross-entropy loss with label smoothing for classification tasks",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, input: torch.Tensor, target: torch.Tensor, sample_weight: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Computes cross-entropy loss with label smoothing and optional sample weights"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional"
          ]
        },
        {
          "name": "MeanSquaredError",
          "purpose": "Mean squared error loss with support for weighted samples and gradient clipping",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, input: torch.Tensor, target: torch.Tensor, sample_weight: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Computes MSE loss with optional sample weights and gradient clipping"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 4,
      "module_path": "src/training/losses/losses.py"
    },
    {
      "filename": "decorrelation_loss.py",
      "module_purpose": "Implements decorrelation regularization to prevent feature collapse in multimodal models",
      "key_classes": [
        {
          "name": "DecorrelationLoss",
          "purpose": "Prevents feature collapse by penalizing correlation between feature dimensions",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, vision_features: Optional[torch.Tensor] = None, text_features: Optional[torch.Tensor] = None, features: Optional[torch.Tensor] = None, **kwargs) -> Dict[str, Any]",
              "brief_description": "Computes decorrelation loss for vision, text, or generic features"
            },
            {
              "name": "_compute_covariance",
              "signature": "_compute_covariance(self, features: torch.Tensor) -> torch.Tensor",
              "brief_description": "Computes feature covariance matrix for regularization"
            },
            {
              "name": "_compute_off_diagonal_loss",
              "signature": "_compute_off_diagonal_loss(self, cov: torch.Tensor) -> torch.Tensor",
              "brief_description": "Calculates loss from off-diagonal covariance elements"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "logging",
            "math"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "logging",
        "math"
      ],
      "complexity_score": 6,
      "module_path": "src/training/losses/decorrelation_loss.py"
    },
    {
      "filename": "dynamic_temperature_contrastive_loss.py",
      "module_purpose": "Implements contrastive loss with dynamic temperature scaling based on training progress",
      "key_classes": [
        {
          "name": "DynamicTemperatureContrastiveLoss",
          "purpose": "Contrastive loss with temperature that adapts during training",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, initial_temp: float = 0.07, min_temp: float = 0.01, max_temp: float = 0.2)",
              "brief_description": "Initialize loss with temperature bounds"
            },
            {
              "name": "forward",
              "signature": "forward(self, features: torch.Tensor, labels: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute loss with current temperature"
            },
            {
              "name": "update_temperature",
              "signature": "update_temperature(self, metrics: Dict[str, float]) -> None",
              "brief_description": "Update temperature based on training metrics"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 7,
      "module_path": "src/training/losses/dynamic_temperature_contrastive_loss.py"
    },
    {
      "filename": "single_modality_strategy.py",
      "module_purpose": "Implements the first stage training strategy for multimodal models, focusing on modality-specific learning",
      "key_classes": [
        {
          "name": "SingleModalityStrategy",
          "purpose": "Training strategy for the first stage of multimodal training: modality-specific learning",
          "key_methods": [
            {
              "name": "initialize_strategy",
              "signature": "initialize_strategy(self) -> None",
              "brief_description": "Initialize the strategy by freezing cross-modal components and configuring modality-specific training"
            },
            {
              "name": "_configure_loss_function",
              "signature": "_configure_loss_function(self) -> None",
              "brief_description": "Configure appropriate loss function for single modality training"
            },
            {
              "name": "prepare_batch",
              "signature": "prepare_batch(self, batch: Dict[str, Any]) -> Dict[str, Any]",
              "brief_description": "Prepare a batch with focus on separate modality processing"
            },
            {
              "name": "training_step",
              "signature": "training_step(self, batch: Dict[str, Any]) -> Dict[str, Any]",
              "brief_description": "Perform a training step with modality-specific focus"
            },
            {
              "name": "configure_optimizers",
              "signature": "configure_optimizers(self) -> tuple",
              "brief_description": "Configure optimizers with layer-wise learning rates for modality components"
            },
            {
              "name": "on_epoch_end",
              "signature": "on_epoch_end(self, epoch: int) -> None",
              "brief_description": "Perform end-of-epoch actions including progressive unfreezing"
            }
          ],
          "inheritance": "TrainingStrategy",
          "dependencies": [
            "torch",
            "torch.nn",
            "tqdm",
            "TrainingStrategy",
            "WarmupCosineScheduler",
            "GradientHandler",
            "ContrastiveLoss",
            "VICRegLoss"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "tqdm"
      ],
      "complexity_score": 8,
      "module_path": "src/training/strategies/single_modality_strategy.py"
    },
    {
      "filename": "training_strategy.py",
      "module_purpose": "Provides an abstract base class for training strategies used in the multistage training framework",
      "key_classes": [
        {
          "name": "TrainingStrategy",
          "purpose": "Abstract base class defining the interface for all training strategies in multimodal learning",
          "key_methods": [
            {
              "name": "initialize_strategy",
              "signature": "initialize_strategy(self) -> None",
              "brief_description": "Initialize the strategy with appropriate parameter freezing and configuration"
            },
            {
              "name": "prepare_batch",
              "signature": "prepare_batch(self, batch: Dict[str, Any]) -> Dict[str, Any]",
              "brief_description": "Prepare a batch of data for the model with strategy-specific processing"
            },
            {
              "name": "training_step",
              "signature": "training_step(self, batch: Dict[str, Any]) -> Dict[str, Any]",
              "brief_description": "Perform a single training step with forward/backward passes"
            },
            {
              "name": "validation_step",
              "signature": "validation_step(self, batch: Dict[str, Any]) -> Dict[str, Any]",
              "brief_description": "Perform a single validation step with metrics calculation"
            },
            {
              "name": "configure_optimizers",
              "signature": "configure_optimizers(self) -> tuple",
              "brief_description": "Configure optimizers and schedulers for current strategy"
            }
          ],
          "inheritance": "ABC",
          "dependencies": [
            "torch",
            "torch.nn",
            "typing",
            "logging",
            "abc"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "abc"
      ],
      "complexity_score": 6,
      "module_path": "src/training/strategies/training_strategy.py"
    },
    {
      "filename": "end_to_end_strategy.py",
      "module_purpose": "Implements the final stage training strategy for multimodal models, focusing on end-to-end fine-tuning",
      "key_classes": [
        {
          "name": "EndToEndStrategy",
          "purpose": "Training strategy for the final stage of multimodal training: end-to-end fine-tuning",
          "key_methods": [
            {
              "name": "initialize_strategy",
              "signature": "initialize_strategy(self) -> None",
              "brief_description": "Initialize the strategy by unfreezing all components with careful learning rates"
            },
            {
              "name": "_store_initial_model_state",
              "signature": "_store_initial_model_state(self) -> None",
              "brief_description": "Store model state for feature consistency to prevent catastrophic forgetting"
            },
            {
              "name": "_configure_loss_function",
              "signature": "_configure_loss_function(self) -> None",
              "brief_description": "Configure hard negative mining loss with feature consistency"
            },
            {
              "name": "training_step",
              "signature": "training_step(self, batch: Dict[str, Any]) -> Dict[str, Any]",
              "brief_description": "Perform a training step with reference model for consistency"
            },
            {
              "name": "configure_optimizers",
              "signature": "configure_optimizers(self) -> tuple",
              "brief_description": "Configure optimizers with very low learning rates for base models"
            },
            {
              "name": "_calculate_topk_accuracy",
              "signature": "_calculate_topk_accuracy(self, similarity: torch.Tensor, match_ids: torch.Tensor, k: int = 1) -> float",
              "brief_description": "Calculate top-k accuracy metrics for comprehensive evaluation"
            },
            {
              "name": "_check_feature_drift",
              "signature": "_check_feature_drift(self) -> None",
              "brief_description": "Monitor feature drift to detect catastrophic forgetting"
            }
          ],
          "inheritance": "TrainingStrategy",
          "dependencies": [
            "torch",
            "torch.nn",
            "tqdm",
            "TrainingStrategy",
            "WarmupCosineScheduler",
            "GradientHandler",
            "HardNegativeMiningContrastiveLoss",
            "FeatureConsistencyLoss"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "tqdm"
      ],
      "complexity_score": 9,
      "module_path": "src/training/strategies/end_to_end_strategy.py"
    },
    {
      "filename": "cross_modal_strategy.py",
      "module_purpose": "Implements the second stage training strategy for multimodal models, focusing on cross-modal integration",
      "key_classes": [
        {
          "name": "CrossModalStrategy",
          "purpose": "Training strategy for the second stage of multimodal training: cross-modal integration",
          "key_methods": [
            {
              "name": "initialize_strategy",
              "signature": "initialize_strategy(self) -> None",
              "brief_description": "Initialize the strategy by freezing base encoders and configuring cross-modal training"
            },
            {
              "name": "_configure_loss_function",
              "signature": "_configure_loss_function(self) -> None",
              "brief_description": "Configure memory queue contrastive loss for cross-modal training"
            },
            {
              "name": "prepare_batch",
              "signature": "prepare_batch(self, batch: Dict[str, Any]) -> Dict[str, Any]",
              "brief_description": "Prepare a batch with focus on cross-modal interactions"
            },
            {
              "name": "training_step",
              "signature": "training_step(self, batch: Dict[str, Any]) -> Dict[str, Any]",
              "brief_description": "Perform a training step focusing on cross-modal integration"
            },
            {
              "name": "configure_optimizers",
              "signature": "configure_optimizers(self) -> tuple",
              "brief_description": "Configure optimizers with focus on cross-modal components"
            },
            {
              "name": "_calculate_recall_at_k",
              "signature": "_calculate_recall_at_k(self, similarity: torch.Tensor, match_ids: torch.Tensor, k: int = 5) -> float",
              "brief_description": "Calculate recall@K metrics for cross-modal retrieval evaluation"
            }
          ],
          "inheritance": "TrainingStrategy",
          "dependencies": [
            "torch",
            "torch.nn",
            "tqdm",
            "TrainingStrategy",
            "WarmupCosineScheduler",
            "GradientHandler",
            "MemoryQueueContrastiveLoss"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "tqdm"
      ],
      "complexity_score": 7,
      "module_path": "src/training/strategies/cross_modal_strategy.py"
    },
    {
      "filename": "multistage_trainer.py",
      "module_purpose": "Implements a flexible trainer for multistage training of multimodal models with distinct training strategies for each stage",
      "key_classes": [
        {
          "name": "MultistageTrainer",
          "purpose": "Manages sequential training stages with different strategies for progressive model improvement",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model: nn.Module, train_dataloader: DataLoader, val_dataloader: Optional[DataLoader] = None, test_dataloader: Optional[DataLoader] = None, config: Optional[TrainingConfig] = None, strategies: Optional[Dict[str, Dict]] = None, checkpoint_dir: str = 'checkpoints', log_dir: str = 'logs', device: Optional[torch.device] = None, **kwargs)",
              "brief_description": "Initialize trainer with model, data, and stage configurations"
            },
            {
              "name": "train",
              "signature": "train(self) -> Dict[str, Any]",
              "brief_description": "Train the model through all configured stages sequentially"
            },
            {
              "name": "train_stage",
              "signature": "train_stage(self, stage_idx: int) -> Dict[str, Any]",
              "brief_description": "Train a specific stage by index"
            },
            {
              "name": "_apply_component_freezing",
              "signature": "_apply_component_freezing(self, stage_config: StageConfig) -> None",
              "brief_description": "Apply component freezing/unfreezing based on stage configuration"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "TrainingStrategy",
            "SingleModalityStrategy",
            "CrossModalStrategy",
            "EndToEndStrategy",
            "MetricsTracker"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "matplotlib",
        "tqdm"
      ],
      "complexity_score": 8,
      "module_path": "src/training/trainers/multistage_trainer.py"
    },
    {
      "filename": "vision_transformer_trainer.py",
      "module_purpose": "Provides a specialized trainer for Vision Transformer models with advanced training techniques",
      "key_classes": [
        {
          "name": "VisionTransformerTrainer",
          "purpose": "Specialized trainer for Vision Transformer models with mixup/cutmix augmentation support",
          "key_methods": [
            {
              "name": "train_epoch",
              "signature": "train_epoch(self)",
              "brief_description": "Train the model for one epoch with mixup/cutmix augmentation support"
            },
            {
              "name": "validate",
              "signature": "validate(self)",
              "brief_description": "Validate the model on validation dataset"
            },
            {
              "name": "train",
              "signature": "train(self) -> Dict[str, List[float]]",
              "brief_description": "Train the model for specified number of epochs with early stopping"
            },
            {
              "name": "save_checkpoint",
              "signature": "save_checkpoint(self, filename: str) -> None",
              "brief_description": "Save a checkpoint of the model and training state"
            },
            {
              "name": "load_checkpoint",
              "signature": "load_checkpoint(self, filename: str) -> None",
              "brief_description": "Load a checkpoint of the model and training state"
            },
            {
              "name": "_mixup_data",
              "signature": "_mixup_data(self, x: torch.Tensor, y: torch.Tensor, alpha: float) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, float]",
              "brief_description": "Perform mixup data augmentation"
            },
            {
              "name": "_cutmix_data",
              "signature": "_cutmix_data(self, x: torch.Tensor, y: torch.Tensor, alpha: float) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, float]",
              "brief_description": "Perform cutmix data augmentation"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn",
            "VisionTransformer",
            "matplotlib",
            "numpy",
            "tqdm"
          ]
        }
      ],
      "key_functions": [],
      "external_dependencies": [
        "torch",
        "matplotlib",
        "numpy",
        "tqdm"
      ],
      "complexity_score": 8,
      "module_path": "src/training/trainers/vision_transformer_trainer.py"
    },
    {
      "filename": "language_model_trainer.py",
      "module_purpose": "Implements a specialized trainer for language modeling tasks with support for causal language modeling, evaluation, and generation",
      "key_classes": [
        {
          "name": "LanguageModelTrainer",
          "purpose": "Main trainer class for language model training with comprehensive training and evaluation capabilities",
          "key_methods": [
            {
              "name": "train",
              "signature": "train(self, num_epochs, save_dir='models/language', model_name='language_model')",
              "brief_description": "Main training loop with support for validation and checkpointing"
            },
            {
              "name": "evaluate",
              "signature": "evaluate(self)",
              "brief_description": "Evaluates the model on validation data and returns loss and perplexity"
            },
            {
              "name": "save_model",
              "signature": "save_model(self, path)",
              "brief_description": "Saves the model and training state to disk"
            },
            {
              "name": "load_model",
              "signature": "load_model(self, path)",
              "brief_description": "Loads a saved model and training state from disk"
            },
            {
              "name": "plot_training_curves",
              "signature": "plot_training_curves(self, save_path=None)",
              "brief_description": "Visualizes training metrics including loss, perplexity, and learning rate"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "numpy",
            "matplotlib",
            "tqdm"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "matplotlib",
        "tqdm"
      ],
      "complexity_score": 8,
      "module_path": "src/training/trainers/language_model_trainer.py"
    },
    {
      "filename": "trainer_factory.py",
      "module_purpose": "Factory for creating trainers based on configuration with appropriate strategies",
      "key_classes": [
        {
          "name": "TrainerFactory",
          "purpose": "Factory for creating trainers based on configuration",
          "key_methods": [
            {
              "name": "create_trainer",
              "signature": "create_trainer(model: nn.Module, train_dataloader: torch.utils.data.DataLoader, val_dataloader: Optional[torch.utils.data.DataLoader] = None, test_dataloader: Optional[torch.utils.data.DataLoader] = None, config: Optional[Dict[str, Any]] = None, device: Optional[torch.device] = None, **kwargs) -> Union[MultimodalTrainer, MultistageTrainer]",
              "brief_description": "Create a trainer based on configuration"
            },
            {
              "name": "_create_multimodal_trainer",
              "signature": "_create_multimodal_trainer(model: nn.Module, train_dataloader: torch.utils.data.DataLoader, val_dataloader: Optional[torch.utils.data.DataLoader], test_dataloader: Optional[torch.utils.data.DataLoader], config: Dict[str, Any], device: Optional[torch.device]) -> MultimodalTrainer",
              "brief_description": "Create a standard multimodal trainer with configuration"
            },
            {
              "name": "_create_multistage_trainer",
              "signature": "_create_multistage_trainer(model: nn.Module, train_dataloader: torch.utils.data.DataLoader, val_dataloader: Optional[torch.utils.data.DataLoader], test_dataloader: Optional[torch.utils.data.DataLoader], config: Dict[str, Any], device: Optional[torch.device]) -> MultistageTrainer",
              "brief_description": "Create a multistage trainer with appropriate strategies"
            },
            {
              "name": "_create_parameter_groups",
              "signature": "_create_parameter_groups(model: nn.Module, config: Dict[str, Any]) -> List[Dict[str, Any]]",
              "brief_description": "Create parameter groups with different learning rates"
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "torch.nn",
            "MultimodalTrainer",
            "MultistageTrainer",
            "TrainingStrategy",
            "SingleModalityStrategy",
            "CrossModalStrategy",
            "EndToEndStrategy",
            "WarmupCosineScheduler",
            "LinearWarmupScheduler"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "os"
      ],
      "complexity_score": 7,
      "module_path": "src/training/trainers/trainer_factory.py"
    },
    {
      "filename": "transformer_trainer.py",
      "module_purpose": "Implements a specialized trainer for transformer models with support for encoder-decoder architectures and advanced training features",
      "key_classes": [
        {
          "name": "TransformerTrainer",
          "purpose": "Main trainer class for transformer model training with comprehensive training and evaluation capabilities",
          "key_methods": [
            {
              "name": "train",
              "signature": "train(self, epochs: int, save_path: Optional[str] = None)",
              "brief_description": "Main training loop with support for validation and early stopping"
            },
            {
              "name": "train_epoch",
              "signature": "train_epoch(self)",
              "brief_description": "Trains the model for a single epoch with progress tracking"
            },
            {
              "name": "validate",
              "signature": "validate(self)",
              "brief_description": "Evaluates the model on validation data and returns loss metrics"
            },
            {
              "name": "get_lr_scheduler",
              "signature": "get_lr_scheduler(self, optimizer)",
              "brief_description": "Creates learning rate scheduler with warmup and decay strategies"
            },
            {
              "name": "save_checkpoint",
              "signature": "save_checkpoint(self, path: str)",
              "brief_description": "Saves model checkpoint with training state"
            },
            {
              "name": "load_checkpoint",
              "signature": "load_checkpoint(self, path: str)",
              "brief_description": "Loads model checkpoint and training state"
            },
            {
              "name": "plot_learning_rate",
              "signature": "plot_learning_rate(self)",
              "brief_description": "Visualizes the learning rate schedule"
            },
            {
              "name": "plot_training_history",
              "signature": "plot_training_history(self)",
              "brief_description": "Visualizes training and validation metrics over time"
            },
            {
              "name": "plot_epoch_metrics",
              "signature": "plot_epoch_metrics(self, epoch: int)",
              "brief_description": "Visualizes detailed metrics for a specific epoch"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn",
            "numpy",
            "matplotlib",
            "tqdm",
            "transformer_utils"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "matplotlib",
        "tqdm"
      ],
      "complexity_score": 8,
      "module_path": "src/training/trainers/transformer_trainer.py"
    },
    {
      "filename": "trainer.py",
      "module_purpose": "Provides a generic, flexible training loop for PyTorch models with support for callbacks and early stopping",
      "key_functions": [
        {
          "name": "train_model",
          "signature": "train_model(model: nn.Module, train_dataloader: torch.utils.data.DataLoader, val_dataloader: Optional[torch.utils.data.DataLoader] = None, epochs: int = 10, learning_rate: float = 0.001, optimizer: Optional[torch.optim.Optimizer] = None, scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None, early_stopping_patience: Optional[int] = None, device: Optional[Union[str, torch.device]] = None, callbacks: List[Callable] = None) -> Dict[str, List[float]]",
          "brief_description": "A comprehensive training loop that handles both standard models and those with custom training/validation steps"
        }
      ],
      "external_dependencies": [
        "torch",
        "tqdm",
        "time"
      ],
      "complexity_score": 6,
      "module_path": "src/training/trainers/trainer.py"
    },
    {
      "filename": "multimodal_trainer.py",
      "module_purpose": "Provides a comprehensive training framework for multimodal models with support for contrastive learning and various training strategies",
      "key_classes": [
        {
          "name": "MultimodalTrainer",
          "purpose": "Main trainer class for multimodal models with support for various training techniques and evaluation metrics",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model: nn.Module, train_dataloader: DataLoader, val_dataloader: Optional[DataLoader] = None, test_dataloader: Optional[DataLoader] = None, optimizer: Optional[Any] = None, scheduler: Optional[Any] = None, loss_fn: Optional[nn.Module] = None, num_epochs: int = 20, learning_rate: float = 1e-4, weight_decay: float = 0.01, warmup_steps: int = 0, checkpoint_dir: str = 'checkpoints', log_dir: str = 'logs', device: Optional[torch.device] = None, mixed_precision: bool = False, accumulation_steps: int = 1, evaluation_steps: int = 0, log_steps: int = 50, early_stopping_patience: Optional[int] = None, clip_grad_norm: Optional[float] = None, balance_modality_gradients: bool = False, args: Optional[Any] = None)",
              "brief_description": "Initialize trainer with model, data, and training configuration"
            },
            {
              "name": "train",
              "signature": "train(self) -> Dict[str, List[float]]",
              "brief_description": "Train the model for specified number of epochs with comprehensive logging and evaluation"
            },
            {
              "name": "evaluate",
              "signature": "evaluate(self, dataloader: DataLoader) -> Dict[str, float]",
              "brief_description": "Evaluate model on given dataloader with comprehensive metrics calculation"
            },
            {
              "name": "train_multistage",
              "signature": "train_multistage(self)",
              "brief_description": "Train the model using a progressive multistage approach to improve convergence"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.optim",
            "ContrastiveLoss",
            "VICRegLoss"
          ]
        },
        {
          "name": "ModalityBalancingScheduler",
          "purpose": "Dynamically balances learning rates between vision and text modalities based on gradient statistics",
          "key_methods": [
            {
              "name": "collect_gradient_stats",
              "signature": "collect_gradient_stats(self, model)",
              "brief_description": "Collect gradient statistics for vision and text components"
            },
            {
              "name": "step",
              "signature": "step(self, model)",
              "brief_description": "Adjust learning rates based on gradient ratio between modalities"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "matplotlib",
        "tqdm"
      ],
      "complexity_score": 9,
      "module_path": "src/training/trainers/multimodal_trainer.py"
    },
    {
      "filename": "model_utils.py",
      "module_purpose": "Provides utility functions for working with neural network models, including inspection, parameter counting, and device management",
      "key_functions": [
        {
          "name": "count_parameters",
          "signature": "count_parameters(model: nn.Module) -> int",
          "brief_description": "Count the total number of trainable parameters in a model"
        },
        {
          "name": "print_model_summary",
          "signature": "print_model_summary(model: nn.Module, title: str = 'MODEL SUMMARY') -> None",
          "brief_description": "Print a concise summary of the model architecture and parameter counts"
        },
        {
          "name": "get_device",
          "signature": "get_device(device_name: Optional[str] = None) -> torch.device",
          "brief_description": "Get the appropriate device based on availability (CUDA, MPS, CPU)"
        },
        {
          "name": "convert_tensors_to_python_types",
          "signature": "convert_tensors_to_python_types(obj: Any) -> Any",
          "brief_description": "Convert PyTorch tensors to native Python types for JSON serialization"
        },
        {
          "name": "ensure_model_on_device",
          "signature": "ensure_model_on_device(model: nn.Module, device: torch.device) -> nn.Module",
          "brief_description": "Ensure all model components are on the correct device, handling complex multimodal models"
        }
      ],
      "external_dependencies": [
        "torch",
        "torch.nn"
      ],
      "complexity_score": 5,
      "module_path": "src/utils/model_utils.py"
    },
    {
      "filename": "logging.py",
      "module_purpose": "Provides custom logging functionality with configurable file and console output",
      "key_classes": [
        {
          "name": "LogManager",
          "purpose": "Central logging manager that configures and provides logger instances",
          "key_methods": [
            {
              "name": "get_logger",
              "signature": "get_logger(self, name: str, level: Optional[Union[str, int]] = None) -> std_logging.Logger",
              "brief_description": "Creates or retrieves a logger with the specified name and level"
            },
            {
              "name": "configure_file_logging",
              "signature": "configure_file_logging(self, log_dir: str, name: str = 'application') -> None",
              "brief_description": "Sets up file logging to the specified directory"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "logging",
            "os",
            "sys"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "get_logger",
          "signature": "get_logger(name: str, level: Optional[Union[str, int]] = None) -> std_logging.Logger",
          "brief_description": "Convenience function to get a logger from the singleton manager"
        },
        {
          "name": "configure_file_logging",
          "signature": "configure_file_logging(log_dir: str, name: str = 'application') -> None",
          "brief_description": "Convenience function to configure file logging"
        }
      ],
      "external_dependencies": [
        "logging"
      ],
      "complexity_score": 4,
      "module_path": "src/utils/logging.py"
    },
    {
      "filename": "argument_configs.py",
      "module_purpose": "Argument configuration utilities for multimodal training scripts",
      "key_functions": [
        {
          "name": "get_multimodal_training_args",
          "signature": "get_multimodal_training_args() -> argparse.ArgumentParser",
          "brief_description": "Create argument parser for multimodal training scripts"
        }
      ],
      "key_argument_groups": [
        {
          "name": "data_args",
          "description": "Arguments for dataset configuration and processing"
        },
        {
          "name": "semantic_batching_args",
          "description": "Arguments for semantic grouping in batch creation for contrastive learning"
        },
        {
          "name": "model_args",
          "description": "Arguments for model architecture and configuration"
        },
        {
          "name": "contrastive_learning_args",
          "description": "Arguments for contrastive learning setup and optimization"
        },
        {
          "name": "training_args",
          "description": "Arguments for training process configuration"
        }
      ],
      "external_dependencies": [
        "argparse"
      ],
      "complexity_score": 4,
      "module_path": "src/utils/argument_configs.py"
    },
    {
      "filename": "learningrate_scheduler.py",
      "module_purpose": "Implements custom learning rate schedulers for transformer and multimodal training",
      "key_classes": [
        {
          "name": "WarmupCosineScheduler",
          "purpose": "Scheduler that combines a warmup phase with cosine annealing decay",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, optimizer: torch.optim.Optimizer, warmup_steps: int, total_steps: int, min_lr: float = 0.0, warmup_start_factor: float = 0.1, last_epoch: int = -1, verbose: bool = False)",
              "brief_description": "Initialize scheduler with warmup and cosine decay parameters"
            },
            {
              "name": "get_lr",
              "signature": "get_lr(self) -> List[float]",
              "brief_description": "Calculate learning rates based on current step and schedule parameters"
            }
          ],
          "inheritance": "_LRScheduler",
          "dependencies": [
            "torch",
            "torch.optim.lr_scheduler",
            "math"
          ]
        },
        {
          "name": "LinearWarmupScheduler",
          "purpose": "Scheduler with linear warmup followed by linear decay",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, optimizer: torch.optim.Optimizer, warmup_epochs: int, total_epochs: int, init_lr: float = 0.0, final_lr: float = 0.0, last_epoch: int = -1, verbose: bool = False)",
              "brief_description": "Initialize scheduler with linear warmup and decay parameters"
            },
            {
              "name": "get_lr",
              "signature": "get_lr(self) -> List[float]",
              "brief_description": "Calculate learning rates using linear scheduling"
            }
          ],
          "inheritance": "_LRScheduler",
          "dependencies": [
            "torch",
            "torch.optim.lr_scheduler"
          ]
        },
        {
          "name": "LayerwiseLRScheduler",
          "purpose": "A utility for creating layer-wise learning rates with different schedules",
          "key_methods": [
            {
              "name": "add_scheduler",
              "signature": "add_scheduler(self, group_name: str, scheduler_type: str = 'warmup_cosine', **scheduler_kwargs)",
              "brief_description": "Add a scheduler for a specific parameter group"
            },
            {
              "name": "step",
              "signature": "step(self) -> None",
              "brief_description": "Update learning rates for all parameter groups with schedulers"
            },
            {
              "name": "get_last_lrs",
              "signature": "get_last_lrs(self) -> Dict[str, float]",
              "brief_description": "Get the last computed learning rate for each parameter group"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "typing"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "math"
      ],
      "complexity_score": 7,
      "module_path": "src/utils/learningrate_scheduler.py"
    },
    {
      "filename": "config.py",
      "module_purpose": "Provides configuration management utilities with file loading and environment support",
      "key_classes": [
        {
          "name": "ConfigManager",
          "purpose": "Manages application configuration with support for file and environment loading",
          "key_methods": [
            {
              "name": "load_from_file",
              "signature": "load_from_file(self, config_path: str) -> None",
              "brief_description": "Load configuration from a JSON file"
            },
            {
              "name": "get",
              "signature": "get(self, key: str, default: Any = None) -> Any",
              "brief_description": "Get a configuration value with optional default"
            },
            {
              "name": "set",
              "signature": "set(self, key: str, value: Any) -> None",
              "brief_description": "Set a configuration value"
            },
            {
              "name": "save_to_file",
              "signature": "save_to_file(self, config_path: str) -> None",
              "brief_description": "Save current configuration to a JSON file"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "os",
            "json"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "get_config",
          "signature": "get_config(key: str, default: Any = None) -> Any",
          "brief_description": "Convenience function to get a config value from the default manager"
        },
        {
          "name": "set_config",
          "signature": "set_config(key: str, value: Any) -> None",
          "brief_description": "Convenience function to set a config value in the default manager"
        }
      ],
      "external_dependencies": [
        "json"
      ],
      "complexity_score": 3,
      "module_path": "src/utils/config.py"
    },
    {
      "filename": "feature_attribution.py",
      "module_purpose": "Implements various feature attribution techniques for model interpretability and visualization",
      "key_classes": [
        {
          "name": "GradCAM",
          "purpose": "Implements Gradient-weighted Class Activation Mapping for vision models",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model: nn.Module, target_layer: nn.Module, use_cuda: bool = False)",
              "brief_description": "Initialize GradCAM with model and target layer"
            },
            {
              "name": "__call__",
              "signature": "__call__(self, input_image: torch.Tensor, target_class: Optional[int] = None) -> Tuple[np.ndarray, torch.Tensor]",
              "brief_description": "Generate a GradCAM heatmap for the input image"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn",
            "numpy"
          ]
        },
        {
          "name": "IntegratedGradients",
          "purpose": "Implements the integrated gradients method for computing feature importance",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model: nn.Module, use_cuda: bool = False, steps: int = 50)",
              "brief_description": "Initialize integrated gradients with model and steps"
            },
            {
              "name": "__call__",
              "signature": "__call__(self, input_tensor: torch.Tensor, target_class: Optional[int] = None, baseline: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Compute integrated gradients for an input tensor"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        },
        {
          "name": "SaliencyMap",
          "purpose": "Creates simple saliency maps based on input gradients",
          "key_methods": [
            {
              "name": "__call__",
              "signature": "__call__(self, input_tensor: torch.Tensor, target_class: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Compute saliency map highlighting important input features"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        },
        {
          "name": "AttributionVisualizer",
          "purpose": "Utilities for visualizing feature attributions for both images and text",
          "key_methods": [
            {
              "name": "overlay_heatmap",
              "signature": "overlay_heatmap(image: Union[np.ndarray, Image.Image, torch.Tensor], heatmap: np.ndarray, colormap: str = 'jet', alpha: float = 0.5) -> np.ndarray",
              "brief_description": "Overlay a heatmap on an image for visualization"
            },
            {
              "name": "visualize_text_attribution",
              "signature": "visualize_text_attribution(tokens: List[str], attributions: torch.Tensor, colormap: str = 'RdBu_r', threshold: float = 0.0) -> plt.Figure",
              "brief_description": "Visualize attributions for text tokens"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "numpy",
            "matplotlib",
            "PIL"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "attribution_for_multimodal_model",
          "signature": "attribution_for_multimodal_model(model: nn.Module, image: torch.Tensor, text: Union[str, torch.Tensor], attribution_method: str = 'grad_cam', target_class: Optional[int] = None, **kwargs) -> Dict[str, Any]",
          "brief_description": "Compute attributions for a multimodal model using the specified method"
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "matplotlib",
        "PIL"
      ],
      "complexity_score": 8,
      "module_path": "src/utils/feature_attribution.py"
    },
    {
      "filename": "metrics_tracker.py",
      "module_purpose": "Tracks and visualizes training metrics across epochs and steps with issue detection",
      "key_classes": [
        {
          "name": "MetricsTracker",
          "purpose": "Tracks and visualizes training metrics with early stopping and issue detection",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, log_dir: str, early_stopping: bool = False, patience: int = 5, monitor: str = 'val_loss', mode: str = 'min', visualization_frequency: int = 1, issue_detection: bool = True)",
              "brief_description": "Initialize metrics tracker with configuration for monitoring and visualization"
            },
            {
              "name": "update_step_metrics",
              "signature": "update_step_metrics(self, metrics: Dict[str, Any], group: str = 'train') -> None",
              "brief_description": "Update metrics for the current step"
            },
            {
              "name": "update_epoch_metrics",
              "signature": "update_epoch_metrics(self, metrics: Dict[str, Any], group: str = 'train') -> None",
              "brief_description": "Update metrics for the current epoch"
            },
            {
              "name": "check_early_stopping",
              "signature": "check_early_stopping(self) -> bool",
              "brief_description": "Check if early stopping criteria are met"
            },
            {
              "name": "create_visualizations",
              "signature": "create_visualizations(self) -> None",
              "brief_description": "Create visualizations of tracked metrics"
            },
            {
              "name": "update_alignment_metrics",
              "signature": "update_alignment_metrics(self, diag_similarity: float, mean_similarity: float, std_similarity: float, step: Optional[int] = None) -> None",
              "brief_description": "Update metrics related to multimodal alignment quality"
            },
            {
              "name": "check_for_issues",
              "signature": "check_for_issues(self) -> List[str]",
              "brief_description": "Check for potential training issues based on metric patterns"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "numpy",
            "matplotlib",
            "typing",
            "os",
            "json",
            "logging",
            "collections",
            "time"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "matplotlib",
        "json"
      ],
      "complexity_score": 7,
      "module_path": "src/utils/metrics_tracker.py"
    },
    {
      "filename": "gradient_manager.py",
      "module_path": "src/utils/gradient_manager.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "visualization.py",
      "module_purpose": "Provides visualization utilities for model performance, attention patterns, embeddings, and multimodal outputs",
      "key_functions": [
        {
          "name": "plot_training_history",
          "signature": "plot_training_history(history: Dict[str, List[float]], figsize: Tuple[int, int] = (12, 8), save_path: Optional[str] = None) -> None",
          "brief_description": "Plot training metrics history over epochs"
        },
        {
          "name": "plot_attention_weights",
          "signature": "plot_attention_weights(attention_weights: torch.Tensor, tokens: List[str] = None, layer: int = 0, head: int = 0, figsize: Tuple[int, int] = (10, 10), save_path: Optional[str] = None) -> None",
          "brief_description": "Visualize attention weights from transformer models"
        },
        {
          "name": "plot_embeddings_tsne",
          "signature": "plot_embeddings_tsne(embeddings: torch.Tensor, labels: Optional[List[Any]] = None, random_state: int = 42, figsize: Tuple[int, int] = (10, 10), save_path: Optional[str] = None) -> None",
          "brief_description": "Visualize embeddings using t-SNE dimensionality reduction"
        },
        {
          "name": "visualize_similarity_matrix",
          "signature": "visualize_similarity_matrix(similarity_matrix: torch.Tensor, captions: List[str], save_path: Optional[str] = None) -> None",
          "brief_description": "Visualize the similarity matrix between images and texts"
        },
        {
          "name": "visualize_attention_maps",
          "signature": "visualize_attention_maps(attention_maps: Dict[str, torch.Tensor], images: torch.Tensor, captions: List[str], save_dir: Optional[str] = None, model: Optional[nn.Module] = None) -> None",
          "brief_description": "Visualize attention maps between images and texts"
        },
        {
          "name": "visualize_test_samples",
          "signature": "visualize_test_samples(model: nn.Module, test_dataset: Any, device: torch.device, save_path: str, num_samples: int = 10) -> float",
          "brief_description": "Visualize test samples with their matched captions"
        },
        {
          "name": "count_parameters",
          "signature": "count_parameters(model: nn.Module) -> int",
          "brief_description": "Count trainable parameters in a model"
        }
      ],
      "external_dependencies": [
        "matplotlib",
        "seaborn",
        "torch",
        "sklearn",
        "numpy",
        "tqdm"
      ],
      "complexity_score": 7,
      "module_path": "src/utils/visualization.py"
    },
    {
      "filename": "list_models.py",
      "module_purpose": "Provides utilities for listing and retrieving information about available models",
      "key_functions": [
        {
          "name": "main",
          "signature": "main(args)",
          "brief_description": "List available models and their information based on provided arguments"
        }
      ],
      "external_dependencies": [
        "argparse",
        "huggingface_hub"
      ],
      "complexity_score": 4,
      "module_path": "src/utils/list_models.py"
    },
    {
      "filename": "gradient_handler.py",
      "module_purpose": "Handles gradient operations including clipping, monitoring, balancing, and analysis for multimodal training",
      "key_classes": [
        {
          "name": "GradientHandler",
          "purpose": "Handles gradient operations including clipping, monitoring, balancing, and analysis",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model: nn.Module, clip_value: Optional[float] = None, component_ratios: Optional[Dict[str, float]] = None, balance_modalities: bool = False, log_frequency: int = 100, visualization_dir: Optional[str] = None)",
              "brief_description": "Initialize gradient handler with configuration for balance and monitoring"
            },
            {
              "name": "clip_gradients",
              "signature": "clip_gradients(self) -> float",
              "brief_description": "Clip gradients if clip_value is set and return total gradient norm"
            },
            {
              "name": "analyze_gradients",
              "signature": "analyze_gradients(self) -> Dict[str, float]",
              "brief_description": "Analyze gradient norms across different model components"
            },
            {
              "name": "balance_component_gradients",
              "signature": "balance_component_gradients(self, optimizer: torch.optim.Optimizer) -> None",
              "brief_description": "Balance gradients between components according to target ratios"
            },
            {
              "name": "_visualize_gradients",
              "signature": "_visualize_gradients(self) -> None",
              "brief_description": "Create visualizations of gradient flow across components"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn",
            "typing",
            "logging",
            "matplotlib",
            "numpy",
            "os"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "matplotlib",
        "numpy"
      ],
      "complexity_score": 8,
      "module_path": "src/utils/gradient_handler.py"
    },
    {
      "filename": "profiling.py",
      "module_purpose": "Provides utilities for profiling and benchmarking PyTorch models with comprehensive performance analysis",
      "key_classes": [
        {
          "name": "ModelProfiler",
          "purpose": "Utility for profiling PyTorch models with execution time, memory usage, and layer-wise analysis",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model: torch.nn.Module, device: Optional[torch.device] = None)",
              "brief_description": "Initialize the profiler with a model and target device"
            },
            {
              "name": "measure_execution_time",
              "signature": "measure_execution_time(self, input_data: Union[torch.Tensor, Dict[str, torch.Tensor]], iterations: int = 10, warmup: int = 2) -> Dict[str, float]",
              "brief_description": "Measure the execution time of a forward pass"
            },
            {
              "name": "measure_memory_usage",
              "signature": "measure_memory_usage(self, input_data: Union[torch.Tensor, Dict[str, torch.Tensor]]) -> Dict[str, float]",
              "brief_description": "Measure the memory usage during a forward pass"
            },
            {
              "name": "generate_report",
              "signature": "generate_report(self, save_path: Optional[str] = None) -> str",
              "brief_description": "Generate a comprehensive profiling report with all metrics"
            },
            {
              "name": "plot_metrics",
              "signature": "plot_metrics(self, save_dir: Optional[str] = None) -> Dict[str, plt.Figure]",
              "brief_description": "Create visualization plots for performance metrics"
            },
            {
              "name": "profile_with_pytorch_profiler",
              "signature": "profile_with_pytorch_profiler(self, input_data: Union[torch.Tensor, Dict[str, torch.Tensor]], use_mps: bool = True, num_steps: int = 10, warmup: int = 3, activities: Optional[List[str]] = None, record_shapes: bool = True, profile_memory: bool = True, save_path: Optional[str] = None) -> None",
              "brief_description": "Profile the model using PyTorch's built-in profiler"
            },
            {
              "name": "trace_memory_by_layer",
              "signature": "trace_memory_by_layer(self, input_data: Union[torch.Tensor, Dict[str, torch.Tensor]], save_path: Optional[str] = None) -> Dict[str, float]",
              "brief_description": "Trace memory usage by layer in the model"
            },
            {
              "name": "benchmark_model",
              "signature": "benchmark_model(self, input_generator: Callable[[int, int], Union[torch.Tensor, Dict[str, torch.Tensor]]], batch_sizes: List[int], sequence_lengths: List[int], num_iterations: int = 5, save_dir: Optional[str] = None) -> pd.DataFrame",
              "brief_description": "Benchmark the model across different batch sizes and sequence lengths"
            },
            {
              "name": "monitor_hardware_utilization",
              "signature": "monitor_hardware_utilization(self, train_fn: Callable, duration: int = 60, interval: float = 0.5, save_path: Optional[str] = None) -> pd.DataFrame",
              "brief_description": "Monitor CPU, GPU, and memory utilization during model execution"
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "numpy",
            "matplotlib",
            "psutil",
            "pandas",
            "seaborn"
          ]
        },
        {
          "name": "ModelBenchmarkSuite",
          "purpose": "Comprehensive suite for benchmarking and comparing multiple models with visualization",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, save_dir: str = \"benchmark_results\")",
              "brief_description": "Initialize the benchmark suite with output directory"
            },
            {
              "name": "benchmark_model",
              "signature": "benchmark_model(self, model: torch.nn.Module, model_name: str, input_generator: Callable[[int, int], torch.Tensor], batch_sizes: List[int] = [1, 2, 4, 8], sequence_lengths: List[int] = [16, 32, 64, 128, 256], num_iterations: int = 5, profile_with_pytorch: bool = True, trace_memory: bool = True, device: Optional[torch.device] = None) -> Dict[str, Any]",
              "brief_description": "Run a comprehensive benchmark on a model"
            },
            {
              "name": "compare_models",
              "signature": "compare_models(self, model_names: List[str] = None, metric: str = 'avg_time', save_path: Optional[str] = None) -> pd.DataFrame",
              "brief_description": "Compare performance metrics across multiple models"
            },
            {
              "name": "generate_optimization_recommendations",
              "signature": "generate_optimization_recommendations(self, model_name: str) -> str",
              "brief_description": "Generate optimization recommendations based on profiling results"
            }
          ],
          "inheritance": "",
          "dependencies": [
            "torch",
            "numpy",
            "matplotlib",
            "pandas",
            "seaborn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "pandas",
        "matplotlib",
        "seaborn",
        "psutil"
      ],
      "complexity_score": 9,
      "module_path": "src/utils/profiling.py"
    },
    {
      "filename": "attention.py",
      "module_purpose": "Implements various attention mechanisms for transformer architectures",
      "key_classes": [
        {
          "name": "ScaledDotProductAttention",
          "purpose": "Core attention mechanism with scaling and masking support",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: Optional[torch.Tensor] = None, device: Optional[torch.device] = None) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Compute attention scores and context vectors"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "math"
          ]
        },
        {
          "name": "MultiHeadAttention",
          "purpose": "Multi-head attention mechanism for parallel attention computation",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, query: torch.Tensor, key: Optional[torch.Tensor] = None, value: Optional[torch.Tensor] = None, mask: Optional[torch.Tensor] = None, rotary_emb: Optional[nn.Module] = None, device: Optional[torch.device] = None) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Compute multi-head attention with optional rotary embeddings"
            },
            {
              "name": "split_heads",
              "signature": "split_heads(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Split input tensor into multiple attention heads"
            },
            {
              "name": "combine_heads",
              "signature": "combine_heads(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Combine multiple attention heads into a single tensor"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional"
          ]
        },
        {
          "name": "GroupedQueryAttention",
          "purpose": "Efficient attention mechanism with grouped query heads for reduced computation",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x, mask=None)",
              "brief_description": "Compute grouped query attention"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        },
        {
          "name": "ALiBiAttention",
          "purpose": "Attention with linear biases for better sequence length extrapolation",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x, mask=None)",
              "brief_description": "Compute attention with ALiBi biases"
            },
            {
              "name": "_get_slopes",
              "signature": "_get_slopes(self, n)",
              "brief_description": "Compute attention slopes for ALiBi"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "math"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 8,
      "module_path": "src/models/attention.py"
    },
    {
      "filename": "activations.py",
      "module_purpose": "Implements various activation functions used in the transformer architecture",
      "key_classes": [
        {
          "name": "GELU",
          "purpose": "Gaussian Error Linear Unit activation function for transformer architectures",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self)",
              "brief_description": "Initialize the GELU activation layer"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Apply the GELU activation function to the input tensor"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 1,
      "module_path": "src/models/activations.py"
    },
    {
      "filename": "feed_forward.py",
      "module_purpose": "Implements various feed-forward neural network architectures with modern features for flexible model building",
      "key_classes": [
        {
          "name": "FeedForwardNN",
          "purpose": "Base class for configurable feed-forward neural networks with optional layer normalization and residual connections",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, input_size: int, hidden_sizes: List[int], output_size: int, activation: Literal['relu', 'gelu', 'tanh', 'sigmoid'] = 'relu', dropout: float = 0.0, use_layer_norm: bool = False, use_residual: bool = False)",
              "brief_description": "Initializes a configurable feed-forward neural network with given architecture"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Performs forward pass through the network layers"
            }
          ],
          "inheritance": "BaseModel",
          "dependencies": [
            "torch",
            "torch.nn",
            ".base_model",
            ".layers"
          ]
        },
        {
          "name": "FeedForwardClassifier",
          "purpose": "Specialized feed-forward classifier with training utilities and prediction methods",
          "key_methods": [
            {
              "name": "predict",
              "signature": "predict(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Makes class predictions by selecting highest probability class"
            },
            {
              "name": "predict_proba",
              "signature": "predict_proba(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Returns class probabilities using softmax on logits"
            },
            {
              "name": "training_step",
              "signature": "training_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]",
              "brief_description": "Performs a single training step with loss calculation and metrics"
            }
          ],
          "inheritance": "FeedForwardNN",
          "dependencies": [
            "torch",
            "torch.nn.functional"
          ]
        },
        {
          "name": "MultiLayerPerceptron",
          "purpose": "Traditional MLP implementation with modern features like layer normalization and residual connections",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Passes input through all network layers with optional skip connections"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 6,
      "module_path": "src/models/feed_forward.py"
    },
    {
      "filename": "base_model.py",
      "module_purpose": "Provides the foundational base class for all neural network models in the MultiModal Insight Engine",
      "key_classes": [
        {
          "name": "BaseModel",
          "purpose": "Abstract base class providing common model functionality like saving/loading, parameter counting, and device management",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x)",
              "brief_description": "Abstract forward pass method that must be implemented by subclasses"
            },
            {
              "name": "save",
              "signature": "save(self, path: str, optimizer: Optional[torch.optim.Optimizer] = None, epoch: Optional[int] = None, loss: Optional[float] = None, additional_info: Optional[Dict[str, Any]] = None)",
              "brief_description": "Save model weights and training state to a file"
            },
            {
              "name": "load",
              "signature": "load(self, path: str, map_location: Optional[str] = None)",
              "brief_description": "Load model weights from a file"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "os",
            "typing"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 3,
      "module_path": "src/models/base_model.py"
    },
    {
      "filename": "embeddings.py",
      "module_purpose": "Implements token embedding layers for transformer models with proper initialization and scaling",
      "key_classes": [
        {
          "name": "TokenEmbedding",
          "purpose": "Neural network layer that converts token indices to dense vector representations with proper scaling",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, vocab_size: int, d_model: int)",
              "brief_description": "Initialize the embedding layer with Xavier uniform initialization"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Convert token indices to scaled embeddings"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "math"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 2,
      "module_path": "src/models/embeddings.py"
    },
    {
      "filename": "transformer.py",
      "module_purpose": "Implements transformer models for sequence processing tasks",
      "key_classes": [
        {
          "name": "TransformerEncoderLayer",
          "purpose": "Implements a single transformer encoder layer with self-attention and feed-forward networks",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Forward pass through the encoder layer with self-attention and feed-forward"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            ".attention",
            ".layers",
            ".positional"
          ]
        },
        {
          "name": "TransformerEncoder",
          "purpose": "Implements the encoder part of the transformer with multiple layers and positional encoding",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Forward pass through the encoder with token embeddings and positional encoding"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            ".embeddings",
            ".positional"
          ]
        },
        {
          "name": "TransformerDecoderLayer",
          "purpose": "Implements a single transformer decoder layer with self-attention, cross-attention, and feed-forward networks",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor, memory: torch.Tensor, tgt_mask: Optional[torch.Tensor] = None, memory_mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Forward pass through the decoder layer with self-attention, cross-attention and feed-forward"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            ".attention",
            ".layers",
            ".positional"
          ]
        },
        {
          "name": "TransformerDecoder",
          "purpose": "Implements the decoder part of the transformer with multiple layers and positional encoding",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor, memory: torch.Tensor, tgt_mask: Optional[torch.Tensor] = None, memory_mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Forward pass through the decoder with token embeddings, positional encoding and encoder memory"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            ".embeddings",
            ".positional"
          ]
        },
        {
          "name": "Transformer",
          "purpose": "Implements a complete transformer model with encoder-only architecture",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Forward pass through the transformer"
            },
            {
              "name": "configure_optimizers",
              "signature": "configure_optimizers(self, lr: float = 0.0001) -> torch.optim.Optimizer",
              "brief_description": "Configure the optimizer for training"
            }
          ],
          "inheritance": "BaseModel",
          "dependencies": [
            "torch",
            "torch.nn",
            ".base_model"
          ]
        },
        {
          "name": "EncoderDecoderTransformer",
          "purpose": "Implements the full transformer architecture with both encoder and decoder",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, src: torch.Tensor, tgt: torch.Tensor, src_mask: Optional[torch.Tensor] = None, tgt_mask: Optional[torch.Tensor] = None, memory_mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Forward pass through the encoder-decoder transformer"
            },
            {
              "name": "encode",
              "signature": "encode(self, src: torch.Tensor, src_mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Encode source sequence"
            },
            {
              "name": "decode",
              "signature": "decode(self, tgt: torch.Tensor, memory: torch.Tensor, tgt_mask: Optional[torch.Tensor] = None, memory_mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Decode target sequence given encoder memory"
            },
            {
              "name": "generate",
              "signature": "generate(self, src: torch.Tensor, max_len: int, bos_token_id: int, eos_token_id: int, src_mask: Optional[torch.Tensor] = None, memory_mask: Optional[torch.Tensor] = None, temperature: float = 1.0) -> torch.Tensor",
              "brief_description": "Generate output sequences using the trained model"
            },
            {
              "name": "generate_square_subsequent_mask",
              "signature": "generate_square_subsequent_mask(self, size: int, device: torch.device) -> torch.Tensor",
              "brief_description": "Generate a square mask for preventing attending to future tokens"
            },
            {
              "name": "clone",
              "signature": "clone(self) -> 'EncoderDecoderTransformer'",
              "brief_description": "Create a deep copy of the transformer model"
            },
            {
              "name": "configure_optimizers",
              "signature": "configure_optimizers(self, lr: float = 0.0001) -> dict",
              "brief_description": "Configure optimizer and learning rate scheduler for training"
            }
          ],
          "inheritance": "BaseModel",
          "dependencies": [
            "torch",
            "torch.nn",
            ".base_model"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 9,
      "module_path": "src/models/transformer.py"
    },
    {
      "filename": "text_generation.py",
      "module_purpose": "Provides utilities for text generation using language models",
      "key_classes": [
        {
          "name": "TextGenerator",
          "purpose": "Text generation utilities with various sampling strategies and optimizations",
          "key_methods": [
            {
              "name": "generate",
              "signature": "generate(self, prompt: str, max_new_tokens: int = 50, temperature: float = 1.0, top_k: Optional[int] = None, top_p: Optional[float] = None, do_sample: bool = True, num_return_sequences: int = 1, return_attention: bool = False) -> Union[List[str], Tuple[List[str], List[torch.Tensor]]]",
              "brief_description": "Generate text from a prompt using various sampling strategies"
            },
            {
              "name": "_generate_with_kv_cache",
              "signature": "_generate_with_kv_cache(self, prompt: str, max_new_tokens: int = 50, temperature: float = 1.0, do_sample: bool = True) -> str",
              "brief_description": "Generate text with key-value caching for faster inference"
            },
            {
              "name": "batch_generate",
              "signature": "batch_generate(self, prompts: List[str], max_new_tokens: int = 50, temperature: float = 1.0, do_sample: bool = True) -> List[str]",
              "brief_description": "Generate text for multiple prompts in parallel"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "torch.nn.functional",
            "numpy"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy"
      ],
      "complexity_score": 7,
      "module_path": "src/models/text_generation.py"
    },
    {
      "filename": "layers.py",
      "module_purpose": "Implements fundamental neural network layers with advanced features for transformer architectures",
      "key_classes": [
        {
          "name": "LinearLayer",
          "purpose": "Enhanced linear layer with configurable initialization, dropout, and layer normalization",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, in_features: int, out_features: int, bias: bool = True, init_type: str = 'kaiming_uniform', dropout: float = 0.0, use_layer_norm: bool = False)",
              "brief_description": "Initialize the enhanced linear layer with optional features"
            },
            {
              "name": "_init_weights",
              "signature": "_init_weights(self, init_type: str) -> None",
              "brief_description": "Initialize weights using specified method (kaiming/xavier)"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Apply linear transformation with optional normalization and dropout"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional"
          ]
        },
        {
          "name": "FeedForwardBlock",
          "purpose": "Flexible feed-forward block with optional residual connections and multiple activation options",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, input_dim: int, hidden_dim: Optional[int] = None, output_dim: Optional[int] = None, activation: Literal['relu', 'gelu', 'tanh', 'sigmoid'] = 'relu', dropout: float = 0.0, use_layer_norm: bool = False, use_residual: bool = False)",
              "brief_description": "Initialize the feed-forward block with configurable architecture"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Apply feed-forward transformation with optional residual connection"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 4,
      "module_path": "src/models/layers.py"
    },
    {
      "filename": "model_factory.py",
      "module_purpose": "Factory functions for creating and configuring different types of models",
      "key_functions": [
        {
          "name": "create_multimodal_model",
          "signature": "create_multimodal_model(args: Any, device: torch.device) -> nn.Module",
          "brief_description": "Create a multimodal model with vision and text components"
        }
      ],
      "external_dependencies": [
        "torch",
        "timm",
        "transformers"
      ],
      "complexity_score": 8,
      "module_path": "src/models/model_factory.py"
    },
    {
      "filename": "positional.py",
      "module_purpose": "Implements various positional encoding schemes for transformer models to handle sequence order information",
      "key_classes": [
        {
          "name": "PositionalEncoding",
          "purpose": "Implements both fixed sinusoidal and learnable positional encodings for transformers",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, d_model: int, max_seq_length: int = 5000, dropout: float = 0.1, encoding_type: Literal['sinusoidal', 'learned'] = 'sinusoidal')",
              "brief_description": "Initializes positional encoding with configurable parameters"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Adds positional information to input embeddings"
            },
            {
              "name": "visualize_encodings",
              "signature": "visualize_encodings(self, seq_length: Optional[int] = None) -> Figure",
              "brief_description": "Visualizes the positional encodings as a heatmap for analysis"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "matplotlib.pyplot",
            "numpy"
          ]
        },
        {
          "name": "RotaryPositionEncoding",
          "purpose": "Implements Rotary Position Embedding (RoPE) for enhanced relative position handling",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, head_dim: int, max_seq_length: int = 5000, base: int = 10000)",
              "brief_description": "Initializes rotary embeddings with given dimensions"
            },
            {
              "name": "forward",
              "signature": "forward(self, q: torch.Tensor, k: torch.Tensor, seq_len: Optional[int] = None) -> tuple",
              "brief_description": "Applies rotary position encoding to query and key tensors"
            },
            {
              "name": "visualize_rotation",
              "signature": "visualize_rotation(self, seq_length: int = 20) -> Figure",
              "brief_description": "Visualizes the rotation effects on different sequence positions"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "math"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "matplotlib",
        "numpy"
      ],
      "complexity_score": 7,
      "module_path": "src/models/positional.py"
    },
    {
      "filename": "image_preprocessing.py",
      "module_purpose": "Provides utilities for preprocessing images for vision transformer models",
      "key_classes": [
        {
          "name": "ImagePreprocessor",
          "purpose": "Handles image resizing, normalization, and conversion to tensor format for vision models",
          "key_methods": [
            {
              "name": "preprocess",
              "signature": "preprocess(self, image: Union[str, Image.Image, np.ndarray, torch.Tensor]) -> torch.Tensor",
              "brief_description": "Processes a single image from various input formats to a standardized tensor"
            },
            {
              "name": "batch_preprocess",
              "signature": "batch_preprocess(self, images: List[Union[str, Image.Image, np.ndarray, torch.Tensor]]) -> torch.Tensor",
              "brief_description": "Processes multiple images into a batch tensor"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torchvision.transforms",
            "PIL.Image",
            "numpy",
            "torch.nn.functional"
          ]
        },
        {
          "name": "PatchExtractor",
          "purpose": "Efficiently extracts fixed-size patches from image tensors using unfold operations",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Tuple[int, int]]",
              "brief_description": "Extracts patches from a batch of images and returns patch dimensions"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "torchvision",
        "PIL",
        "numpy"
      ],
      "complexity_score": 6,
      "module_path": "src/models/vision/image_preprocessing.py"
    },
    {
      "filename": "vision_transformer.py",
      "module_purpose": "Implements Vision Transformer (ViT) architecture for image classification tasks",
      "key_classes": [
        {
          "name": "PatchEmbed",
          "purpose": "Converts images into sequences of patch embeddings using efficient convolution",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Projects image to patch embeddings"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        },
        {
          "name": "Attention",
          "purpose": "Implements multi-head self-attention mechanism with combined QKV projection",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Performs multi-head attention operation"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        },
        {
          "name": "Block",
          "purpose": "Transformer block with attention, MLP, and residual connections",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Processes input through attention and MLP layers with residual connections"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        },
        {
          "name": "VisionTransformer",
          "purpose": "Complete Vision Transformer model for image classification",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor, return_features: bool = False) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]",
              "brief_description": "Forward pass through the model to get class logits and optionally features"
            },
            {
              "name": "forward_features",
              "signature": "forward_features(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Forward pass to extract features before classification head"
            },
            {
              "name": "extract_features",
              "signature": "extract_features(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Convenience method to extract features for external use"
            },
            {
              "name": "configure_optimizers",
              "signature": "configure_optimizers(self, lr: float = 1e-3, weight_decay: float = 0.05, betas: Tuple[float, float] = (0.9, 0.999)) -> torch.optim.Optimizer",
              "brief_description": "Creates optimizer with weight decay excluded from bias and norm parameters"
            }
          ],
          "inheritance": "BaseModel",
          "dependencies": [
            "torch",
            "torch.nn",
            "..base_model"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "math"
      ],
      "complexity_score": 8,
      "module_path": "src/models/vision/vision_transformer.py"
    },
    {
      "filename": "patch_embedding.py",
      "module_purpose": "Implements patch embedding for Vision Transformer (ViT) models",
      "key_classes": [
        {
          "name": "PatchEmbedding",
          "purpose": "Extracts image patches and projects them to an embedding space with positional information",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Transforms images into sequences of embedded patches with positional information"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "create_sinusoidal_embeddings",
          "signature": "create_sinusoidal_embeddings(num_positions: int, embedding_dim: int) -> torch.Tensor",
          "brief_description": "Creates fixed sinusoidal positional embeddings using the method from the Transformer paper"
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 5,
      "module_path": "src/models/vision/patch_embedding.py"
    },
    {
      "filename": "multimodal_decoder_generation.py",
      "module_purpose": "Implements a multimodal decoder generation model for text generation conditioned on multiple modalities",
      "key_classes": [
        {
          "name": "MultimodalDecoderGeneration",
          "purpose": "Generative model that combines vision and text inputs to generate text outputs",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, vision_model: nn.Module, text_encoder: nn.Module, text_decoder: nn.Module, fusion_dim: int = 768, num_fusion_layers: int = 2, use_cross_attention: bool = True, max_sequence_length: int = 128, fusion_dropout: float = 0.1, tie_embeddings: bool = True, vocab_size: Optional[int] = None, use_gated_fusion: bool = True, generation_config: Optional[Dict[str, Any]] = None)",
              "brief_description": "Initialize the multimodal decoder generation model"
            },
            {
              "name": "prepare_inputs_for_decoder",
              "signature": "prepare_inputs_for_decoder(self, vision_features: Optional[torch.Tensor] = None, encoder_features: Optional[torch.Tensor] = None, attention_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, Optional[torch.Tensor]]",
              "brief_description": "Prepare fused representation for the decoder"
            },
            {
              "name": "forward",
              "signature": "forward(self, images: Optional[torch.Tensor] = None, encoder_input_ids: Optional[torch.Tensor] = None, encoder_attention_mask: Optional[torch.Tensor] = None, decoder_input_ids: Optional[torch.Tensor] = None, decoder_attention_mask: Optional[torch.Tensor] = None, labels: Optional[torch.Tensor] = None, **kwargs) -> Dict[str, Any]",
              "brief_description": "Process inputs through the model to compute logits and loss"
            },
            {
              "name": "generate",
              "signature": "generate(self, images: Optional[torch.Tensor] = None, encoder_input_ids: Optional[torch.Tensor] = None, encoder_attention_mask: Optional[torch.Tensor] = None, generation_config: Optional[Dict[str, Any]] = None, **kwargs) -> torch.Tensor",
              "brief_description": "Generate text based on visual and/or textual inputs"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "typing"
          ]
        },
        {
          "name": "CrossModalFusionTransformer",
          "purpose": "Transformer-based fusion mechanism for combining vision and text representations",
          "inheritance": "nn.Module"
        },
        {
          "name": "GatedMultimodalFusion",
          "purpose": "Gated fusion module that controls information flow between modalities",
          "inheritance": "nn.Module"
        }
      ],
      "external_dependencies": [
        "torch",
        "math",
        "logging"
      ],
      "complexity_score": 9,
      "module_path": "src/models/multimodal/multimodal_decoder_generation.py"
    },
    {
      "filename": "multimodal_integration.py",
      "module_purpose": "Implements models for combining vision and text modalities in a unified architecture",
      "key_classes": [
        {
          "name": "MultiModalTransformer",
          "purpose": "Combines vision and text transformer models with projection layers to a common embedding space",
          "key_methods": [
            {
              "name": "encode_image",
              "signature": "encode_image(self, image: torch.Tensor) -> torch.Tensor",
              "brief_description": "Projects image features to multimodal embedding space"
            },
            {
              "name": "encode_text",
              "signature": "encode_text(self, text: Dict[str, torch.Tensor]) -> torch.Tensor",
              "brief_description": "Projects text features to multimodal embedding space"
            },
            {
              "name": "forward",
              "signature": "forward(self, image: Optional[torch.Tensor] = None, text: Optional[Dict[str, torch.Tensor]] = None) -> Dict[str, torch.Tensor]",
              "brief_description": "Processes image and/or text inputs and computes similarity if both are provided"
            }
          ],
          "inheritance": "BaseModel",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "..base_model",
            "..transformer",
            ".vision_transformer"
          ]
        },
        {
          "name": "CrossAttentionMultiModalTransformer",
          "purpose": "Advanced multimodal transformer using cross-attention mechanisms for rich cross-modal interactions",
          "key_methods": [
            {
              "name": "extract_vision_features",
              "signature": "extract_vision_features(self, images: torch.Tensor) -> torch.Tensor",
              "brief_description": "Extracts features from images using the vision model"
            },
            {
              "name": "extract_text_features",
              "signature": "extract_text_features(self, text_data: Dict[str, torch.Tensor]) -> torch.Tensor",
              "brief_description": "Extracts features from text using the text model with device-aware processing"
            },
            {
              "name": "forward",
              "signature": "forward(self, images: Optional[torch.Tensor] = None, text_data: Optional[Dict[str, torch.Tensor]] = None, return_attention: bool = False) -> Dict[str, torch.Tensor]",
              "brief_description": "Processes image and/or text inputs with cross-attention fusion and returns enhanced features"
            }
          ],
          "inheritance": "BaseModel",
          "dependencies": [
            "torch",
            "torch.nn",
            "torch.nn.functional",
            "src.models.base_model",
            "src.models.transformer",
            "src.models.vision.vision_transformer",
            "src.models.multimodal.co_attention_fusion",
            "src.models.multimodal.bidirectional_cross_attention"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 7,
      "module_path": "src/models/multimodal/multimodal_integration.py"
    },
    {
      "filename": "vicreg_multimodal_model.py",
      "module_purpose": "Implements VICReg (Variance-Invariance-Covariance Regularization) for multimodal representation learning",
      "key_classes": [
        {
          "name": "VICRegMultimodalModel",
          "purpose": "Implements VICReg approach for learning aligned multimodal representations",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, vision_encoder: nn.Module, text_encoder: nn.Module, projection_dim: int = 8192, hidden_dim: int = 8192)",
              "brief_description": "Initialize VICReg multimodal model with encoders and projectors"
            },
            {
              "name": "forward",
              "signature": "forward(self, vision_input: torch.Tensor, text_input: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]",
              "brief_description": "Compute VICReg representations and regularization terms"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "transformers"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "transformers",
        "typing"
      ],
      "complexity_score": 8,
      "module_path": "src/models/multimodal/vicreg_multimodal_model.py"
    },
    {
      "filename": "bidirectional_cross_attention.py",
      "module_purpose": "Implements bidirectional cross-attention mechanism for multimodal fusion between vision and text features",
      "key_classes": [
        {
          "name": "BidirectionalCrossAttention",
          "purpose": "Implements bidirectional attention flow between vision and text modalities",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, vision_dim: int, text_dim: int, num_heads: int = 8, dropout: float = 0.1)",
              "brief_description": "Initialize bidirectional cross-attention module"
            },
            {
              "name": "forward",
              "signature": "forward(self, vision_features: torch.Tensor, text_features: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Compute bidirectional attention and fuse features"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 8,
      "module_path": "src/models/multimodal/bidirectional_cross_attention.py"
    },
    {
      "filename": "co_attention_fusion.py",
      "module_purpose": "Implements co-attention fusion mechanism for combining vision and text features through mutual attention",
      "key_classes": [
        {
          "name": "CoAttentionFusion",
          "purpose": "Implements parallel co-attention mechanism for multimodal feature fusion",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, vision_dim: int, text_dim: int, fusion_dim: int, num_heads: int = 8)",
              "brief_description": "Initialize co-attention fusion module"
            },
            {
              "name": "forward",
              "signature": "forward(self, vision_features: torch.Tensor, text_features: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor",
              "brief_description": "Compute co-attention and fuse features"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 7,
      "module_path": "src/models/multimodal/co_attention_fusion.py"
    },
    {
      "filename": "gated_cross_modal_attention.py",
      "module_purpose": "Implements gated cross-modal attention mechanism for controlled information flow between modalities",
      "key_classes": [
        {
          "name": "GatedCrossModalAttention",
          "purpose": "Implements gated attention mechanism for controlled cross-modal feature fusion",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, source_dim: int, target_dim: int, num_heads: int = 8, dropout: float = 0.1)",
              "brief_description": "Initialize gated cross-modal attention module"
            },
            {
              "name": "forward",
              "signature": "forward(self, source_features: torch.Tensor, target_features: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Compute gated cross-modal attention and fuse features"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing"
      ],
      "complexity_score": 7,
      "module_path": "src/models/multimodal/gated_cross_modal_attention.py"
    },
    {
      "filename": "clip_style_direct_projection.py",
      "module_purpose": "Implements a CLIP-style model with direct projection between modalities",
      "key_classes": [
        {
          "name": "CLIPStyleDirectProjection",
          "purpose": "CLIP-style model that directly projects vision and text to a shared space",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, vision_model: nn.Module, text_model: nn.Module, projection_dim: int = 512, dropout: float = 0.1, use_multi_head: bool = False, num_projection_heads: int = 4, use_layernorm: bool = True, prompt_pooling: str = 'mean', initial_temperature: float = 0.07, feature_dropout: float = 0.0)",
              "brief_description": "Initialize CLIP-style model with projection options"
            },
            {
              "name": "extract_text_features",
              "signature": "extract_text_features(self, text_data: Union[Dict[str, torch.Tensor], torch.Tensor]) -> torch.Tensor",
              "brief_description": "Extract features from text model with pooling"
            },
            {
              "name": "extract_vision_features",
              "signature": "extract_vision_features(self, images: torch.Tensor) -> torch.Tensor",
              "brief_description": "Extract features from vision model with pooling"
            },
            {
              "name": "forward",
              "signature": "forward(self, images: Optional[torch.Tensor] = None, text_data: Optional[Union[Dict[str, torch.Tensor], torch.Tensor]] = None) -> Dict[str, Any]",
              "brief_description": "Process images and text, compute similarity"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "numpy"
          ]
        },
        {
          "name": "MultiHeadProjection",
          "purpose": "Multi-head projection module for more expressive projections",
          "key_methods": [
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Project features through multiple heads and concatenate"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "logging"
      ],
      "complexity_score": 7,
      "module_path": "src/models/multimodal/clip_style_direct_projection.py"
    },
    {
      "filename": "dual_encoder.py",
      "module_purpose": "Implements a dual encoder architecture for vision-text multimodal learning with specialized projection layers",
      "key_classes": [
        {
          "name": "DualEncoder",
          "purpose": "Core class that processes both vision and text inputs through modality-specific encoders and projections",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, vision_model, text_model, projection_dim=512)",
              "brief_description": "Initialize with vision and text encoders and configurable projection dimension"
            },
            {
              "name": "forward",
              "signature": "forward(self, images=None, text_data=None)",
              "brief_description": "Process vision and text inputs, computing aligned features and similarity scores"
            },
            {
              "name": "_extract_features",
              "signature": "_extract_features(self, model, inputs)",
              "brief_description": "Extract features from various model types with unified interface"
            },
            {
              "name": "_get_model_dimension",
              "signature": "_get_model_dimension(self, model)",
              "brief_description": "Determine output dimension from different model architectures"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "numpy"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "torch.nn",
        "numpy"
      ],
      "complexity_score": 7,
      "module_path": "src/models/multimodal/dual_encoder.py"
    },
    {
      "filename": "cross_modal_attention_base.py",
      "module_purpose": "Provides base class and utilities for implementing cross-modal attention mechanisms between different modalities",
      "key_classes": [
        {
          "name": "CrossModalAttentionBase",
          "purpose": "Abstract base class defining interface for cross-modal attention mechanisms",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, source_dim: int, target_dim: int, num_heads: int = 8)",
              "brief_description": "Initialize base cross-modal attention module"
            },
            {
              "name": "forward",
              "signature": "forward(self, source_features: torch.Tensor, target_features: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Abstract method for computing cross-modal attention"
            }
          ],
          "inheritance": "nn.Module, ABC",
          "dependencies": [
            "torch",
            "torch.nn",
            "abc"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "typing",
        "abc"
      ],
      "complexity_score": 6,
      "module_path": "src/models/multimodal/cross_modal_attention_base.py"
    },
    {
      "filename": "vision_transformer.py",
      "module_purpose": "Provides a wrapper for Hugging Face Vision Transformer models with standardized interface",
      "key_classes": [
        {
          "name": "VisionTransformerWrapper",
          "purpose": "Wrapper for Hugging Face Vision Transformer models with simplified interface",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model_name: str = \"google/vit-base-patch16-224\")",
              "brief_description": "Initialize with specific ViT model"
            },
            {
              "name": "load_model",
              "signature": "load_model(self, model_name: str) -> None",
              "brief_description": "Load a pretrained Vision Transformer model"
            },
            {
              "name": "forward",
              "signature": "forward(self, pixel_values: torch.Tensor) -> torch.Tensor",
              "brief_description": "Process images through the Vision Transformer"
            }
          ],
          "inheritance": "PretrainedModelWrapper",
          "dependencies": [
            "torch",
            "transformers"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "transformers"
      ],
      "complexity_score": 3,
      "module_path": "src/models/pretrained/vision_transformer.py"
    },
    {
      "filename": "huggingface_wrapper.py",
      "module_purpose": "Provides wrapper classes for HuggingFace models to make them compatible with the project's architecture",
      "key_classes": [
        {
          "name": "HuggingFaceTextModelWrapper",
          "purpose": "Wrapper for HuggingFace text models (BERT, RoBERTa, etc.) with standardized interface",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model_name: str)",
              "brief_description": "Initialize wrapper with a HuggingFace model by name"
            },
            {
              "name": "encode",
              "signature": "encode(self, src, src_mask=None)",
              "brief_description": "Encode text using the HuggingFace model with fallback handling"
            },
            {
              "name": "forward",
              "signature": "forward(self, src, tgt=None, src_mask=None, tgt_mask=None)",
              "brief_description": "Forward pass that calls encode for encoder-only models"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "transformers"
          ]
        },
        {
          "name": "DimensionMatchingWrapper",
          "purpose": "Wrapper that adds projection layer to match dimensions between models",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, base_model: nn.Module, input_dim: int, output_dim: int)",
              "brief_description": "Initialize wrapper with base model and projection dimensions"
            },
            {
              "name": "encode",
              "signature": "encode(self, *args, **kwargs)",
              "brief_description": "Encode inputs using base model and project to target dimension"
            },
            {
              "name": "forward",
              "signature": "forward(self, *args, **kwargs)",
              "brief_description": "Forward pass that calls encode"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "transformers",
        "typing"
      ],
      "complexity_score": 7,
      "module_path": "src/models/pretrained/huggingface_wrapper.py"
    },
    {
      "filename": "clip_model.py",
      "module_purpose": "Provides a wrapper for OpenAI CLIP multimodal models with standardized interface",
      "key_classes": [
        {
          "name": "CLIPModelWrapper",
          "purpose": "Wrapper for OpenAI CLIP models with image-text similarity functionality",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model_name: str = \"ViT-B-32\", pretrained: str = \"laion2b_s34b_b79k\")",
              "brief_description": "Initialize with specific CLIP model variant and weights"
            },
            {
              "name": "load_model",
              "signature": "load_model(self, model_name: str) -> None",
              "brief_description": "Load a pretrained CLIP model with transforms and tokenizer"
            },
            {
              "name": "encode_image",
              "signature": "encode_image(self, image: torch.Tensor) -> torch.Tensor",
              "brief_description": "Encode images to the multimodal embedding space"
            },
            {
              "name": "encode_text",
              "signature": "encode_text(self, text: list) -> torch.Tensor",
              "brief_description": "Encode text to the multimodal embedding space"
            },
            {
              "name": "forward",
              "signature": "forward(self, images: torch.Tensor = None, texts: list = None) -> dict",
              "brief_description": "Process images and/or text through CLIP and compute similarities"
            }
          ],
          "inheritance": "PretrainedModelWrapper",
          "dependencies": [
            "torch",
            "torch.nn",
            "open_clip"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "open_clip"
      ],
      "complexity_score": 5,
      "module_path": "src/models/pretrained/clip_model.py"
    },
    {
      "filename": "base_wrapper.py",
      "module_purpose": "Provides a base wrapper class for pretrained models with consistent interface",
      "key_classes": [
        {
          "name": "PretrainedModelWrapper",
          "purpose": "Base wrapper for pretrained models with standardized interface and utilities",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, model_name: str = None, model: nn.Module = None)",
              "brief_description": "Initialize the wrapper with model name or model instance"
            },
            {
              "name": "load_model",
              "signature": "load_model(self, model_name: str) -> None",
              "brief_description": "Abstract method for loading a pretrained model"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Abstract forward pass method"
            },
            {
              "name": "save",
              "signature": "save(self, path: str) -> None",
              "brief_description": "Save wrapper configuration and model weights"
            },
            {
              "name": "load",
              "signature": "load(self, path: str, map_location: Optional[str] = None) -> Dict[str, Any]",
              "brief_description": "Load wrapper configuration and model weights"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn",
            "os",
            "typing"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 4,
      "module_path": "src/models/pretrained/base_wrapper.py"
    },
    {
      "filename": "model_registry.py",
      "module_purpose": "Implements a registry pattern for accessing and instantiating pretrained models",
      "key_classes": [
        {
          "name": "ModelRegistry",
          "purpose": "Registry that provides centralized access to all available models",
          "key_methods": [
            {
              "name": "get_model",
              "signature": "get_model(cls, model_type: str, **kwargs) -> nn.Module",
              "brief_description": "Instantiate a model by type name with optional configuration"
            },
            {
              "name": "register_model",
              "signature": "register_model(cls, model_type: str, model_class: Type[nn.Module]) -> None",
              "brief_description": "Register a new model type in the registry"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch.nn",
            ".vision_transformer",
            ".clip_model"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 3,
      "module_path": "src/models/pretrained/model_registry.py"
    },
    {
      "filename": "adapters.py",
      "module_purpose": "Implements adapter layers for fine-tuning frozen pretrained models efficiently",
      "key_classes": [
        {
          "name": "ModelAdapter",
          "purpose": "Adapter that adds small trainable components to a frozen pretrained model",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, base_model: nn.Module, adapter_dim: int = 64)",
              "brief_description": "Initialize the adapter with the base model and adapter dimension"
            },
            {
              "name": "_get_output_dim",
              "signature": "_get_output_dim(self) -> int",
              "brief_description": "Get the output dimension of the base model"
            },
            {
              "name": "forward",
              "signature": "forward(self, x: torch.Tensor) -> torch.Tensor",
              "brief_description": "Forward pass with residual adapter connection"
            }
          ],
          "inheritance": "nn.Module",
          "dependencies": [
            "torch",
            "torch.nn"
          ]
        }
      ],
      "external_dependencies": [
        "torch"
      ],
      "complexity_score": 3,
      "module_path": "src/models/pretrained/adapters.py"
    },
    {
      "filename": "harness.py",
      "module_purpose": "Provides a test harness for evaluating model safety on benchmark test cases, including test suite generation, model evaluation, and report generation",
      "key_classes": [
        {
          "name": "SafetyTestHarness",
          "purpose": "Main class for safety testing and evaluation of models against benchmark test cases",
          "key_methods": [
            {
              "name": "create_test_suite",
              "signature": "def create_test_suite(self) -> None",
              "brief_description": "Creates a basic test suite with examples for each safety category"
            },
            {
              "name": "load_test_cases",
              "signature": "def load_test_cases(self, category: Optional[str] = None) -> List[Dict[str, Any]]",
              "brief_description": "Loads test cases from disk, optionally filtered by category"
            },
            {
              "name": "evaluate_model",
              "signature": "def evaluate_model(self, model_func: Callable, category: Optional[str] = None) -> Dict[str, Any]",
              "brief_description": "Evaluates a model against safety test cases and tracks performance metrics"
            },
            {
              "name": "generate_report",
              "signature": "def generate_report(self, results: Dict[str, Any], model_name: str = 'unnamed_model') -> str",
              "brief_description": "Generates detailed safety evaluation reports with performance metrics"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "os",
            "json",
            "typing",
            "datetime",
            "evaluator",
            "utils"
          ]
        }
      ],
      "external_dependencies": [],
      "complexity_score": 9,
      "module_path": "src/safety/harness.py"
    },
    {
      "filename": "integration.py",
      "module_purpose": "Provides integration layer for augmenting models with safety mechanisms, including input validation, output filtering, and safety event logging",
      "key_classes": [
        {
          "name": "SafetyAugmentedModel",
          "purpose": "Wrapper class that adds safety checks and filtering to base models",
          "key_methods": [
            {
              "name": "predict",
              "signature": "def predict(self, input_text: str, metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]",
              "brief_description": "Main method for safe model inference with input validation and output filtering"
            },
            {
              "name": "_generate_rejection_message",
              "signature": "def _generate_rejection_message(self, validation_info: Dict[str, Any]) -> str",
              "brief_description": "Generates appropriate rejection messages based on safety violations"
            },
            {
              "name": "_log_safety_event",
              "signature": "def _log_safety_event(self, event_type: str, content: str, details: Dict[str, Any]) -> None",
              "brief_description": "Logs safety-related events for monitoring"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "typing",
            "datetime",
            "filter"
          ]
        }
      ],
      "external_dependencies": [],
      "complexity_score": 8,
      "module_path": "src/safety/integration.py"
    },
    {
      "filename": "utils.py",
      "module_purpose": "Provides utility functions and constants for safety evaluation, including pattern matching, scoring, and report generation",
      "key_classes": [],
      "key_functions": [
        {
          "name": "check_text_patterns",
          "signature": "def check_text_patterns(text: str, patterns: Dict[str, str]) -> Dict[str, List[str]]",
          "brief_description": "Checks text against multiple regex patterns for safety concerns"
        },
        {
          "name": "calculate_category_score",
          "signature": "def calculate_category_score(matches: Dict[str, List[str]], text: str) -> float",
          "brief_description": "Calculates normalized safety scores based on pattern matches"
        },
        {
          "name": "evaluate_text_safety",
          "signature": "def evaluate_text_safety(text: str, sensitivity: str = SENSITIVITY_MEDIUM, safety_thresholds: Optional[Dict[str, float]] = None) -> Dict[str, Any]",
          "brief_description": "Main function for evaluating text safety across multiple categories"
        }
      ],
      "external_dependencies": [],
      "complexity_score": 9,
      "module_path": "src/safety/utils.py"
    },
    {
      "filename": "filter.py",
      "module_purpose": "Implements safety filtering mechanisms for validating model inputs and filtering outputs based on safety evaluation results",
      "key_classes": [
        {
          "name": "SafetyFilter",
          "purpose": "Main class for validating inputs and filtering outputs based on safety concerns",
          "key_methods": [
            {
              "name": "validate_input",
              "signature": "def validate_input(self, input_text: str, metadata: Optional[Dict[str, Any]] = None, override: bool = False) -> Tuple[bool, Dict[str, Any]]",
              "brief_description": "Validates input text for safety concerns with optional override"
            },
            {
              "name": "filter_output",
              "signature": "def filter_output(self, output_text: str, metadata: Optional[Dict[str, Any]] = None) -> Tuple[str, Dict[str, Any]]",
              "brief_description": "Filters output text to ensure safety and remove unsafe content"
            },
            {
              "name": "_redact_unsafe_content",
              "signature": "def _redact_unsafe_content(self, text: str, evaluation: Dict[str, Any]) -> str",
              "brief_description": "Redacts unsafe content from text based on safety evaluation"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "re",
            "typing",
            "evaluator",
            "utils"
          ]
        }
      ],
      "external_dependencies": [],
      "complexity_score": 8,
      "module_path": "src/safety/filter.py"
    },
    {
      "filename": "evaluator.py",
      "module_purpose": "Provides a comprehensive framework for evaluating model outputs for safety concerns with configurable sensitivity levels",
      "key_classes": [
        {
          "name": "SafetyEvaluator",
          "purpose": "Main class for safety evaluation with configurable thresholds and sensitivity levels",
          "key_methods": [
            {
              "name": "evaluate_text",
              "signature": "evaluate_text(self, text: str) -> Dict[str, Any]",
              "brief_description": "Evaluates text for safety concerns across multiple categories and returns detailed results"
            },
            {
              "name": "log_evaluation",
              "signature": "log_evaluation(self, text: str, results: Dict[str, Any], metadata: Optional[Dict[str, Any]] = None) -> None",
              "brief_description": "Records safety evaluation results for analysis and tracking"
            },
            {
              "name": "set_sensitivity",
              "signature": "set_sensitivity(self, sensitivity: str) -> None",
              "brief_description": "Adjusts the sensitivity level of safety checks based on application requirements"
            },
            {
              "name": "get_safety_summary",
              "signature": "get_safety_summary(self) -> Dict[str, Any]",
              "brief_description": "Provides aggregate statistics on past evaluations and current settings"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "typing",
            "re",
            "json",
            "os",
            ".utils"
          ]
        }
      ],
      "external_dependencies": [
        "numpy",
        "torch"
      ],
      "complexity_score": 8,
      "module_path": "src/safety/evaluator.py"
    },
    {
      "filename": "framework.py",
      "module_purpose": "Provides a framework for conducting red teaming exercises on language models",
      "key_classes": [
        {
          "name": "RedTeamingFramework",
          "purpose": "Framework for organizing, executing, and analyzing adversarial testing strategies",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, output_dir: str = \"red_team_results\", log_results: bool = True)",
              "brief_description": "Initialize the red teaming framework with output configuration"
            },
            {
              "name": "register_attack_strategy",
              "signature": "register_attack_strategy(self, name: str, strategy_fn: Callable[[str], List[str]]) -> None",
              "brief_description": "Register an attack strategy function for generating adversarial inputs"
            },
            {
              "name": "generate_adversarial_inputs",
              "signature": "generate_adversarial_inputs(self, base_prompts: List[str], strategy_name: Optional[str] = None, num_variations: int = 5) -> Dict[str, List[str]]",
              "brief_description": "Generate adversarial inputs using registered strategies"
            },
            {
              "name": "evaluate_model_robustness",
              "signature": "evaluate_model_robustness(self, model_fn: Callable[[str], str], adversarial_inputs: Dict[str, List[str]], evaluation_fn: Callable[[str, str], Dict[str, Any]], model_name: str = \"unnamed_model\") -> Dict[str, Any]",
              "brief_description": "Evaluate model robustness against adversarial inputs"
            },
            {
              "name": "generate_report",
              "signature": "generate_report(self, results: Optional[Dict[str, Any]] = None, include_details: bool = False) -> str",
              "brief_description": "Generate a human-readable report from evaluation results"
            }
          ],
          "inheritance": "",
          "dependencies": [
            "os",
            "json",
            "datetime",
            "typing"
          ]
        }
      ],
      "external_dependencies": [
        "json",
        "datetime"
      ],
      "complexity_score": 7,
      "module_path": "src/safety/red_teaming/framework.py"
    },
    {
      "filename": "generators.py",
      "module_purpose": "Provides strategies for generating adversarial inputs to test model robustness and safety",
      "key_classes": [
        {
          "name": "AdversarialInputGenerator",
          "purpose": "Collection of methods for creating adversarial prompts to test model boundaries",
          "key_methods": [
            {
              "name": "directive_smuggling",
              "signature": "directive_smuggling(prompt: str) -> List[str]",
              "brief_description": "Generate inputs that attempt to smuggle harmful directives into prompts"
            },
            {
              "name": "prompt_injection",
              "signature": "prompt_injection(prompt: str) -> List[str]",
              "brief_description": "Generate inputs that attempt to inject malicious instructions"
            },
            {
              "name": "context_manipulation",
              "signature": "context_manipulation(prompt: str) -> List[str]",
              "brief_description": "Generate inputs that manipulate the context to elicit problematic outputs"
            },
            {
              "name": "goal_hijacking",
              "signature": "goal_hijacking(prompt: str) -> List[str]",
              "brief_description": "Generate inputs that attempt to hijack the model's goal"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "re",
            "random"
          ]
        }
      ],
      "external_dependencies": [
        "re",
        "random"
      ],
      "complexity_score": 7,
      "module_path": "src/safety/red_teaming/generators.py"
    },
    {
      "filename": "model_loader.py",
      "module_path": "src/safety/red_teaming/model_loader.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "prompt_injection.py",
      "module_path": "src/safety/red_teaming/prompt_injection.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "evaluator.py",
      "module_purpose": "Provides evaluation tools for measuring model robustness against adversarial attacks",
      "key_classes": [
        {
          "name": "AdversarialRobustnessEvaluator",
          "purpose": "Evaluates model robustness against various adversarial inputs and attacks",
          "key_methods": [
            {
              "name": "evaluate",
              "signature": "evaluate(self, prompt: str, response: str) -> Dict[str, Any]",
              "brief_description": "Evaluate model robustness based on prompt-response pair"
            },
            {
              "name": "_evaluate_jailbreak_success",
              "signature": "_evaluate_jailbreak_success(self, prompt: str, response: str) -> Dict[str, Any]",
              "brief_description": "Evaluate whether a jailbreak attempt was successful"
            },
            {
              "name": "_evaluate_harmful_content",
              "signature": "_evaluate_harmful_content(self, prompt: str, response: str) -> Dict[str, Any]",
              "brief_description": "Evaluate whether the response contains harmful content"
            },
            {
              "name": "_evaluate_response_consistency",
              "signature": "_evaluate_response_consistency(self, prompt: str, response: str) -> Dict[str, Any]",
              "brief_description": "Evaluate whether the response is consistent or shows signs of manipulation"
            },
            {
              "name": "_evaluate_instruction_following",
              "signature": "_evaluate_instruction_following(self, prompt: str, response: str) -> Dict[str, Any]",
              "brief_description": "Evaluate whether the model improperly followed harmful instructions"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "src.safety.evaluator.SafetyEvaluator",
            "re",
            "json"
          ]
        }
      ],
      "external_dependencies": [
        "re",
        "json"
      ],
      "complexity_score": 8,
      "module_path": "src/safety/red_teaming/evaluator.py"
    },
    {
      "filename": "flickr30k_multistage_config.py",
      "module_path": "src/configs/flickr30k_multistage_config.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "training_config.py",
      "module_path": "src/configs/training_config.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "stage_config.py",
      "module_path": "src/configs/stage_config.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "translation_metrics.py",
      "module_purpose": "Implements standard evaluation metrics for machine translation tasks including BLEU and TER scoring",
      "key_functions": [
        {
          "name": "calculate_bleu",
          "signature": "calculate_bleu(hypotheses: List[str], references: List[str], weights: Tuple[float, ...] = (0.4, 0.3, 0.2, 0.1)) -> float",
          "brief_description": "Calculates BLEU score for translation quality using NLTK's implementation with smoothing"
        },
        {
          "name": "calculate_ter",
          "signature": "calculate_ter(hypotheses: List[str], references: List[str]) -> float",
          "brief_description": "Calculates Translation Edit Rate (TER) to measure edit distance between translations"
        },
        {
          "name": "evaluate_translation",
          "signature": "evaluate_translation(hypotheses: List[str], references: List[str]) -> Dict[str, float]",
          "brief_description": "Evaluates translation quality using multiple metrics and returns consolidated results"
        },
        {
          "name": "print_evaluation_results",
          "signature": "print_evaluation_results(scores: Dict[str, float])",
          "brief_description": "Formats and prints evaluation results in a readable format"
        }
      ],
      "external_dependencies": [
        "numpy",
        "nltk",
        "re"
      ],
      "complexity_score": 3,
      "module_path": "src/evaluation/translation_metrics.py"
    },
    {
      "filename": "language_model_evaluation.py",
      "module_purpose": "Provides comprehensive evaluation utilities for language models, including perplexity calculation, attention visualization, and token probability analysis",
      "key_classes": [
        {
          "name": "LanguageModelEvaluator",
          "purpose": "Evaluation class for language models with metrics and visualization capabilities",
          "key_methods": [
            {
              "name": "calculate_perplexity",
              "signature": "calculate_perplexity(self, text: str) -> float",
              "brief_description": "Calculates perplexity score for a given text under the model"
            },
            {
              "name": "calculate_batch_perplexity",
              "signature": "calculate_batch_perplexity(self, texts: List[str]) -> Dict[str, Union[float, List[float]]]",
              "brief_description": "Calculate perplexity for a batch of texts with optimized processing"
            },
            {
              "name": "visualize_attention",
              "signature": "visualize_attention(self, text: str, layer: int = -1, head: int = 0, attention_type: str = 'self', cmap: str = 'viridis') -> Figure",
              "brief_description": "Visualizes attention patterns for a given text at specified layer and head"
            },
            {
              "name": "visualize_attention_patterns",
              "signature": "visualize_attention_patterns(self, text: str, save_dir: Optional[str] = None) -> List[Figure]",
              "brief_description": "Visualizes attention patterns across all layers and heads"
            },
            {
              "name": "analyze_token_probabilities",
              "signature": "analyze_token_probabilities(self, text: str) -> Dict[str, Any]",
              "brief_description": "Analyzes token probabilities in a text to identify high and low confidence predictions"
            },
            {
              "name": "evaluate_on_dataset",
              "signature": "evaluate_on_dataset(self, texts: List[str], save_path: Optional[str] = None) -> Dict[str, Any]",
              "brief_description": "Evaluates model performance on a dataset of texts"
            },
            {
              "name": "plot_perplexity_distribution",
              "signature": "plot_perplexity_distribution(self, perplexities: List[float], save_path: Optional[str] = None) -> Figure",
              "brief_description": "Plot the distribution of perplexities as a histogram with statistics"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "numpy",
            "matplotlib",
            "seaborn"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "matplotlib",
        "seaborn"
      ],
      "complexity_score": 7,
      "module_path": "src/evaluation/language_model_evaluation.py"
    },
    {
      "filename": "inference_demo.py",
      "module_purpose": "Inference demo utilities for multimodal models",
      "key_functions": [
        {
          "name": "run_inference_demo",
          "signature": "run_inference_demo(model: nn.Module, image_preprocessor: Any, tokenizer: Any, device: torch.device, args: Any) -> Dict[str, float]",
          "brief_description": "Run inference demo with visualizations and metrics"
        }
      ],
      "external_dependencies": [
        "torch",
        "matplotlib",
        "logging"
      ],
      "complexity_score": 7,
      "module_path": "src/evaluation/inference_demo.py"
    },
    {
      "filename": "wmt_dataset.py",
      "module_purpose": "Provides a dataset class for loading and preprocessing WMT dataset for machine translation",
      "key_classes": [
        {
          "name": "WMTDataset",
          "purpose": "Handles loading and preprocessing parallel text data from the WMT dataset",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, src_lang='de', tgt_lang='en', year='14', split='train', max_examples=None, data_dir='data/wmt', random_seed=42, subset=None)",
              "brief_description": "Initialize the dataset with source/target languages and processing options"
            },
            {
              "name": "load_data",
              "signature": "load_data(self) -> Tuple[List[str], List[str]]",
              "brief_description": "Load and preprocess parallel corpora from WMT dataset"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "os",
            "random",
            "tqdm"
          ]
        }
      ],
      "external_dependencies": [
        "datasets"
      ],
      "complexity_score": 4,
      "module_path": "src/data/wmt_dataset.py"
    },
    {
      "filename": "curriculum_dataset.py",
      "module_purpose": "Implements curriculum learning for translation datasets, gradually increasing difficulty during training",
      "key_classes": [
        {
          "name": "CurriculumTranslationDataset",
          "purpose": "Dataset that implements curriculum learning strategies for translation tasks",
          "key_methods": [
            {
              "name": "_calculate_difficulties",
              "signature": "_calculate_difficulties(self) -> List[float]",
              "brief_description": "Calculate difficulty scores for all examples based on selected strategy"
            },
            {
              "name": "update_stage",
              "signature": "update_stage(self, new_stage: int) -> None",
              "brief_description": "Update the curriculum stage to expose more complex examples"
            },
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx: int) -> Dict[str, torch.Tensor]",
              "brief_description": "Get an item from the dataset based on curriculum stage"
            },
            {
              "name": "get_curriculum_stats",
              "signature": "get_curriculum_stats(self) -> Dict[str, Any]",
              "brief_description": "Get statistics about the current curriculum stage"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch.utils.data.Dataset",
            "numpy",
            "collections.Counter"
          ]
        }
      ],
      "key_functions": [],
      "external_dependencies": [
        "torch",
        "numpy",
        "collections"
      ],
      "complexity_score": 7,
      "module_path": "src/data/curriculum_dataset.py"
    },
    {
      "filename": "image_dataset.py",
      "module_purpose": "Provides dataset functionality for loading and preprocessing image data for vision transformer models",
      "key_classes": [
        {
          "name": "ImageDataset",
          "purpose": "Dataset for loading and preprocessing images for vision transformer models",
          "key_methods": [
            {
              "name": "_get_class_idx",
              "signature": "_get_class_idx(self, class_name: str) -> int",
              "brief_description": "Get class index from class name using mapping or dynamic creation"
            },
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx: int) -> Dict[str, torch.Tensor]",
              "brief_description": "Load, preprocess and return an image with its label and path"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch.utils.data.Dataset",
            "PIL.Image",
            "ImagePreprocessor"
          ]
        }
      ],
      "key_functions": [],
      "external_dependencies": [
        "torch",
        "PIL",
        "pathlib",
        "json"
      ],
      "complexity_score": 4,
      "module_path": "src/data/image_dataset.py"
    },
    {
      "filename": "augmentation_pipeline.py",
      "module_purpose": "Provides comprehensive augmentation capabilities for multimodal datasets",
      "key_classes": [
        {
          "name": "MultimodalAugmentationPipeline",
          "purpose": "Configurable pipeline for applying augmentations to both image and text data",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, image_augs: Optional[List[Callable]] = None, text_augs: Optional[List[Callable]] = None, image_aug_prob: float = 0.5, text_aug_prob: float = 0.3, consistency_mode: str = 'matched', image_size: int = 224, severity: str = 'medium', random_erasing_prob: float = 0.0, random_erasing_scale: Tuple[float, float] = (0.02, 0.33), color_jitter_prob: float = 0.0, random_resized_crop: bool = True, debug_mode: bool = False)",
              "brief_description": "Initialize the augmentation pipeline with configurable parameters"
            },
            {
              "name": "augment_image",
              "signature": "augment_image(self, image: torch.Tensor) -> torch.Tensor",
              "brief_description": "Apply image augmentations with probability"
            },
            {
              "name": "augment_text",
              "signature": "augment_text(self, text_data: Union[str, Dict]) -> Union[str, Dict]",
              "brief_description": "Apply text augmentations with probability"
            },
            {
              "name": "__call__",
              "signature": "__call__(self, batch: Dict[str, Union[torch.Tensor, Dict]]) -> Dict[str, Union[torch.Tensor, Dict]]",
              "brief_description": "Apply augmentations to a batch of multimodal data"
            }
          ],
          "inheritance": "object"
        },
        {
          "name": "TextAugmentation",
          "purpose": "Base class for text augmentation transforms",
          "inheritance": "object"
        },
        {
          "name": "DropWords",
          "purpose": "Randomly drop words from text",
          "inheritance": "TextAugmentation"
        },
        {
          "name": "ShuffleWords",
          "purpose": "Shuffle some words within a window",
          "inheritance": "TextAugmentation"
        },
        {
          "name": "ReplaceWithSynonym",
          "purpose": "Replace words with simple synonyms",
          "inheritance": "TextAugmentation"
        },
        {
          "name": "ChangeWordOrder",
          "purpose": "Change the order of phrases in text",
          "inheritance": "TextAugmentation"
        },
        {
          "name": "AddMisspelling",
          "purpose": "Add simple misspellings to text",
          "inheritance": "TextAugmentation"
        },
        {
          "name": "RandomPosterize",
          "purpose": "Apply posterization to images",
          "inheritance": "nn.Module"
        }
      ],
      "external_dependencies": [
        "torch",
        "torchvision",
        "PIL",
        "random",
        "numpy"
      ],
      "complexity_score": 8,
      "module_path": "src/data/augmentation_pipeline.py"
    },
    {
      "filename": "wmt_dataloader.py",
      "module_purpose": "Provides a data loader for WMT (Workshop on Machine Translation) parallel corpus",
      "key_classes": [
        {
          "name": "WMTDataLoader",
          "purpose": "Loads and preprocesses WMT parallel corpus data with batching capability",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, data_dir: str, source_lang: str, target_lang: str, batch_size: int = 32, max_examples: Optional[int] = None, seed: int = 42, shuffle: bool = True)",
              "brief_description": "Initialize the WMT data loader with configurable batch size and filtering"
            },
            {
              "name": "load_data",
              "signature": "load_data(self) -> Tuple[List[str], List[str]]",
              "brief_description": "Load and preprocess parallel data"
            },
            {
              "name": "__iter__",
              "signature": "__iter__(self) -> Tuple[List[str], List[str]]",
              "brief_description": "Yield batches of source and target sentences"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "os",
            "random"
          ]
        }
      ],
      "external_dependencies": [
        "os",
        "random"
      ],
      "complexity_score": 3,
      "module_path": "src/data/wmt_dataloader.py"
    },
    {
      "filename": "combined_dataset.py",
      "module_path": "src/data/combined_dataset.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "augmentation.py",
      "module_path": "src/data/augmentation.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "iwslt_dataset.py",
      "module_purpose": "Provides a dataset class for loading and preprocessing IWSLT dataset for machine translation",
      "key_classes": [
        {
          "name": "IWSLTDataset",
          "purpose": "Handles loading and preprocessing parallel text data from the IWSLT dataset",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, src_lang='de', tgt_lang='en', year='2017', split='train', max_examples=None, data_dir='data/iwslt', random_seed=42, combine_years=True)",
              "brief_description": "Initialize the dataset with source/target languages and processing options"
            },
            {
              "name": "download_data",
              "signature": "download_data(self, year=None)",
              "brief_description": "Download and prepare the IWSLT dataset for a specific year with fallback to synthetic data generation"
            },
            {
              "name": "load_data",
              "signature": "load_data(self) -> Tuple[List[str], List[str]]",
              "brief_description": "Load and preprocess parallel corpora, combining data from multiple years if needed"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "os",
            "random",
            "requests",
            "tqdm",
            "tarfile",
            "io"
          ]
        }
      ],
      "external_dependencies": [
        "datasets"
      ],
      "complexity_score": 5,
      "module_path": "src/data/iwslt_dataset.py"
    },
    {
      "filename": "language_modeling.py",
      "module_purpose": "Implements dataset and dataloaders for language modeling tasks with efficient tokenization and batching",
      "key_classes": [
        {
          "name": "LanguageModelingDataset",
          "purpose": "Dataset for causal language modeling with next-token prediction setup",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, texts: List[str], tokenizer: BPETokenizer, max_length: int = 512, pad_idx: int = 0, bos_idx: int = 1, eos_idx: int = 2)",
              "brief_description": "Initializes dataset and tokenizes all texts upfront for efficiency"
            },
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx: int) -> Dict[str, torch.Tensor]",
              "brief_description": "Creates input-target pairs for next-token prediction tasks"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch",
            "torch.utils.data",
            "tokenization.BPETokenizer"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "lm_collate_fn",
          "signature": "lm_collate_fn(batch: List[Dict[str, torch.Tensor]], pad_idx: int) -> Dict[str, torch.Tensor]",
          "brief_description": "Collates and pads batches for efficient training"
        },
        {
          "name": "create_lm_dataloaders",
          "signature": "create_lm_dataloaders(texts: List[str], tokenizer: BPETokenizer, batch_size: int = 16, max_length: int = 512, val_split: float = 0.1, seed: int = 42) -> tuple",
          "brief_description": "Creates training and validation dataloaders with proper data splitting"
        }
      ],
      "external_dependencies": [
        "torch",
        "tqdm",
        "random"
      ],
      "complexity_score": 5,
      "module_path": "src/data/language_modeling.py"
    },
    {
      "filename": "europarl_dataset.py",
      "module_purpose": "Provides a dataset class for loading and preprocessing Europarl parallel corpus data",
      "key_classes": [
        {
          "name": "EuroparlDataset",
          "purpose": "Handles loading and preprocessing parallel text data from the Europarl corpus",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, data_dir: str = 'data/europarl', src_lang: str = 'de', tgt_lang: str = 'en', max_examples: Optional[int] = None, random_seed: int = 42)",
              "brief_description": "Initialize the dataset with language pair and optional filtering"
            },
            {
              "name": "load_data",
              "signature": "load_data(self) -> Tuple[List[str], List[str]]",
              "brief_description": "Load and preprocess parallel data with multiple file pattern detection"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "os",
            "random"
          ]
        }
      ],
      "external_dependencies": [
        "os",
        "random"
      ],
      "complexity_score": 4,
      "module_path": "src/data/europarl_dataset.py"
    },
    {
      "filename": "combined_wmt_translation_dataset.py",
      "module_path": "src/data/combined_wmt_translation_dataset.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "combined_translation_dataset.py",
      "module_purpose": "Implements dataset class for combining multiple translation datasets with configurable sampling",
      "key_classes": [
        {
          "name": "CombinedTranslationDataset",
          "purpose": "Combines samples from multiple translation datasets for unified training",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, src_lang: str = 'de', tgt_lang: str = 'en', datasets: Dict[str, int] = None, seed: int = 42)",
              "brief_description": "Initialize the combined dataset with configurable sources and sample counts"
            }
          ],
          "inheritance": "",
          "dependencies": [
            ".europarl_dataset",
            ".opensubtitles_dataset"
          ]
        }
      ],
      "external_dependencies": [],
      "complexity_score": 2,
      "module_path": "src/data/combined_translation_dataset.py"
    },
    {
      "filename": "multimodal_data_utils.py",
      "module_purpose": "Provides utility functions for handling multimodal data including image-text pairs and feature processing",
      "key_classes": [
        {
          "name": "SemanticBatchSampler",
          "purpose": "Sample batch items to ensure related semantic content is grouped together",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, match_ids, batch_size, min_samples_per_group=4)",
              "brief_description": "Create semantically meaningful batches for contrastive learning"
            },
            {
              "name": "_create_semantic_groups",
              "signature": "_create_semantic_groups(self)",
              "brief_description": "Group samples by match_id for semantic batching"
            }
          ],
          "inheritance": "Sampler",
          "dependencies": [
            "torch.utils.data",
            "collections.defaultdict"
          ]
        },
        {
          "name": "SemanticGroupBatchSampler",
          "purpose": "Advanced batch sampler ensuring each batch contains multiple examples from the same semantic groups",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, dataset: Any, batch_size: int, drop_last: bool = True, min_samples_per_group: int = 2, max_samples_per_group: Optional[int] = None, cap_strategy: str = 'random', groups_per_batch: Optional[int] = None)",
              "brief_description": "Initialize sampler with semantic grouping parameters"
            },
            {
              "name": "_get_match_ids",
              "signature": "_get_match_ids(self) -> List[str]",
              "brief_description": "Extract match_ids from the dataset"
            },
            {
              "name": "_apply_random_capping",
              "signature": "_apply_random_capping(self) -> Dict[str, List[int]]",
              "brief_description": "Cap group sizes by randomly selecting samples"
            },
            {
              "name": "_apply_split_capping",
              "signature": "_apply_split_capping(self) -> Dict[str, List[int]]",
              "brief_description": "Cap group sizes by creating new smaller groups"
            },
            {
              "name": "__iter__",
              "signature": "__iter__(self) -> Iterator[List[int]]",
              "brief_description": "Generate batches with proper semantic grouping"
            }
          ],
          "inheritance": "BatchSampler",
          "dependencies": [
            "torch.utils.data",
            "collections.defaultdict",
            "random"
          ]
        },
        {
          "name": "MultimodalDataset",
          "purpose": "Enhanced dataset for feature statistics and semantic grouping",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, vision_data: Dict[str, torch.Tensor], text_data: Dict[str, torch.Tensor], match_ids: List[str], feature_dim: int = 512, diversity_weight: float = 0.1, min_group_size: int = 2, max_group_size: int = 10)",
              "brief_description": "Initialize dataset with feature diversity and semantic grouping"
            },
            {
              "name": "_compute_feature_diversity",
              "signature": "_compute_feature_diversity(self, features: torch.Tensor) -> torch.Tensor",
              "brief_description": "Compute diversity score for a set of features"
            },
            {
              "name": "get_diverse_features",
              "signature": "get_diverse_features(self, num_features: int) -> Tuple[torch.Tensor, torch.Tensor]",
              "brief_description": "Get diverse features by selecting from different semantic groups"
            }
          ],
          "inheritance": null,
          "dependencies": [
            "torch",
            "collections.defaultdict"
          ]
        },
        {
          "name": "FeatureStats",
          "purpose": "Store and track statistics about feature vectors",
          "key_fields": [
            "mean: torch.Tensor",
            "std: torch.Tensor",
            "count: int"
          ],
          "inheritance": "dataclass",
          "dependencies": [
            "torch",
            "dataclasses"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "randomize_dataset_positions",
          "signature": "randomize_dataset_positions(dataset: Any) -> List[int]",
          "brief_description": "Create randomized batch indices for a dataset to break position correlations"
        },
        {
          "name": "create_data_loaders",
          "signature": "create_data_loaders(args: Any, image_preprocessor: Any, tokenizer: Any) -> Tuple[DataLoader, DataLoader, DataLoader]",
          "brief_description": "Create train, validation, and test data loaders with appropriate configurations"
        }
      ],
      "external_dependencies": [
        "torch",
        "PIL",
        "numpy",
        "torchvision"
      ],
      "complexity_score": 8,
      "module_path": "src/data/multimodal_data_utils.py"
    },
    {
      "filename": "fixed_semantic_sampler.py",
      "module_path": "src/data/fixed_semantic_sampler.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "multimodal_dataset.py",
      "module_purpose": "Implements dataset classes for handling multimodal data pairs with support for various data formats and preprocessing",
      "key_classes": [
        {
          "name": "MultimodalDataset",
          "purpose": "Base dataset class for handling image-text pairs with configurable preprocessing",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, data_root: str, image_processor: Optional[Union[ImagePreprocessor, transforms.Compose]] = None, text_tokenizer=None, max_text_length: int = 77, split: str = 'train', transform_image: Optional[Callable] = None, transform_text: Optional[Callable] = None, metadata_file: str = 'metadata.json', image_key: str = 'image_path', caption_key: str = 'caption', label_key: Optional[str] = 'label', image_dir: str = 'images', limit_samples: Optional[int] = None, return_metadata: bool = False)",
              "brief_description": "Initialize dataset with data path and preprocessing options"
            },
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx: int) -> Dict[str, Any]",
              "brief_description": "Get a processed image-text pair with optional transformations"
            },
            {
              "name": "_load_metadata",
              "signature": "_load_metadata(self, metadata_path: str, split: str) -> List[Dict]",
              "brief_description": "Load and validate dataset metadata from file"
            },
            {
              "name": "get_hard_negative",
              "signature": "get_hard_negative(self, idx: int, neg_type: str = 'same_class') -> int",
              "brief_description": "Get index of hard negative sample for contrastive learning"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch.utils.data",
            "PIL",
            "torchvision"
          ]
        },
        {
          "name": "Flickr30kDataset",
          "purpose": "Specialized dataset for Flickr30k with 5 captions per image support",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, data_root: str = '', image_processor: Optional[Union[ImagePreprocessor, transforms.Compose]] = None, text_tokenizer=None, max_text_length: int = 77, split: str = 'train', transform_image: Optional[Callable] = None, transform_text: Optional[Callable] = None, limit_samples: Optional[int] = None, return_metadata: bool = False)",
              "brief_description": "Initialize Flickr30k dataset with specialized configuration"
            },
            {
              "name": "_load_from_cache",
              "signature": "_load_from_cache(self) -> bool",
              "brief_description": "Load preprocessed dataset from cache if available"
            },
            {
              "name": "_generate_synthetic_data",
              "signature": "_generate_synthetic_data(self)",
              "brief_description": "Create synthetic data for testing when real data unavailable"
            }
          ],
          "inheritance": "MultimodalDataset",
          "dependencies": [
            "torch.utils.data",
            "PIL",
            "torchvision"
          ]
        },
        {
          "name": "EnhancedMultimodalDataset",
          "purpose": "Advanced dataset with semantic grouping, caching, and multiple caption support",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, split: str = 'train', image_preprocessor=None, tokenizer=None, max_text_length: int = 77, dataset_name: str = 'flickr30k', synthetic_samples: int = 100, cache_dir: Optional[str] = None, max_samples: Optional[int] = None, captions_per_image: int = 1, min_samples_per_group: int = 2, max_samples_per_group: Optional[int] = None, cap_strategy: str = 'random')",
              "brief_description": "Initialize enhanced dataset with advanced configuration options"
            },
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx)",
              "brief_description": "Get sample with proper format for MultimodalTrainer including match_id"
            },
            {
              "name": "_load_flickr30k",
              "signature": "_load_flickr30k(self)",
              "brief_description": "Load and process Flickr30k dataset with semantic grouping"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch.utils.data",
            "PIL",
            "Image"
          ]
        }
      ],
      "external_dependencies": [
        "torch",
        "PIL",
        "numpy",
        "torchvision"
      ],
      "complexity_score": 8,
      "module_path": "src/data/multimodal_dataset.py"
    },
    {
      "filename": "preprocessing.py",
      "module_purpose": "Provides data preprocessing utilities for time series data and machine learning datasets",
      "key_classes": [
        {
          "name": "DataPreprocessor",
          "purpose": "Handles data preprocessing operations like standardization and normalization",
          "key_methods": [
            {
              "name": "fit",
              "signature": "fit(self, data: Union[torch.Tensor, np.ndarray]) -> None",
              "brief_description": "Fit the preprocessor on the data"
            },
            {
              "name": "transform",
              "signature": "transform(self, data: Union[torch.Tensor, np.ndarray]) -> torch.Tensor",
              "brief_description": "Transform the data using the fitted preprocessor"
            },
            {
              "name": "fit_transform",
              "signature": "fit_transform(self, data: Union[torch.Tensor, np.ndarray]) -> torch.Tensor",
              "brief_description": "Fit the preprocessor and transform the data"
            },
            {
              "name": "inverse_transform",
              "signature": "inverse_transform(self, data: Union[torch.Tensor, np.ndarray]) -> torch.Tensor",
              "brief_description": "Inverse transform data back to original scale"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch",
            "numpy",
            "sklearn.preprocessing"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "create_sequences",
          "signature": "create_sequences(data: torch.Tensor, seq_length: int) -> Tuple[torch.Tensor, torch.Tensor]",
          "brief_description": "Create input-target sequences from time series data"
        },
        {
          "name": "split_data",
          "signature": "split_data(data: torch.Tensor, train_ratio: float = 0.8, val_ratio: float = 0.1) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]",
          "brief_description": "Split data into train, validation, and test sets"
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy",
        "sklearn"
      ],
      "complexity_score": 4,
      "module_path": "src/data/preprocessing.py"
    },
    {
      "filename": "sequence_data.py",
      "module_purpose": "Provides dataset and dataloader utilities for transformer sequence-to-sequence tasks",
      "key_classes": [
        {
          "name": "TransformerDataset",
          "purpose": "Dataset for handling tokenized source and target sequences for transformer models",
          "key_methods": [
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx)",
              "brief_description": "Get source and target sequences with proper BOS/EOS tokens and truncation"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch.utils.data.Dataset"
          ]
        },
        {
          "name": "TransformerCollator",
          "purpose": "Collator class for batching transformer sequences with padding",
          "key_methods": [
            {
              "name": "__call__",
              "signature": "__call__(self, batch: List[Dict[str, List[int]]]) -> Dict[str, torch.Tensor]",
              "brief_description": "Collate a batch of data with proper padding"
            }
          ],
          "inheritance": "object",
          "dependencies": []
        },
        {
          "name": "TransformerDataModule",
          "purpose": "Complete data module for handling loading, preprocessing, and batching transformer data",
          "key_methods": [
            {
              "name": "_setup",
              "signature": "_setup(self)",
              "brief_description": "Set up datasets and dataloaders with train/validation splits"
            },
            {
              "name": "get_train_dataloader",
              "signature": "get_train_dataloader(self)",
              "brief_description": "Get the training dataloader"
            },
            {
              "name": "get_val_dataloader",
              "signature": "get_val_dataloader(self)",
              "brief_description": "Get the validation dataloader"
            },
            {
              "name": "_collate_fn",
              "signature": "_collate_fn(self, batch)",
              "brief_description": "Collate function to create batches with padding"
            },
            {
              "name": "update_curriculum_stage",
              "signature": "update_curriculum_stage(self, epoch: int) -> None",
              "brief_description": "Update curriculum stage based on epoch"
            },
            {
              "name": "get_curriculum_stats",
              "signature": "get_curriculum_stats(self) -> Dict[str, Any]",
              "brief_description": "Get statistics about the current curriculum stage"
            },
            {
              "name": "estimate_steps_per_epoch",
              "signature": "estimate_steps_per_epoch(self) -> int",
              "brief_description": "Estimate the number of steps per epoch"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "torch.utils.data.DataLoader",
            "numpy"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "transformer_collate_fn",
          "signature": "transformer_collate_fn(batch: List[Dict[str, List[int]]], pad_idx: int) -> Dict[str, torch.Tensor]",
          "brief_description": "Collate function that pads sequences to the same length within a batch"
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy"
      ],
      "complexity_score": 6,
      "module_path": "src/data/sequence_data.py"
    },
    {
      "filename": "opensubtitles_dataset.py",
      "module_purpose": "Provides a dataset class for loading and preprocessing OpenSubtitles parallel corpus data for machine translation",
      "key_classes": [
        {
          "name": "OpenSubtitlesDataset",
          "purpose": "Handles loading and preprocessing parallel text data from the OpenSubtitles corpus",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, data_dir: str = 'data/os', src_lang: str = 'de', tgt_lang: str = 'en', max_examples: Optional[int] = None, random_seed: int = 42)",
              "brief_description": "Initialize the dataset with source/target languages and processing options"
            },
            {
              "name": "load_data",
              "signature": "load_data(self) -> Tuple[List[str], List[str]]",
              "brief_description": "Load and preprocess parallel corpora with support for multiple file patterns"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "os",
            "random",
            "typing"
          ]
        }
      ],
      "external_dependencies": [],
      "complexity_score": 4,
      "module_path": "src/data/opensubtitles_dataset.py"
    },
    {
      "filename": "dataloader.py",
      "module_purpose": "Provides utilities for handling multimodal data with PyTorch DataLoader",
      "key_classes": [
        {
          "name": "MultimodalDataset",
          "purpose": "Dataset class for handling multiple modalities of data with consistent length validation",
          "key_methods": [
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx: int) -> Dict[str, torch.Tensor]",
              "brief_description": "Get an item from each modality at the specified index"
            },
            {
              "name": "__len__",
              "signature": "__len__(self) -> int",
              "brief_description": "Return the length of the dataset"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch.utils.data.Dataset"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "create_dataloader",
          "signature": "create_dataloader(dataset: Dataset, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, collate_fn: Optional[callable] = None) -> DataLoader",
          "brief_description": "Create a DataLoader from a dataset with common configuration options"
        },
        {
          "name": "collate_fn",
          "signature": "collate_fn(batch: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]",
          "brief_description": "Custom collate function for batching multimodal data"
        },
        {
          "name": "get_dataloaders",
          "signature": "get_dataloaders(train_data: Dict[str, torch.Tensor], val_data: Optional[Dict[str, torch.Tensor]] = None, test_data: Optional[Dict[str, torch.Tensor]] = None, batch_size: int = 32, num_workers: int = 0) -> Tuple[DataLoader, Optional[DataLoader], Optional[DataLoader]]",
          "brief_description": "Create DataLoaders for train, validation, and test sets"
        }
      ],
      "external_dependencies": [
        "torch",
        "numpy"
      ],
      "complexity_score": 3,
      "module_path": "src/data/dataloader.py"
    },
    {
      "filename": "dataset_wrapper.py",
      "module_purpose": "Provides dataset wrappers to standardize interfaces for different dataset types",
      "key_classes": [
        {
          "name": "DictionaryDataset",
          "purpose": "Wrapper for datasets that return tuples, converting them to dictionaries for a standardized interface",
          "key_methods": [
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx: int) -> Dict[str, Any]",
              "brief_description": "Get a sample from the dataset as a dictionary with standardized keys"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch.utils.data.Dataset"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "create_dictionary_dataloader",
          "signature": "create_dictionary_dataloader(dataset: Dataset, batch_size: int = 32, shuffle: bool = True, num_workers: int = 4, pin_memory: bool = True, keys: List[str] = None) -> DataLoader",
          "brief_description": "Create a DataLoader that returns dictionary-format batches"
        },
        {
          "name": "load_cifar10_dict",
          "signature": "load_cifar10_dict(batch_size: int = 128, num_workers: int = 4, image_size: int = 32) -> Tuple[DataLoader, DataLoader, List[str]]",
          "brief_description": "Load CIFAR-10 dataset with dictionary-format data loaders"
        }
      ],
      "external_dependencies": [
        "torch",
        "torch.utils.data"
      ],
      "complexity_score": 3,
      "module_path": "src/data/dataset_wrapper.py"
    },
    {
      "filename": "wikipedia_dataset.py",
      "module_purpose": "Provides a dataset class for loading and preprocessing Wikipedia Web2M data from TFRecord format",
      "key_classes": [
        {
          "name": "WikipediaDataset",
          "purpose": "Handles loading and preprocessing multimodal (image-text) data from WikiWeb2M TFRecords",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, data_dir: str = 'data/wiki', split: str = 'train', max_examples: Optional[int] = None, cache_processed_data: bool = True, cache_dir: Optional[str] = None, image_size: int = 224, random_seed: int = 42)",
              "brief_description": "Initialize the dataset with data split and processing options"
            },
            {
              "name": "load_data",
              "signature": "load_data(self) -> Dict[str, List[Any]]",
              "brief_description": "Load and preprocess data from TFRecord files with caching capability"
            },
            {
              "name": "to_pytorch_dataset",
              "signature": "to_pytorch_dataset(self)",
              "brief_description": "Convert to a PyTorch dataset compatible with MultimodalDataset"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "tensorflow",
            "torch",
            "numpy",
            "tqdm"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "create_wiki_dataloaders",
          "signature": "create_wiki_dataloaders(data_dir: str = 'data/wiki', batch_size: int = 32, max_examples: Optional[Dict[str, int]] = None, num_workers: int = 0, image_size: int = 224, random_seed: int = 42) -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader, torch.utils.data.DataLoader]",
          "brief_description": "Create DataLoaders for train, validation, and test sets"
        }
      ],
      "external_dependencies": [
        "tensorflow",
        "torch",
        "numpy",
        "tqdm"
      ],
      "complexity_score": 5,
      "module_path": "src/data/wikipedia_dataset.py"
    },
    {
      "filename": "optimized_bpe_tokenizer.py",
      "module_purpose": "Implements an optimized Byte Pair Encoding tokenizer with smart caching and batch processing",
      "key_classes": [
        {
          "name": "LRUCache",
          "purpose": "LRU (Least Recently Used) Cache with expiration for efficient tokenizer caching",
          "key_methods": [
            {
              "name": "get",
              "signature": "get(self, key: Any) -> Optional[Any]",
              "brief_description": "Get a value from the cache with expiration checking"
            },
            {
              "name": "put",
              "signature": "put(self, key: Any, value: Any) -> None",
              "brief_description": "Add or update a value in the cache with timestamp"
            },
            {
              "name": "_cleanup_expired",
              "signature": "_cleanup_expired(self) -> None",
              "brief_description": "Remove expired items from cache"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "collections.OrderedDict",
            "threading"
          ]
        },
        {
          "name": "OptimizedBPETokenizer",
          "purpose": "High-performance BPE tokenizer with caching, vectorization, and memory efficiency",
          "key_methods": [
            {
              "name": "tokenize",
              "signature": "tokenize(self, text: str) -> List[str]",
              "brief_description": "Convert text to tokens with caching and validation"
            },
            {
              "name": "encode",
              "signature": "encode(self, text: str) -> List[int]",
              "brief_description": "Convert text to token indices"
            },
            {
              "name": "batch_encode_optimized",
              "signature": "batch_encode_optimized(self, texts: List[str], batch_size: Optional[int] = None) -> List[List[int]]",
              "brief_description": "Encode a batch of texts with optimized processing"
            },
            {
              "name": "train",
              "signature": "train(self, texts: List[str], vocab_size: Optional[int] = None, min_frequency: int = 2, show_progress: bool = True) -> None",
              "brief_description": "Train the BPE tokenizer on a corpus of texts"
            }
          ],
          "inheritance": "BaseTokenizer",
          "dependencies": [
            ".base_tokenizer",
            ".vocabulary",
            "torch",
            "psutil"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "preprocess_data_with_optimized_bpe",
          "signature": "preprocess_data_with_optimized_bpe(dataset, de_tokenizer, en_tokenizer, batch_size=4000, use_multiprocessing=False, num_workers=4)",
          "brief_description": "Efficiently preprocess translation data with optimized BPE tokenizers"
        }
      ],
      "external_dependencies": [
        "torch",
        "psutil",
        "tqdm",
        "threading",
        "json"
      ],
      "complexity_score": 9,
      "module_path": "src/data/tokenization/optimized_bpe_tokenizer.py"
    },
    {
      "filename": "base_tokenizer.py",
      "module_purpose": "Defines the abstract base class for all tokenizers in the system with standard interface",
      "key_classes": [
        {
          "name": "BaseTokenizer",
          "purpose": "Abstract base class that defines the standard interface for all tokenizer implementations",
          "key_methods": [
            {
              "name": "tokenize",
              "signature": "tokenize(self, text: str) -> List[str]",
              "brief_description": "Convert text into tokens"
            },
            {
              "name": "encode",
              "signature": "encode(self, text: str) -> List[int]",
              "brief_description": "Convert text to token indices"
            },
            {
              "name": "decode",
              "signature": "decode(self, token_ids: List[int]) -> str",
              "brief_description": "Convert token indices back to text"
            },
            {
              "name": "batch_encode",
              "signature": "batch_encode(self, texts: List[str]) -> List[List[int]]",
              "brief_description": "Encode multiple texts efficiently"
            },
            {
              "name": "vocab_size",
              "signature": "vocab_size(self) -> int",
              "brief_description": "Get the size of the vocabulary"
            },
            {
              "name": "special_tokens",
              "signature": "special_tokens(self) -> Dict[str, int]",
              "brief_description": "Get the special tokens used by this tokenizer"
            }
          ],
          "inheritance": "ABC",
          "dependencies": [
            "abc.ABC"
          ]
        }
      ],
      "external_dependencies": [
        "abc"
      ],
      "complexity_score": 2,
      "module_path": "src/data/tokenization/base_tokenizer.py"
    },
    {
      "filename": "utils.py",
      "module_purpose": "Provides utility functions and classes for tokenization and text processing in transformer models",
      "key_classes": [
        {
          "name": "TransformerTextDataset",
          "purpose": "PyTorch dataset for transformer text processing with support for BOS/EOS tokens and attention masks",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, texts: List[str], tokenizer: BaseTokenizer, max_length: Optional[int] = None, add_bos: bool = True, add_eos: bool = True, return_tensors: bool = True)",
              "brief_description": "Initialize dataset with texts and tokenization parameters"
            },
            {
              "name": "__getitem__",
              "signature": "__getitem__(self, idx: int) -> Dict[str, Any]",
              "brief_description": "Get a processed example with input_ids and attention_mask"
            }
          ],
          "inheritance": "Dataset",
          "dependencies": [
            "torch.utils.data",
            ".base_tokenizer"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "create_transformer_dataloaders",
          "signature": "create_transformer_dataloaders(train_texts: List[str], tokenizer: BaseTokenizer, val_texts: Optional[List[str]] = None, batch_size: int = 32, max_length: Optional[int] = None, shuffle: bool = True, num_workers: int = 0) -> Tuple[DataLoader, Optional[DataLoader]]",
          "brief_description": "Create train and validation dataloaders for transformer training with appropriate collation"
        },
        {
          "name": "transformer_collate_fn",
          "signature": "transformer_collate_fn(batch: List[Union[Dict[str, torch.Tensor], List[int]]]) -> Union[Dict[str, torch.Tensor], torch.Tensor]",
          "brief_description": "Collate and pad batches of text sequences for transformer models"
        }
      ],
      "external_dependencies": [
        "torch",
        "torch.utils.data"
      ],
      "complexity_score": 5,
      "module_path": "src/data/tokenization/utils.py"
    },
    {
      "filename": "preprocessing.py",
      "module_purpose": "Provides text preprocessing utilities for tokenization including Unicode normalization and text cleaning",
      "key_classes": [],
      "key_functions": [
        {
          "name": "normalize_unicode",
          "signature": "normalize_unicode(text: str) -> str",
          "brief_description": "Normalize Unicode characters in text using NFKC form"
        },
        {
          "name": "clean_text",
          "signature": "clean_text(text: str, lower: bool = True, remove_accents: bool = False, strip_html: bool = True, handle_contractions: bool = True) -> str",
          "brief_description": "Clean and normalize text with configurable options for case, accents, HTML, and contractions"
        },
        {
          "name": "segment_on_punc",
          "signature": "segment_on_punc(text: str) -> str",
          "brief_description": "Add spaces around punctuation to help with tokenization"
        }
      ],
      "external_dependencies": [
        "re",
        "unicodedata",
        "html"
      ],
      "complexity_score": 3,
      "module_path": "src/data/tokenization/preprocessing.py"
    },
    {
      "filename": "bert_tokenizer_adapter.py",
      "module_purpose": "Provides an adapter class to make HuggingFace BERT tokenizers compatible with the project's tokenizer interface",
      "key_classes": [
        {
          "name": "BertTokenizerAdapter",
          "purpose": "Adapter class that wraps HuggingFace BERT tokenizers to match project interface",
          "key_methods": [
            {
              "name": "__init__",
              "signature": "__init__(self, pretrained_model_name_or_path: str)",
              "brief_description": "Initialize adapter with a pretrained BERT tokenizer"
            },
            {
              "name": "tokenize",
              "signature": "tokenize(self, text: str) -> List[str]",
              "brief_description": "Convert text into BERT tokens"
            },
            {
              "name": "encode",
              "signature": "encode(self, text: str) -> List[int]",
              "brief_description": "Convert text to BERT token indices"
            }
          ],
          "inheritance": "BaseTokenizer",
          "dependencies": [
            "transformers.BertTokenizer"
          ]
        }
      ],
      "external_dependencies": [
        "transformers",
        "torch",
        "typing"
      ],
      "complexity_score": 4,
      "module_path": "src/data/tokenization/bert_tokenizer_adapter.py"
    },
    {
      "filename": "bpe_tokenizer.py",
      "module_purpose": "Implements Byte Pair Encoding tokenizer for subword tokenization with merge operations",
      "key_classes": [
        {
          "name": "BPETokenizer",
          "purpose": "Tokenizer that implements Byte Pair Encoding algorithm for subword tokenization",
          "key_methods": [
            {
              "name": "preprocess",
              "signature": "preprocess(self, text: str) -> str",
              "brief_description": "Preprocess text before tokenization"
            },
            {
              "name": "train",
              "signature": "train(self, texts: List[str], vocab_size: Optional[int] = None, min_frequency: int = 2, show_progress: bool = True) -> None",
              "brief_description": "Train the BPE tokenizer on a corpus of texts by iteratively merging frequent character pairs"
            },
            {
              "name": "_tokenize_word",
              "signature": "_tokenize_word(self, word: str) -> List[str]",
              "brief_description": "Tokenize a single word using BPE merge operations"
            },
            {
              "name": "tokenize",
              "signature": "tokenize(self, text: str) -> List[str]",
              "brief_description": "Convert text into subword tokens based on learned merge operations"
            },
            {
              "name": "encode",
              "signature": "encode(self, text: str) -> List[int]",
              "brief_description": "Convert text to token indices using the vocabulary"
            },
            {
              "name": "batch_encode",
              "signature": "batch_encode(self, texts: List[str]) -> List[List[int]]",
              "brief_description": "Encode a batch of texts into token indices"
            },
            {
              "name": "decode",
              "signature": "decode(self, token_ids: List[int]) -> str",
              "brief_description": "Convert token indices back to text"
            },
            {
              "name": "save_pretrained",
              "signature": "save_pretrained(self, path: str) -> None",
              "brief_description": "Save tokenizer configuration, vocabulary and merges to disk"
            },
            {
              "name": "from_pretrained",
              "signature": "from_pretrained(cls, path: str) -> 'BPETokenizer'",
              "brief_description": "Load a tokenizer from a saved directory"
            },
            {
              "name": "vocab_size",
              "signature": "vocab_size(self) -> int",
              "brief_description": "Get the size of the tokenizer vocabulary (property)"
            },
            {
              "name": "special_tokens",
              "signature": "special_tokens(self) -> Dict[str, int]",
              "brief_description": "Get the special token IDs (property)"
            }
          ],
          "inheritance": "BaseTokenizer",
          "dependencies": [
            ".base_tokenizer",
            ".vocabulary",
            ".preprocessing"
          ]
        }
      ],
      "key_functions": [
        {
          "name": "preprocess_data_with_optimized_bpe",
          "signature": "preprocess_data_with_optimized_bpe(dataset, de_tokenizer, en_tokenizer, batch_size=4000, use_multiprocessing=False, num_workers=4)",
          "brief_description": "Optimized preprocessing function for translation datasets"
        },
        {
          "name": "_preprocess_without_multiprocessing",
          "signature": "_preprocess_without_multiprocessing(dataset, de_tokenizer, en_tokenizer, batch_size)",
          "brief_description": "Process dataset without multiprocessing (better for GPU utilization)"
        },
        {
          "name": "_preprocess_with_multiprocessing",
          "signature": "_preprocess_with_multiprocessing(dataset, de_tokenizer, en_tokenizer, batch_size, num_workers)",
          "brief_description": "Process dataset with multiprocessing (better for CPU-bound tasks)"
        }
      ],
      "external_dependencies": [
        "json",
        "tqdm",
        "collections.Counter",
        "multiprocessing.Pool"
      ],
      "complexity_score": 7,
      "module_path": "src/data/tokenization/bpe_tokenizer.py"
    },
    {
      "filename": "tokenizer_metrics.py",
      "module_path": "src/data/tokenization/tokenizer_metrics.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "vocabulary.py",
      "module_purpose": "Implements a flexible vocabulary system for mapping between tokens and indices with special token support",
      "key_classes": [
        {
          "name": "Vocabulary",
          "purpose": "Manages token-to-index and index-to-token mappings with special token handling",
          "key_methods": [
            {
              "name": "add_token",
              "signature": "add_token(self, token: str) -> int",
              "brief_description": "Add a token to the vocabulary and return its index"
            },
            {
              "name": "token_to_index",
              "signature": "token_to_index(self, token: str) -> int",
              "brief_description": "Convert a token to its index with validation"
            },
            {
              "name": "index_to_token",
              "signature": "index_to_token(self, idx: int) -> str",
              "brief_description": "Convert an index to its token with validation"
            },
            {
              "name": "tokens_to_indices",
              "signature": "tokens_to_indices(self, tokens: List[str]) -> List[int]",
              "brief_description": "Convert a list of tokens to their indices"
            },
            {
              "name": "indices_to_tokens",
              "signature": "indices_to_tokens(self, indices: List[int]) -> List[str]",
              "brief_description": "Convert a list of indices to their tokens"
            },
            {
              "name": "save",
              "signature": "save(self, path: str) -> None",
              "brief_description": "Save vocabulary to a JSON file"
            },
            {
              "name": "load",
              "signature": "load(cls, path: str) -> 'Vocabulary'",
              "brief_description": "Load vocabulary from a JSON file"
            },
            {
              "name": "build_from_texts",
              "signature": "build_from_texts(cls, texts: List[str], tokenizer, max_vocab_size: Optional[int] = None, min_freq: int = 1, **kwargs) -> 'Vocabulary'",
              "brief_description": "Build a vocabulary from a list of texts using the provided tokenizer"
            }
          ],
          "inheritance": "object",
          "dependencies": [
            "json",
            "collections.Counter",
            "logging"
          ]
        }
      ],
      "external_dependencies": [
        "json",
        "collections.Counter",
        "logging"
      ],
      "complexity_score": 6,
      "module_path": "src/data/tokenization/vocabulary.py"
    },
    {
      "filename": "turbo_bpe_preprocessor.py",
      "module_path": "src/data/tokenization/turbo_bpe_preprocessor.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    },
    {
      "filename": "simple_tokenizer.py",
      "module_path": "src/data/tokenization/simple_tokenizer.py",
      "module_purpose": "No metadata function available",
      "has_metadata_function": false
    }
  ],
  "summary": {
    "total_modules": 126,
    "modules_with_metadata": 113,
    "modules_without_metadata": 13
  },
  "complexity_summary": {
    "average_complexity": 6.256637168141593,
    "modules_by_complexity": [
      {
        "module": "src/training/flickr_multistage_training.py",
        "score": 9
      },
      {
        "module": "src/training/losses/hybrid_pretrain_vicreg_loss.py",
        "score": 9
      },
      {
        "module": "src/training/strategies/end_to_end_strategy.py",
        "score": 9
      },
      {
        "module": "src/training/trainers/multimodal_trainer.py",
        "score": 9
      },
      {
        "module": "src/utils/profiling.py",
        "score": 9
      },
      {
        "module": "src/models/transformer.py",
        "score": 9
      },
      {
        "module": "src/models/multimodal/multimodal_decoder_generation.py",
        "score": 9
      },
      {
        "module": "src/safety/harness.py",
        "score": 9
      },
      {
        "module": "src/safety/utils.py",
        "score": 9
      },
      {
        "module": "src/data/tokenization/optimized_bpe_tokenizer.py",
        "score": 9
      },
      {
        "module": "src/optimization/quantization.py",
        "score": 8
      },
      {
        "module": "src/training/optimizers.py",
        "score": 8
      },
      {
        "module": "src/training/losses/multimodal_mixed_contrastive_loss.py",
        "score": 8
      },
      {
        "module": "src/training/losses/decoupled_contrastive_loss.py",
        "score": 8
      },
      {
        "module": "src/training/losses/hard_negative_mining_contrastive_loss.py",
        "score": 8
      },
      {
        "module": "src/training/losses/ema_moco_loss.py",
        "score": 8
      },
      {
        "module": "src/training/losses/contrastive_loss.py",
        "score": 8
      },
      {
        "module": "src/training/strategies/single_modality_strategy.py",
        "score": 8
      },
      {
        "module": "src/training/trainers/multistage_trainer.py",
        "score": 8
      },
      {
        "module": "src/training/trainers/vision_transformer_trainer.py",
        "score": 8
      },
      {
        "module": "src/training/trainers/language_model_trainer.py",
        "score": 8
      },
      {
        "module": "src/training/trainers/transformer_trainer.py",
        "score": 8
      },
      {
        "module": "src/utils/feature_attribution.py",
        "score": 8
      },
      {
        "module": "src/utils/gradient_handler.py",
        "score": 8
      },
      {
        "module": "src/models/attention.py",
        "score": 8
      },
      {
        "module": "src/models/model_factory.py",
        "score": 8
      },
      {
        "module": "src/models/vision/vision_transformer.py",
        "score": 8
      },
      {
        "module": "src/models/multimodal/vicreg_multimodal_model.py",
        "score": 8
      },
      {
        "module": "src/models/multimodal/bidirectional_cross_attention.py",
        "score": 8
      },
      {
        "module": "src/safety/integration.py",
        "score": 8
      },
      {
        "module": "src/safety/filter.py",
        "score": 8
      },
      {
        "module": "src/safety/evaluator.py",
        "score": 8
      },
      {
        "module": "src/safety/red_teaming/evaluator.py",
        "score": 8
      },
      {
        "module": "src/data/augmentation_pipeline.py",
        "score": 8
      },
      {
        "module": "src/data/multimodal_data_utils.py",
        "score": 8
      },
      {
        "module": "src/data/multimodal_dataset.py",
        "score": 8
      },
      {
        "module": "src/optimization/pruning.py",
        "score": 7
      },
      {
        "module": "src/training/metrics.py",
        "score": 7
      },
      {
        "module": "src/training/losses/loss_factory.py",
        "score": 7
      },
      {
        "module": "src/training/losses/vicreg_loss.py",
        "score": 7
      },
      {
        "module": "src/training/losses/multitask_loss.py",
        "score": 7
      },
      {
        "module": "src/training/losses/contrastive_learning.py",
        "score": 7
      },
      {
        "module": "src/training/losses/memory_queue_contrastive_loss.py",
        "score": 7
      },
      {
        "module": "src/training/losses/supervised_contrastive_loss.py",
        "score": 7
      },
      {
        "module": "src/training/losses/clip_style_loss.py",
        "score": 7
      },
      {
        "module": "src/training/losses/feature_consistency_loss.py",
        "score": 7
      },
      {
        "module": "src/training/losses/dynamic_temperature_contrastive_loss.py",
        "score": 7
      },
      {
        "module": "src/training/strategies/cross_modal_strategy.py",
        "score": 7
      },
      {
        "module": "src/training/trainers/trainer_factory.py",
        "score": 7
      },
      {
        "module": "src/utils/learningrate_scheduler.py",
        "score": 7
      },
      {
        "module": "src/utils/metrics_tracker.py",
        "score": 7
      },
      {
        "module": "src/utils/visualization.py",
        "score": 7
      },
      {
        "module": "src/models/text_generation.py",
        "score": 7
      },
      {
        "module": "src/models/positional.py",
        "score": 7
      },
      {
        "module": "src/models/multimodal/multimodal_integration.py",
        "score": 7
      },
      {
        "module": "src/models/multimodal/co_attention_fusion.py",
        "score": 7
      },
      {
        "module": "src/models/multimodal/gated_cross_modal_attention.py",
        "score": 7
      },
      {
        "module": "src/models/multimodal/clip_style_direct_projection.py",
        "score": 7
      },
      {
        "module": "src/models/multimodal/dual_encoder.py",
        "score": 7
      },
      {
        "module": "src/models/pretrained/huggingface_wrapper.py",
        "score": 7
      },
      {
        "module": "src/safety/red_teaming/framework.py",
        "score": 7
      },
      {
        "module": "src/safety/red_teaming/generators.py",
        "score": 7
      },
      {
        "module": "src/evaluation/language_model_evaluation.py",
        "score": 7
      },
      {
        "module": "src/evaluation/inference_demo.py",
        "score": 7
      },
      {
        "module": "src/data/curriculum_dataset.py",
        "score": 7
      },
      {
        "module": "src/data/tokenization/bpe_tokenizer.py",
        "score": 7
      },
      {
        "module": "src/optimization/benchmarking.py",
        "score": 6
      },
      {
        "module": "src/training/transformer_utils.py",
        "score": 6
      },
      {
        "module": "src/training/losses/barlow_twins_loss.py",
        "score": 6
      },
      {
        "module": "src/training/losses/decorrelation_loss.py",
        "score": 6
      },
      {
        "module": "src/training/strategies/training_strategy.py",
        "score": 6
      },
      {
        "module": "src/training/trainers/trainer.py",
        "score": 6
      },
      {
        "module": "src/models/feed_forward.py",
        "score": 6
      },
      {
        "module": "src/models/vision/image_preprocessing.py",
        "score": 6
      },
      {
        "module": "src/models/multimodal/cross_modal_attention_base.py",
        "score": 6
      },
      {
        "module": "src/data/sequence_data.py",
        "score": 6
      },
      {
        "module": "src/data/tokenization/vocabulary.py",
        "score": 6
      },
      {
        "module": "src/optimization/mixed_precision.py",
        "score": 5
      },
      {
        "module": "src/training/losses/combined_loss.py",
        "score": 5
      },
      {
        "module": "src/utils/model_utils.py",
        "score": 5
      },
      {
        "module": "src/models/vision/patch_embedding.py",
        "score": 5
      },
      {
        "module": "src/models/pretrained/clip_model.py",
        "score": 5
      },
      {
        "module": "src/data/iwslt_dataset.py",
        "score": 5
      },
      {
        "module": "src/data/language_modeling.py",
        "score": 5
      },
      {
        "module": "src/data/wikipedia_dataset.py",
        "score": 5
      },
      {
        "module": "src/data/tokenization/utils.py",
        "score": 5
      },
      {
        "module": "src/training/losses/losses.py",
        "score": 4
      },
      {
        "module": "src/utils/logging.py",
        "score": 4
      },
      {
        "module": "src/utils/argument_configs.py",
        "score": 4
      },
      {
        "module": "src/utils/list_models.py",
        "score": 4
      },
      {
        "module": "src/models/layers.py",
        "score": 4
      },
      {
        "module": "src/models/pretrained/base_wrapper.py",
        "score": 4
      },
      {
        "module": "src/data/wmt_dataset.py",
        "score": 4
      },
      {
        "module": "src/data/image_dataset.py",
        "score": 4
      },
      {
        "module": "src/data/europarl_dataset.py",
        "score": 4
      },
      {
        "module": "src/data/preprocessing.py",
        "score": 4
      },
      {
        "module": "src/data/opensubtitles_dataset.py",
        "score": 4
      },
      {
        "module": "src/data/tokenization/bert_tokenizer_adapter.py",
        "score": 4
      },
      {
        "module": "src/training/joint_bpe_training.py",
        "score": 3
      },
      {
        "module": "src/utils/config.py",
        "score": 3
      },
      {
        "module": "src/models/base_model.py",
        "score": 3
      },
      {
        "module": "src/models/pretrained/vision_transformer.py",
        "score": 3
      },
      {
        "module": "src/models/pretrained/model_registry.py",
        "score": 3
      },
      {
        "module": "src/models/pretrained/adapters.py",
        "score": 3
      },
      {
        "module": "src/evaluation/translation_metrics.py",
        "score": 3
      },
      {
        "module": "src/data/wmt_dataloader.py",
        "score": 3
      },
      {
        "module": "src/data/dataloader.py",
        "score": 3
      },
      {
        "module": "src/data/dataset_wrapper.py",
        "score": 3
      },
      {
        "module": "src/data/tokenization/preprocessing.py",
        "score": 3
      },
      {
        "module": "src/models/embeddings.py",
        "score": 2
      },
      {
        "module": "src/data/combined_translation_dataset.py",
        "score": 2
      },
      {
        "module": "src/data/tokenization/base_tokenizer.py",
        "score": 2
      },
      {
        "module": "src/models/activations.py",
        "score": 1
      }
    ]
  },
  "dependency_summary": {
    "total_external_dependencies": 39,
    "dependencies_by_usage": [
      {
        "name": "torch",
        "usage_count": 90
      },
      {
        "name": "numpy",
        "usage_count": 32
      },
      {
        "name": "typing",
        "usage_count": 20
      },
      {
        "name": "logging",
        "usage_count": 17
      },
      {
        "name": "matplotlib",
        "usage_count": 15
      },
      {
        "name": "tqdm",
        "usage_count": 15
      },
      {
        "name": "json",
        "usage_count": 9
      },
      {
        "name": "PIL",
        "usage_count": 6
      },
      {
        "name": "math",
        "usage_count": 5
      },
      {
        "name": "transformers",
        "usage_count": 5
      },
      {
        "name": "random",
        "usage_count": 5
      },
      {
        "name": "os",
        "usage_count": 4
      },
      {
        "name": "torchvision",
        "usage_count": 4
      },
      {
        "name": "re",
        "usage_count": 4
      },
      {
        "name": "abc",
        "usage_count": 3
      },
      {
        "name": "seaborn",
        "usage_count": 3
      },
      {
        "name": "nltk",
        "usage_count": 2
      },
      {
        "name": "torch.nn",
        "usage_count": 2
      },
      {
        "name": "argparse",
        "usage_count": 2
      },
      {
        "name": "sklearn",
        "usage_count": 2
      },
      {
        "name": "psutil",
        "usage_count": 2
      },
      {
        "name": "datasets",
        "usage_count": 2
      },
      {
        "name": "torch.utils.data",
        "usage_count": 2
      },
      {
        "name": "collections.Counter",
        "usage_count": 2
      },
      {
        "name": "src.data.tokenization",
        "usage_count": 1
      },
      {
        "name": "copy",
        "usage_count": 1
      },
      {
        "name": "time",
        "usage_count": 1
      },
      {
        "name": "huggingface_hub",
        "usage_count": 1
      },
      {
        "name": "pandas",
        "usage_count": 1
      },
      {
        "name": "timm",
        "usage_count": 1
      },
      {
        "name": "open_clip",
        "usage_count": 1
      },
      {
        "name": "datetime",
        "usage_count": 1
      },
      {
        "name": "collections",
        "usage_count": 1
      },
      {
        "name": "pathlib",
        "usage_count": 1
      },
      {
        "name": "tensorflow",
        "usage_count": 1
      },
      {
        "name": "threading",
        "usage_count": 1
      },
      {
        "name": "unicodedata",
        "usage_count": 1
      },
      {
        "name": "html",
        "usage_count": 1
      },
      {
        "name": "multiprocessing.Pool",
        "usage_count": 1
      }
    ]
  }
}