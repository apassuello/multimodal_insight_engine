import torch
from torch.utils.data import Dataset
import numpy as np
from collections import Counter
from typing import List, Dict, Tuple, Optional, Callable, Any


class CurriculumTranslationDataset(Dataset):
    """
    Dataset for curriculum learning in translation tasks.

    This dataset implements various curriculum learning strategies for machine translation:
    - "length": Sort by sentence length (shorter sentences first)
    - "vocab": Sort by vocabulary complexity (common words first)
    - "similarity": Sort by source-target length ratio (similar lengths first)

    The curriculum progresses in stages, exposing more complex examples as training advances.
    """

    def __init__(
        self,
        source_sequences: List[List[int]],
        target_sequences: List[List[int]],
        curriculum_strategy: str = "length",
        num_stages: int = 5,
        pad_idx: int = 0,
        max_src_len: int = 100,
        max_tgt_len: int = 100,
    ):
        """
        Initialize the curriculum dataset.

        Args:
            source_sequences: List of source token sequences (already encoded)
            target_sequences: List of target token sequences (already encoded)
            curriculum_strategy: Strategy for curriculum (length, vocab, similarity)
            num_stages: Number of curriculum stages
            pad_idx: Padding token index
            max_src_len: Maximum source sequence length
            max_tgt_len: Maximum target sequence length
        """
        print("\n=== Initializing Curriculum Learning Dataset ===")
        print(f"Total examples: {len(source_sequences)}")
        print(f"Strategy: {curriculum_strategy}")
        print(f"Number of stages: {num_stages}")

        self.source_sequences = source_sequences
        self.target_sequences = target_sequences
        self.curriculum_strategy = curriculum_strategy
        self.num_stages = num_stages
        self.pad_idx = pad_idx
        self.max_src_len = max_src_len
        self.max_tgt_len = max_tgt_len

        # Start at the first curriculum stage
        self.current_stage = 0

        print("\nCalculating difficulty scores...")
        # Calculate difficulty scores for each example
        self.difficulties = self._calculate_difficulties()

        # Sort examples by difficulty
        print("Sorting examples by difficulty...")
        self.sorted_indices = np.argsort(self.difficulties).tolist()

        print("\nCurriculum initialization complete!")
        print(f"Initialized curriculum learning with strategy '{curriculum_strategy}'")
        print(f"Curriculum will progress through {num_stages} stages")

        # Calculate statistics for reporting
        difficulties = np.array(self.difficulties)
        print(f"\nDifficulty statistics:")
        print(f"  Min: {difficulties.min():.2f}")
        print(f"  Max: {difficulties.max():.2f}")
        print(f"  Mean: {difficulties.mean():.2f}")
        print(f"  Median: {np.median(difficulties):.2f}")

        # Print initial curriculum samples
        print("\nInitial curriculum setup:")
        self.print_curriculum_samples(num_samples=5)
        print("=== Curriculum Learning Dataset Initialization Complete ===\n")

    def _calculate_difficulties(self) -> List[float]:
        """Calculate difficulty scores for all examples based on selected strategy."""
        difficulties = []

        if self.curriculum_strategy == "length":
            # Length-based curriculum: shorter sentences are easier
            for src, tgt in zip(self.source_sequences, self.target_sequences):
                # Use maximum length as difficulty
                difficulty = max(len(src), len(tgt))
                difficulties.append(difficulty)

        elif self.curriculum_strategy == "vocab":
            # Vocabulary-based curriculum: common words are easier
            # First, calculate token frequencies across the dataset
            counter = Counter()
            for seq in self.source_sequences + self.target_sequences:
                counter.update(seq)

            # Calculate inverse frequency (rarity) for each token
            total_tokens = sum(counter.values())
            token_rarity = {
                token: total_tokens / count for token, count in counter.items()
            }

            # Calculate average token rarity for each example
            for src, tgt in zip(self.source_sequences, self.target_sequences):
                # Average rarity across both source and target
                src_rarity = sum(token_rarity.get(t, 1.0) for t in src) / max(
                    1, len(src)
                )
                tgt_rarity = sum(token_rarity.get(t, 1.0) for t in tgt) / max(
                    1, len(tgt)
                )
                difficulty = (src_rarity + tgt_rarity) / 2
                difficulties.append(difficulty)

        elif self.curriculum_strategy == "similarity":
            # Similarity-based curriculum: sentences with similar lengths are easier
            for src, tgt in zip(self.source_sequences, self.target_sequences):
                # Ratio of longer to shorter (always â‰¥ 1.0)
                longer = max(len(src), len(tgt))
                shorter = min(len(src), len(tgt))
                # Avoid division by zero
                if shorter == 0:
                    difficulty = 10.0  # Arbitrary high value
                else:
                    difficulty = longer / shorter
                difficulties.append(difficulty)

        else:
            # Default to length-based if strategy not recognized
            print(
                f"Warning: Curriculum strategy '{self.curriculum_strategy}' not recognized."
            )
            print("Defaulting to length-based curriculum.")
            return self._calculate_difficulties_by_length()

        return difficulties

    def _calculate_difficulties_by_length(self) -> List[float]:
        """Calculate difficulty scores based on sequence length."""
        difficulties = []
        for src, tgt in zip(self.source_sequences, self.target_sequences):
            difficulty = max(len(src), len(tgt))
            difficulties.append(difficulty)
        return difficulties

    def update_stage(self, new_stage: int) -> None:
        """
        Update the curriculum stage.

        Args:
            new_stage: New curriculum stage (0 to num_stages-1)
        """
        if new_stage < 0 or new_stage >= self.num_stages:
            print(
                f"Warning: Invalid curriculum stage {new_stage}. Must be between 0 and {self.num_stages-1}."
            )
            return

        prev_stage = self.current_stage
        self.current_stage = new_stage

        # Calculate percent of data available at current stage
        percent = 100 * self.get_stage_percent()

        if prev_stage != new_stage:
            print(
                f"Curriculum advanced to stage {new_stage}/{self.num_stages-1} ({percent:.1f}% of data)"
            )
            # Print sample examples from the current stage
            self.print_curriculum_samples()

    def print_curriculum_samples(self, num_samples: int = 3) -> None:
        """
        Print sample examples from the current curriculum stage.

        Args:
            num_samples: Number of samples to print
        """
        available_length = self.__len__()
        total_length = len(self.source_sequences)
        available_indices = self.sorted_indices[:available_length]

        # Get difficulty scores for available examples
        available_difficulties = [self.difficulties[i] for i in available_indices]

        # Print statistics about current stage
        print(f"\nCurriculum Stage {self.current_stage} Samples:")
        print(f"Strategy: {self.curriculum_strategy}")
        print(
            f"Available examples: {available_length}/{total_length} ({100 * available_length/total_length:.1f}%)"
        )
        print(
            f"Difficulty range: {min(available_difficulties):.2f} - {max(available_difficulties):.2f}"
        )
        print(
            f"Average difficulty: {sum(available_difficulties)/len(available_difficulties):.2f}"
        )

        # Print sample examples
        print("\nSample examples from current stage:")
        for i in range(min(num_samples, available_length)):
            idx = available_indices[i]
            src = self.source_sequences[idx]
            tgt = self.target_sequences[idx]
            difficulty = self.difficulties[idx]

            print(f"\nExample {i+1} (Difficulty: {difficulty:.2f}):")
            print(f"Source length: {len(src)}, Target length: {len(tgt)}")
            print(f"Source tokens: {src}")
            print(f"Target tokens: {tgt}")

    def get_stage_percent(self) -> float:
        """
        Get the percentage of data available at the current stage.

        Returns:
            Float between 0 and 1 representing portion of data available
        """
        # Progressively include more data as stages advance
        # Stage 0: 20% of data, Stage 1: 40% of data, etc.
        return (self.current_stage + 1) / self.num_stages

    def __len__(self) -> int:
        """Get the length of the dataset at the current curriculum stage."""
        total_length = len(self.source_sequences)
        available_percent = self.get_stage_percent()
        # Ensure at least 100 examples are available even at the first stage
        return max(100, int(total_length * available_percent))

    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """
        Get an item from the dataset based on curriculum stage.

        Args:
            idx: Index into the curriculum-filtered dataset

        Returns:
            Dictionary with source and target tensors
        """
        # Map the input index to the sorted curriculum index
        available_length = self.__len__()
        if idx >= available_length:
            idx = idx % available_length

        # Get the actual index based on difficulty
        actual_idx = self.sorted_indices[idx]

        # Get source and target sequences
        src = self.source_sequences[actual_idx]
        tgt = self.target_sequences[actual_idx]

        # Truncate sequences if needed
        src = src[: self.max_src_len]
        tgt = tgt[: self.max_tgt_len]

        return {
            "src_tokens": torch.tensor(src, dtype=torch.long),
            "tgt_tokens": torch.tensor(tgt, dtype=torch.long),
        }

    def get_curriculum_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the current curriculum stage.

        Returns:
            Dictionary of curriculum statistics
        """
        available_length = self.__len__()
        total_length = len(self.source_sequences)
        available_indices = self.sorted_indices[:available_length]

        available_difficulties = [self.difficulties[i] for i in available_indices]
        if not available_difficulties:
            return {"error": "No examples available at current stage"}

        return {
            "stage": self.current_stage,
            "num_stages": self.num_stages,
            "examples_available": available_length,
            "total_examples": total_length,
            "percent_available": 100 * available_length / total_length,
            "min_difficulty": min(available_difficulties),
            "max_difficulty": max(available_difficulties),
            "mean_difficulty": sum(available_difficulties)
            / len(available_difficulties),
        }

    def print_curriculum_progression_summary(self) -> None:
        """
        Print a summary of the curriculum progression.
        """
        print("\nCurriculum Learning Progression Summary:")
        print(f"Strategy: {self.curriculum_strategy}")
        print(f"Total stages: {self.num_stages}")
        print(f"Final stage reached: {self.current_stage}/{self.num_stages-1}")

        # Calculate statistics for each stage
        total_examples = len(self.source_sequences)
        for stage in range(self.num_stages + 1):
            # Calculate how many examples would be available at this stage
            available_percent = (stage + 1) / self.num_stages
            available_count = max(100, int(total_examples * available_percent))
            available_indices = self.sorted_indices[:available_count]

            # Get difficulty scores for this stage
            stage_difficulties = [self.difficulties[i] for i in available_indices]

            print(f"\nStage {stage}/{self.num_stages-1}:")
            print(
                f"  Examples available: {available_count}/{total_examples} ({100 * available_count/total_examples:.1f}%)"
            )
            print(
                f"  Difficulty range: {min(stage_difficulties):.2f} - {max(stage_difficulties):.2f}"
            )
            print(
                f"  Average difficulty: {sum(stage_difficulties)/len(stage_difficulties):.2f}"
            )
