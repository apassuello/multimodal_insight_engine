# Environment Variables for Constitutional AI Demo
# Copy this file to .env and customize as needed

# ============================================================================
# Gradio Configuration
# ============================================================================

# Server hostname (use 0.0.0.0 for Docker, localhost for local)
GRADIO_SERVER_NAME=0.0.0.0

# Server port
GRADIO_SERVER_PORT=7860

# Enable/disable sharing (creates temporary public URL)
GRADIO_SHARE=false

# ============================================================================
# Model Configuration
# ============================================================================

# Default model to use (gpt2, gpt2-medium, distilgpt2)
DEFAULT_MODEL=gpt2

# Device preference (auto, mps, cuda, cpu)
DEVICE_PREFERENCE=auto

# ============================================================================
# Training Configuration
# ============================================================================

# Quick demo settings
QUICK_DEMO_EPOCHS=2
QUICK_DEMO_DATASET_SIZE=20
QUICK_DEMO_BATCH_SIZE=4
QUICK_DEMO_LEARNING_RATE=5e-5

# Standard training settings
STANDARD_EPOCHS=5
STANDARD_DATASET_SIZE=50
STANDARD_BATCH_SIZE=4
STANDARD_LEARNING_RATE=5e-5

# ============================================================================
# Paths Configuration
# ============================================================================

# Directory for model checkpoints
CHECKPOINTS_DIR=demo/checkpoints

# Directory for logs
LOGS_DIR=demo/logs

# Directory for exports
EXPORTS_DIR=demo/exports

# HuggingFace cache directory (optional)
# HF_HOME=/root/.cache/huggingface

# ============================================================================
# Optional: HuggingFace Configuration
# ============================================================================

# HuggingFace API token (for private models)
# HF_TOKEN=your_token_here

# Use HuggingFace offline mode (requires pre-downloaded models)
# HF_DATASETS_OFFLINE=1
# TRANSFORMERS_OFFLINE=1

# ============================================================================
# Optional: Resource Limits
# ============================================================================

# Maximum memory per process (for OOM prevention)
# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Number of CPU threads for PyTorch
# OMP_NUM_THREADS=4

# ============================================================================
# Optional: Monitoring & Logging
# ============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable/disable verbose logging
VERBOSE=false

# ============================================================================
# Optional: Security (for public deployments)
# ============================================================================

# Enable authentication (requires Gradio Pro)
# GRADIO_AUTH_USERNAME=admin
# GRADIO_AUTH_PASSWORD=change_this_password

# Allow embedding in iframes
# GRADIO_ALLOW_FLAGGING=never

# ============================================================================
# Optional: Performance Tuning
# ============================================================================

# Enable mixed precision training (faster on CUDA)
# ENABLE_MIXED_PRECISION=false

# Gradient accumulation steps
# GRADIENT_ACCUMULATION_STEPS=1

# Maximum sequence length
# MAX_SEQUENCE_LENGTH=512
